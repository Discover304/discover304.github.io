<!DOCTYPE html><html lang="en" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>【机器学习】第二部分下：决策树回归 | Yang's Harbor</title><meta name="keywords" content="学习,记录,Python,笔记,机器学习"><meta name="author" content="✨YangSier✨,hobart.yang@qq.com"><meta name="copyright" content="✨YangSier✨"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="决策树回归核心思想：相似的输入必会产生相似的输出。例如预测某人薪资： 年龄：1-青年，2-中年，3-老年学历：1-本科，2-硕士，3-博士经历：1-出道，2-一般，3-老手，4-骨灰性别：1-男性，2-女性    年龄 学历 经历 性别 &#x3D;&#x3D;&gt; 薪资    1 1 1 1 &#x3D;&#x3D;&gt; 6000（低）   2 1 3 1 &#x3D;&#x3D;&amp;gt">
<meta property="og:type" content="article">
<meta property="og:title" content="【机器学习】第二部分下：决策树回归">
<meta property="og:url" content="https://discover304.top/2021/11/25/2021q4/103-1-ml-dt/index.html">
<meta property="og:site_name" content="Yang&#39;s Harbor">
<meta property="og:description" content="决策树回归核心思想：相似的输入必会产生相似的输出。例如预测某人薪资： 年龄：1-青年，2-中年，3-老年学历：1-本科，2-硕士，3-博士经历：1-出道，2-一般，3-老手，4-骨灰性别：1-男性，2-女性    年龄 学历 经历 性别 &#x3D;&#x3D;&gt; 薪资    1 1 1 1 &#x3D;&#x3D;&gt; 6000（低）   2 1 3 1 &#x3D;&#x3D;&amp;gt">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://image.discover304.top/ai/AI-cover-black-white.webp">
<meta property="article:published_time" content="2021-11-25T06:27:23.000Z">
<meta property="article:modified_time" content="2021-12-25T06:48:56.000Z">
<meta property="article:author" content="✨YangSier✨">
<meta property="article:tag" content="学习">
<meta property="article:tag" content="记录">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="笔记">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://image.discover304.top/ai/AI-cover-black-white.webp"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://discover304.top/2021/11/25/2021q4/103-1-ml-dt/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="preconnect" href="//zz.bdstatic.com"/><meta name="google-site-verification" content="ilqpfk3vkgzDNNikz_V37-DOvRyi5wv4Hoi_eyBqvTg"/><meta name="msvalidate.01" content="49D9A50CCF9744E17274791468EDB517"/><meta name="baidu-site-verification" content="code-V24KosyVh1"/><meta name="360-site-verification" content="bd8859c3d74dfa3e8aeee9db30c94bd2"/><meta name="yandex-verification" content="f28ec9bbd50c56f5"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script async="async" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script>(adsbygoogle = window.adsbygoogle || []).push({
  google_ad_client: 'ca-pub-1849044985266192',
  enable_page_level_ads: 'true'
});</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8030f6052f2fed6a4704d96619f090d6";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><link rel="stylesheet" href="/css/font.css" media="print" onload="this.media='all'"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: {"limitDay":365,"position":"bottom","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'days',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: {"limitCount":200,"languages":{"author":"Author: ✨YangSier✨","link":"Link: ","source":"Source: Yang's Harbor","info":"Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source."}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"Traditional Chinese Activated Manually","cht_to_chs":"Simplified Chinese Activated Manually","day_to_night":"Dark Mode Activated Manually","night_to_day":"Light Mode Activated Manually","bgLight":"#ffc910","bgDark":"#02c3f6","position":"bottom-left"},
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isanchor: true
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}

// https://stackoverflow.com/questions/16839698/jquery-getscript-alternative-in-native-javascript
const getScript = url => new Promise((resolve, reject) => {
  const script = document.createElement('script')
  script.src = url
  script.async = true
  script.onerror = reject
  script.onload = script.onreadystatechange = function() {
    const loadState = this.readyState
    if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
    script.onload = script.onreadystatechange = null
    resolve()
  }
  document.head.appendChild(script)
})</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-12-25 14:48:56'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
   if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }
  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified
    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }const asideStatus = saveToLocal.get('aside-status')
if (asideStatus !== undefined) {
   if (asideStatus === 'hide') {
     document.documentElement.classList.add('hide-aside')
   } else {
     document.documentElement.classList.remove('hide-aside')
   }
}})()</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Yang's Harbor" type="application/atom+xml">
</head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/head.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">261</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">90</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">29</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-link"></i><span> Connection</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/link/"><i class="fa-fw fas fa-address-book"></i><span> Friends</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://aierlab.com"><i class="fa-fw fas fa-sitemap"></i><span> GroupSite</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-wrench"></i><span> Tools</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/diary"><i class="fa-fw fas fa-file-text"></i><span> Diary</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://wandb.ai/"><i class="fa-fw fas fa-newspaper"></i><span> WandB</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> Article</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archive</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Category</span></a></li><li><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></li></ul></div></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://image.discover304.top/ai/AI-cover-black-white.webp)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Yang's Harbor</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-link"></i><span> Connection</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/link/"><i class="fa-fw fas fa-address-book"></i><span> Friends</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://aierlab.com"><i class="fa-fw fas fa-sitemap"></i><span> GroupSite</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-wrench"></i><span> Tools</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/diary"><i class="fa-fw fas fa-file-text"></i><span> Diary</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://wandb.ai/"><i class="fa-fw fas fa-newspaper"></i><span> WandB</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> Article</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archive</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Category</span></a></li><li><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">【机器学习】第二部分下：决策树回归</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2021-11-25T06:27:23.000Z" title="Created 2021-11-25 14:27:23">2021-11-25</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2021-12-25T06:48:56.000Z" title="Updated 2021-12-25 14:48:56">2021-12-25</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/NoteBook/">NoteBook</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/NoteBook/PythonNote/">PythonNote</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">3.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>14min</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="决策树回归"><a href="#决策树回归" class="headerlink" title="决策树回归"></a>决策树回归</h1><p>核心思想：相似的输入必会产生相似的输出。例如预测某人薪资：</p>
<p>年龄：1-青年，2-中年，3-老年<br>学历：1-本科，2-硕士，3-博士<br>经历：1-出道，2-一般，3-老手，4-骨灰<br>性别：1-男性，2-女性</p>
<table>
<thead>
<tr>
<th>年龄</th>
<th>学历</th>
<th>经历</th>
<th>性别</th>
<th>&#x3D;&#x3D;&gt;</th>
<th>薪资</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>&#x3D;&#x3D;&gt;</td>
<td>6000（低）</td>
</tr>
<tr>
<td>2</td>
<td>1</td>
<td>3</td>
<td>1</td>
<td>&#x3D;&#x3D;&gt;</td>
<td>10000（中）</td>
</tr>
<tr>
<td>3</td>
<td>3</td>
<td>4</td>
<td>1</td>
<td>&#x3D;&#x3D;&gt;</td>
<td>50000（高）</td>
</tr>
<tr>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>&#x3D;&#x3D;&gt;</td>
<td>…</td>
</tr>
<tr>
<td>1</td>
<td>3</td>
<td>2</td>
<td>2</td>
<td>&#x3D;&#x3D;&gt;</td>
<td>?</td>
</tr>
</tbody></table>
 <figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">样本数量非常庞大  <span class="number">100</span>W个样本</span><br><span class="line"></span><br><span class="line">换一种数据结构，来提高检索效率</span><br><span class="line"></span><br><span class="line">树形结构</span><br><span class="line"></span><br><span class="line">回归 ：  均值</span><br><span class="line">分类 ： 投票<span class="comment">(概率)</span></span><br></pre></td></tr></table></figure>



<p>为了提高搜索效率，使用树形数据结构处理样本数据：<br>$$<br>\text{年龄}&#x3D;1\left{<br>\begin{aligned}<br>\text{学历}1 \<br>\text{学历}2 \<br>\text{学历}3 \<br>\end{aligned}<br>\right.<br>\quad\quad<br>\text{年龄}&#x3D;2\left{<br>\begin{aligned}<br>\text{学历}1 \<br>\text{学历}2 \<br>\text{学历}3 \<br>\end{aligned}<br>\right.<br>\quad\quad<br>\text{年龄}&#x3D;3\left{<br>\begin{aligned}<br>\text{学历}1 \<br>\text{学历}2 \<br>\text{学历}3 \<br>\end{aligned}<br>\right.<br>$$<br>首先从训练样本矩阵中选择一个特征进行子表划分，使每个子表中该特征的值全部相同，然后再在每个子表中选择下一个特征按照同样的规则继续划分更小的子表，不断重复直到所有的特征全部使用完为止，此时便得到叶级子表，其中所有样本的特征值全部相同。对于待预测样本，根据其每一个特征的值，选择对应的子表，逐一匹配，直到找到与之完全匹配的叶级子表，用该子表中样本的输出，通过平均(回归)或者投票(分类)为待预测样本提供输出。</p>
<p><strong>首先选择哪一个特征进行子表划分决定了决策树的性能。这么多特征，使用哪个特征先进行子表划分？</strong></p>
<p>sklearn提供的决策树底层为cart树（Classification and Regression Tree），cart回归树在解决回归问题时的步骤如下：</p>
<ol>
<li><p>原始数据集S，此时树的深度depth&#x3D;0；</p>
</li>
<li><p>针对集合S，遍历每一个特征的每一个value(遍历数据中的所有离散值 (12个)   )</p>
<p>用该value将原数据集S分裂成2个集合：左集合left(&lt;&#x3D;value的样本)、右集合right(&gt;value的样本)，</p>
<p>分别计算这2个集合的mse(均方误差)，找到使（left_mse+right_mse）最小的那个value，记录下此时的特征名称和value，这个就是最佳分割特征以及最佳分割值；</p>
<p>​	mse:均方误差</p>
<p>​	((y1-y1’)^2 + (y2-y2’)^2 + (y3-y3’)^2  + (y4-y4’)^2 )  &#x2F; 4   &#x3D; mse</p>
</li>
</ol>
<pre><code>	
</code></pre>
<p>x1   y1       y1’</p>
<p>x2   y2	  y2’</p>
<p>x3   y3	  y3’</p>
<p>x4   y4	  y4’</p>
<ol>
<li><p>找到最佳分割特征以及最佳分割value之后，用该value将集合S分裂成2个集合，depth+&#x3D;1；</p>
</li>
<li><p>针对集合left、right分别重复步骤2,3，直到达到终止条件。</p>
</li>
</ol>
<p>决策树底层结构 为二叉树</p>
<figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">终止条件有如下几种：</span><br><span class="line"><span class="number">1</span>、特征已经用完了：没有可供使用的特征再进行分裂了，则树停止分裂；</span><br><span class="line"><span class="number">2</span>、子节点中没有样本了：此时该结点已经没有样本可供划分，该结点停止分裂；</span><br><span class="line"><span class="number">3</span>、树达到了人为预先设定的最大深度：depth &gt;<span class="operator">=</span> max_depth，树停止分裂。</span><br><span class="line"><span class="number">4</span>、节点的样本数量达到了人为设定的阈值：样本数量 &lt; min_samples_split ，则该节点停止分裂；</span><br></pre></td></tr></table></figure>

<p>决策树回归器模型相关API：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sklearn.tree <span class="keyword">as</span> st</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建决策树回归器模型  决策树的最大深度为4</span></span><br><span class="line">model = st.DecisionTreeRegressor(max_depth=<span class="number">4</span>)</span><br><span class="line"><span class="comment"># 训练模型  </span></span><br><span class="line"><span class="comment"># train_x： 二维数组样本数据</span></span><br><span class="line"><span class="comment"># train_y： 训练集中对应每行样本的结果</span></span><br><span class="line">model.fit(train_x, train_y)</span><br><span class="line"><span class="comment"># 测试模型</span></span><br><span class="line">pred_test_y = model.predict(test_x)</span><br></pre></td></tr></table></figure>

<p>案例：预测波士顿地区房屋价格。</p>
<ol>
<li>读取数据，打断原始数据集。 划分训练集和测试集。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sklearn.datasets <span class="keyword">as</span> sd</span><br><span class="line"><span class="keyword">import</span> sklearn.utils <span class="keyword">as</span> su</span><br><span class="line"><span class="comment"># 加载波士顿地区房价数据集</span></span><br><span class="line">boston = sd.load_boston()</span><br><span class="line"><span class="built_in">print</span>(boston.feature_names)</span><br><span class="line"><span class="comment"># |CRIM|ZN|INDUS|CHAS|NOX|RM|AGE|DIS|RAD|TAX|PTRATIO|B|LSTAT|</span></span><br><span class="line"><span class="comment"># 犯罪率|住宅用地比例|商业用地比例|是否靠河|空气质量|房间数|年限|距中心区距离|路网密度|房产税|师生比|黑人比例|低地位人口比例|</span></span><br><span class="line"><span class="comment"># 打乱原始数据集的输入和输出</span></span><br><span class="line">x, y = su.shuffle(boston.data, boston.target, random_state=<span class="number">7</span>)</span><br><span class="line"><span class="comment"># 划分训练集和测试集</span></span><br><span class="line">train_size = <span class="built_in">int</span>(<span class="built_in">len</span>(x) * <span class="number">0.8</span>)</span><br><span class="line">train_x, test_x, train_y, test_y = \</span><br><span class="line">    x[:train_size], x[train_size:], \</span><br><span class="line">    y[:train_size], y[train_size:]</span><br></pre></td></tr></table></figure>

<ol>
<li>创建决策树回归器模型，使用训练集训练模型。使用测试集测试模型。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sklearn.tree <span class="keyword">as</span> st</span><br><span class="line"><span class="keyword">import</span> sklearn.metrics <span class="keyword">as</span> sm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建决策树回归模型</span></span><br><span class="line">model = st.DecisionTreeRegressor(max_depth=<span class="number">4</span>)</span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model.fit(train_x, train_y)</span><br><span class="line"><span class="comment"># 测试模型</span></span><br><span class="line">pred_test_y = model.predict(test_x)</span><br><span class="line"><span class="built_in">print</span>(sm.r2_score(test_y, pred_test_y))</span><br></pre></td></tr></table></figure>

<h1 id="集成算法"><a href="#集成算法" class="headerlink" title="集成算法"></a>集成算法</h1><blockquote>
<p>三个臭皮匠，顶个诸葛亮</p>
</blockquote>
<p>单个模型得到的预测结果总是片面的，根据多个不同模型给出的预测结果，利用平均(回归)或者投票(分类)的方法，得出最终预测结果。</p>
<p>基于决策树的集成算法，就是按照某种规则，构建多棵彼此不同的决策树模型，分别给出针对未知样本的预测结果，最后通过平均或投票得到相对综合的结论。常用的集成模型包括Boosting类模型（AdaBoost、GBDT、<a target="_blank" rel="noopener" href="https://www.cnblogs.com/mantch/p/11164221.html">XGBoost</a>）与Bagging（自助聚合、随机森林）类模型。</p>
<h2 id="AdaBoost模型（正向激励）"><a href="#AdaBoost模型（正向激励）" class="headerlink" title="AdaBoost模型（正向激励）"></a>AdaBoost模型（正向激励）</h2><p>首先为样本矩阵中的样本随机分配初始权重，由此构建一棵带有权重的决策树，在由该决策树提供预测输出时，通过加权平均或者加权投票的方式产生预测值。</p>
<figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">已经构建好一个决策树  通过1322 找到所有的女博士  一个4个 <span class="number"> 6000 </span><span class="number"> 8000 </span>9000 10000</span><br><span class="line">由于正向激励，对每个样本都分配了初始权重 权重为:1<span class="number"> 1 </span>1<span class="number"> 3 </span> 预测： 加权均值</span><br></pre></td></tr></table></figure>

<p>将训练样本代入模型，预测其输出，对那些预测值与实际值不同的样本，提高其权重，进行针对性训练，由此形成第二棵决策树。重复以上过程，构建出不同权重的若干棵决策树。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">实际值：10000  但是你预测的为6000   构建第二个决策树，提高10000样本的权重</span><br></pre></td></tr></table></figure>



<p>正向激励相关API：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sklearn.tree <span class="keyword">as</span> st</span><br><span class="line"><span class="keyword">import</span> sklearn.ensemble <span class="keyword">as</span> se</span><br><span class="line"><span class="comment"># model: 决策树模型（一颗）</span></span><br><span class="line">model = st.DecisionTreeRegressor(max_depth=<span class="number">4</span>)</span><br><span class="line"><span class="comment"># 自适应增强决策树回归模型	</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line">model = se.AdaBoostRegressor(model, n_estimators=<span class="number">400</span>, random_state=<span class="number">7</span>)</span><br><span class="line"></span><br><span class="line">正向激励 的基础模型 ： 决策树</span><br><span class="line">n_estimators：构建<span class="number">400</span>棵不同权重的决策树，训练模型</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model.fit(train_x, train_y)</span><br><span class="line"><span class="comment"># 测试模型</span></span><br><span class="line">pred_test_y = model.predict(test_x)</span><br></pre></td></tr></table></figure>

<p>案例：基于正向激励训练预测波士顿地区房屋价格的模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建基于决策树的正向激励回归器模型</span></span><br><span class="line">model = se.AdaBoostRegressor(</span><br><span class="line">	st.DecisionTreeRegressor(max_depth=<span class="number">4</span>), n_estimators=<span class="number">400</span>, random_state=<span class="number">7</span>)</span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model.fit(train_x, train_y)</span><br><span class="line"><span class="comment"># 测试模型</span></span><br><span class="line">pred_test_y = model.predict(test_x)</span><br><span class="line"><span class="built_in">print</span>(sm.r2_score(test_y, pred_test_y))</span><br></pre></td></tr></table></figure>



<p><strong>特征重要性</strong></p>
<p>作为决策树模型训练过程的副产品，根据划分子表时选择特征的顺序标志了该特征的重要程度，此即为该特征重要性指标。训练得到的模型对象提供了属性：feature_importances_来存储每个特征的重要性。</p>
<p>获取样本矩阵特征重要性属性：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.fit(train_x, train_y)</span><br><span class="line">fi = model.feature_importances_</span><br></pre></td></tr></table></figure>

<p>案例：获取普通决策树与正向激励决策树训练的两个模型的特征重要性值，按照从大到小顺序输出绘图。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> mp</span><br><span class="line"></span><br><span class="line">model = st.DecisionTreeRegressor(max_depth=<span class="number">4</span>)</span><br><span class="line">model.fit(train_x, train_y)</span><br><span class="line"><span class="comment"># 决策树回归器给出的特征重要性</span></span><br><span class="line">fi_dt = model.feature_importances_</span><br><span class="line">model = se.AdaBoostRegressor(</span><br><span class="line">    st.DecisionTreeRegressor(max_depth=<span class="number">4</span>), n_estimators=<span class="number">400</span>, random_state=<span class="number">7</span>)</span><br><span class="line">model.fit(train_x, train_y)</span><br><span class="line"><span class="comment"># 基于决策树的正向激励回归器给出的特征重要性</span></span><br><span class="line">fi_ab = model.feature_importances_</span><br><span class="line"></span><br><span class="line">mp.figure(<span class="string">&#x27;Feature Importance&#x27;</span>, facecolor=<span class="string">&#x27;lightgray&#x27;</span>)</span><br><span class="line">mp.subplot(<span class="number">211</span>)</span><br><span class="line">mp.title(<span class="string">&#x27;Decision Tree&#x27;</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">mp.ylabel(<span class="string">&#x27;Importance&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">mp.tick_params(labelsize=<span class="number">10</span>)</span><br><span class="line">mp.grid(axis=<span class="string">&#x27;y&#x27;</span>, linestyle=<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">sorted_indices = fi_dt.argsort()[::-<span class="number">1</span>]</span><br><span class="line">pos = np.arange(sorted_indices.size)</span><br><span class="line">mp.bar(pos, fi_dt[sorted_indices], facecolor=<span class="string">&#x27;deepskyblue&#x27;</span>, edgecolor=<span class="string">&#x27;steelblue&#x27;</span>)</span><br><span class="line">mp.xticks(pos, feature_names[sorted_indices], rotation=<span class="number">30</span>)</span><br><span class="line">mp.subplot(<span class="number">212</span>)</span><br><span class="line">mp.title(<span class="string">&#x27;AdaBoost Decision Tree&#x27;</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">mp.ylabel(<span class="string">&#x27;Importance&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">mp.tick_params(labelsize=<span class="number">10</span>)</span><br><span class="line">mp.grid(axis=<span class="string">&#x27;y&#x27;</span>, linestyle=<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">sorted_indices = fi_ab.argsort()[::-<span class="number">1</span>]</span><br><span class="line">pos = np.arange(sorted_indices.size)</span><br><span class="line">mp.bar(pos, fi_ab[sorted_indices], facecolor=<span class="string">&#x27;lightcoral&#x27;</span>, edgecolor=<span class="string">&#x27;indianred&#x27;</span>)</span><br><span class="line">mp.xticks(pos, feature_names[sorted_indices], rotation=<span class="number">30</span>)</span><br><span class="line">mp.tight_layout()</span><br><span class="line">mp.show()</span><br></pre></td></tr></table></figure>

<h2 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h2><p>GBDT（Gradient Boosting Decision Tree 梯度提升树）通过多轮迭代，每轮迭代产生一个弱分类器，每个分类器在上一轮分类器的残差<strong>（残差在数理统计中是指实际观察值与估计值（拟合值）之间的差）</strong>基础上进行训练。基于预测结果的残差设计损失函数。GBDT训练的过程即是求该损失函数最小值的过程。</p>
<p><strong>案例</strong></p>
<p><img src="https://image.discover304.top/ai/GBDT%E6%A1%88%E4%BE%8B.png" alt="GBDT案例"></p>
<p><strong>原理1</strong>：</p>
<p><img src="https://image.discover304.top/ai/GBDT%E5%8E%9F%E7%90%861.png" alt="GBDT原理1"></p>
<p><strong>原理2</strong>：</p>
<p><img src="https://image.discover304.top/ai/GBDT%E5%8E%9F%E7%90%862.png" alt="GBDT原理2"></p>
<p><strong>原理3</strong>：</p>
<p><img src="https://image.discover304.top/ai/GBDT%E5%8E%9F%E7%90%863.png" alt="GBDT原理3"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sklearn.tree <span class="keyword">as</span> st</span><br><span class="line"><span class="keyword">import</span> sklearn.ensemble <span class="keyword">as</span> se</span><br><span class="line"><span class="comment"># 自适应增强决策树回归模型	</span></span><br><span class="line"><span class="comment"># n_estimators：构建400棵不同权重的决策树，训练模型</span></span><br><span class="line">model = se.GridientBoostingRegressor(</span><br><span class="line">    	max_depth=<span class="number">10</span>, n_estimators=<span class="number">1000</span>, min_samples_split=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model.fit(train_x, train_y)</span><br><span class="line"><span class="comment"># 测试模型</span></span><br><span class="line">pred_test_y = model.predict(test_x)</span><br></pre></td></tr></table></figure>

<h2 id="自助聚合（BootStrap）"><a href="#自助聚合（BootStrap）" class="headerlink" title="自助聚合（BootStrap）"></a>自助聚合（BootStrap）</h2><p>每次从总样本矩阵中以有放回抽样的方式随机抽取部分样本构建决策树，这样形成多棵包含不同训练样本的决策树，以削弱某些强势样本对模型预测结果的影响，提高模型的泛化特性。</p>
<p>因为sklearn大部分训练已经打包成了接口，很难调整每次训练的样本，所以在没有sklean接口的情况下自助聚合不容易使用。</p>
<h2 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h2><p>在自助聚合的基础上，每次构建决策树模型时，不仅随机选择部分样本，而且还随机选择部分特征，这样的集合算法，不仅规避了强势样本对预测结果的影响，而且也削弱了强势特征的影响，使模型的预测能力更加泛化。</p>
<p>随机森林相关API：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sklearn.ensemble <span class="keyword">as</span> se</span><br><span class="line"><span class="comment"># 随机森林回归模型	（属于集合算法的一种）</span></span><br><span class="line"><span class="comment"># max_depth：决策树最大深度10</span></span><br><span class="line"><span class="comment"># n_estimators：构建1000棵决策树，训练模型</span></span><br><span class="line"><span class="comment"># min_samples_split: 子表中最小样本数 若小于这个数字，则不再继续向下拆分</span></span><br><span class="line">model = se.RandomForestRegressor(</span><br><span class="line">    max_depth=<span class="number">10</span>, n_estimators=<span class="number">1000</span>, min_samples_split=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<p>案例：分析共享单车的需求，从而判断如何进行共享单车的投放。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1。加载并整理数据集</span><br><span class="line">2.特征分析</span><br><span class="line">3.打乱数据集，划分训练集，测试集</span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sklearn.utils <span class="keyword">as</span> su</span><br><span class="line"><span class="keyword">import</span> sklearn.ensemble <span class="keyword">as</span> se</span><br><span class="line"><span class="keyword">import</span> sklearn.metrics <span class="keyword">as</span> sm</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> mp</span><br><span class="line"></span><br><span class="line">data = np.loadtxt(<span class="string">&#x27;../data/bike_day.csv&#x27;</span>, unpack=<span class="literal">False</span>, dtype=<span class="string">&#x27;U20&#x27;</span>, delimiter=<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">day_headers = data[<span class="number">0</span>, <span class="number">2</span>:<span class="number">13</span>]</span><br><span class="line">x = np.array(data[<span class="number">1</span>:, <span class="number">2</span>:<span class="number">13</span>], dtype=<span class="built_in">float</span>)</span><br><span class="line">y = np.array(data[<span class="number">1</span>:, -<span class="number">1</span>], dtype=<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line">x, y = su.shuffle(x, y, random_state=<span class="number">7</span>)</span><br><span class="line"><span class="built_in">print</span>(x.shape, y.shape)</span><br><span class="line">train_size = <span class="built_in">int</span>(<span class="built_in">len</span>(x) * <span class="number">0.9</span>)</span><br><span class="line">train_x, test_x, train_y, test_y = \</span><br><span class="line">    x[:train_size], x[train_size:], y[:train_size], y[train_size:]</span><br><span class="line"><span class="comment"># 随机森林回归器</span></span><br><span class="line">model = se.RandomForestRegressor( max_depth=<span class="number">10</span>, n_estimators=<span class="number">1000</span>, min_samples_split=<span class="number">2</span>)</span><br><span class="line">model.fit(train_x, train_y)</span><br><span class="line"><span class="comment"># 基于“天”数据集的特征重要性</span></span><br><span class="line">fi_dy = model.feature_importances_</span><br><span class="line">pred_test_y = model.predict(test_x)</span><br><span class="line"><span class="built_in">print</span>(sm.r2_score(test_y, pred_test_y))</span><br><span class="line"></span><br><span class="line">data = np.loadtxt(<span class="string">&#x27;../data/bike_hour.csv&#x27;</span>, unpack=<span class="literal">False</span>, dtype=<span class="string">&#x27;U20&#x27;</span>, delimiter=<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">hour_headers = data[<span class="number">0</span>, <span class="number">2</span>:<span class="number">13</span>]</span><br><span class="line">x = np.array(data[<span class="number">1</span>:, <span class="number">2</span>:<span class="number">13</span>], dtype=<span class="built_in">float</span>)</span><br><span class="line">y = np.array(data[<span class="number">1</span>:, -<span class="number">1</span>], dtype=<span class="built_in">float</span>)</span><br><span class="line">x, y = su.shuffle(x, y, random_state=<span class="number">7</span>)</span><br><span class="line">train_size = <span class="built_in">int</span>(<span class="built_in">len</span>(x) * <span class="number">0.9</span>)</span><br><span class="line">train_x, test_x, train_y, test_y = \</span><br><span class="line">    x[:train_size], x[train_size:], \</span><br><span class="line">    y[:train_size], y[train_size:]</span><br><span class="line"><span class="comment"># 随机森林回归器</span></span><br><span class="line">model = se.RandomForestRegressor(</span><br><span class="line">    max_depth=<span class="number">10</span>, n_estimators=<span class="number">1000</span>,</span><br><span class="line">    min_samples_split=<span class="number">2</span>)</span><br><span class="line">model.fit(train_x, train_y)</span><br><span class="line"><span class="comment"># 基于“小时”数据集的特征重要性</span></span><br><span class="line">fi_hr = model.feature_importances_</span><br><span class="line">pred_test_y = model.predict(test_x)</span><br><span class="line"><span class="built_in">print</span>(sm.r2_score(test_y, pred_test_y))</span><br></pre></td></tr></table></figure>

<p>画图显示两组样本数据的特征重要性：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">mp.figure(<span class="string">&#x27;Bike&#x27;</span>, facecolor=<span class="string">&#x27;lightgray&#x27;</span>)</span><br><span class="line">mp.subplot(<span class="number">211</span>)</span><br><span class="line">mp.title(<span class="string">&#x27;Day&#x27;</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">mp.ylabel(<span class="string">&#x27;Importance&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">mp.tick_params(labelsize=<span class="number">10</span>)</span><br><span class="line">mp.grid(axis=<span class="string">&#x27;y&#x27;</span>, linestyle=<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">sorted_indices = fi_dy.argsort()[::-<span class="number">1</span>]</span><br><span class="line">pos = np.arange(sorted_indices.size)</span><br><span class="line">mp.bar(pos, fi_dy[sorted_indices], facecolor=<span class="string">&#x27;deepskyblue&#x27;</span>, edgecolor=<span class="string">&#x27;steelblue&#x27;</span>)</span><br><span class="line">mp.xticks(pos, day_headers[sorted_indices], rotation=<span class="number">30</span>)</span><br><span class="line"></span><br><span class="line">mp.subplot(<span class="number">212</span>)</span><br><span class="line">mp.title(<span class="string">&#x27;Hour&#x27;</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">mp.ylabel(<span class="string">&#x27;Importance&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">mp.tick_params(labelsize=<span class="number">10</span>)</span><br><span class="line">mp.grid(axis=<span class="string">&#x27;y&#x27;</span>, linestyle=<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">sorted_indices = fi_hr.argsort()[::-<span class="number">1</span>]</span><br><span class="line">pos = np.arange(sorted_indices.size)</span><br><span class="line">mp.bar(pos, fi_hr[sorted_indices], facecolor=<span class="string">&#x27;lightcoral&#x27;</span>, edgecolor=<span class="string">&#x27;indianred&#x27;</span>)</span><br><span class="line">mp.xticks(pos, hour_headers[sorted_indices], rotation=<span class="number">30</span>)</span><br><span class="line">mp.tight_layout()</span><br><span class="line">mp.show()</span><br></pre></td></tr></table></figure>

<h1 id="补充知识"><a href="#补充知识" class="headerlink" title="补充知识"></a>补充知识</h1><h2 id="R2系数详细计算"><a href="#R2系数详细计算" class="headerlink" title="R2系数详细计算"></a>R2系数详细计算</h2><p>R2系数详细计算过程如下：</p>
<p>若用$y_i$表示真实的观测值，用$\bar{y}$表示真实观测值的平均值，用$\hat{y_i}$表示预测值则，有以下评估指标：</p>
<ul>
<li>回归平方和（SSR）</li>
</ul>
<p>$$<br>SSR &#x3D; \sum_{i&#x3D;1}^{n}(\hat{y_i} - \bar{y})^2<br>$$</p>
<p>估计值与平均值的误差，反映自变量与因变量之间的相关程度的偏差平方和.</p>
<ul>
<li>残差平方和（SSE）</li>
</ul>
<p>$$<br>SSE &#x3D; \sum_{i&#x3D;1}^{n}(y_i-\hat{y_i} )^2<br>$$</p>
<p>即估计值与真实值的误差，反映模型拟合程度.</p>
<ul>
<li>总离差平方和（SST）</li>
</ul>
<p>$$<br>SST &#x3D;SSR + SSE&#x3D; \sum_{i&#x3D;1}^{n}(y_i - \bar{y})^2<br>$$</p>
<p>即平均值与真实值的误差，反映与数学期望的偏离程度.</p>
<ul>
<li>R2_score计算公式</li>
</ul>
<p>R2_score，即决定系数，反映因变量的全部变异能通过回归关系被自变量解释的比例.计算公式：<br>$$<br>R^2&#x3D;1-\frac{SSE}{SST}<br>$$<br>即：<br>$$<br>R^2 &#x3D; 1 - \frac{\sum_{i&#x3D;1}^{n} (y_i - \hat{y}<em>i)2}{\sum</em>{i&#x3D;1}{n} (y_i - \bar{y})^2}<br>$$<br>进一步化简为：<br>$$<br>R^2 &#x3D; 1 - \frac{\sum\limits_i(y_i - y_i)^2 &#x2F; n}{\sum\limits_i(y_i - \hat{y})^2 &#x2F; n} &#x3D; 1 - \frac{RMSE}{Var}<br>$$<br>分子就变成了常用的评价指标均方误差MSE，分母就变成了方差，对于$R^2$可以通俗地理解为使用均值作为误差基准，看预测误差是否大于或者小于均值基准误差.</p>
<p>R2_score &#x3D; 1，样本中预测值和真实值完全相等，没有任何误差，表示回归分析中自变量对因变量的解释越好.</p>
<p>R2_score &#x3D; 0，此时分子等于分母，样本的每项预测值都等于均值.</p>
<h2 id="线性回归损失函数求导过程"><a href="#线性回归损失函数求导过程" class="headerlink" title="线性回归损失函数求导过程"></a>线性回归损失函数求导过程</h2><p>线性函数定义为：<br>$$<br>y &#x3D; w_0 + w_0 x_1<br>$$<br>采用均方差损失函数：<br>$$<br>loss &#x3D; \frac{1}{2} (y - y’)^2<br>$$<br>其中，y为真实值，来自样本；y’为预测值，即线性方程表达式，带入损失函数得：<br>$$<br>loss &#x3D; \frac{1}{2} (y - (w_0 + w_1 x_1))^2<br>$$<br>将该式子展开：<br>$$<br>loss &#x3D; \frac{1}{2} (y^2 - 2y(w_0 + w_1 x_1) + (w_0 + w_1 x_1)^2) \<br>\frac{1}{2} (y^2 - 2y<em>w_0 - 2y</em>w_1x_1 + w_0^2 + 2w_0<em>w_1 x_1 + w_1^2x_1^2) \<br>$$<br>对$w_0$求导：<br>$$<br>\frac{\partial loss}{\partial w_0} &#x3D; \frac{1}{2}(0-2y-0+2w_0 + 2w_1 x_1 +0) \<br>&#x3D;\frac{1}{2}(-2y + 2 w_0 + 2w_1 x_1) \<br>&#x3D; \frac{1}{2} * 2(-y + (w_0 + w_1 x_1)) \<br>&#x3D;(-y + y’) &#x3D; -(y - y’)<br>$$<br>对$w_1$求导：<br>$$<br>\frac{\partial loss}{\partial w_1} &#x3D; \frac{1}{2}(0-0-2y</em>x_1+0+2 w_0 x_1 + 2 w_1 x_1^2) \<br>&#x3D; \frac{1}{2} (-2y x_1 + 2 w_0 x_1 + 2w_1 x_1^2) \<br>&#x3D; \frac{1}{2} * 2 x_1(-y + w_0 + w_1 x_1) \<br>&#x3D; x_1(-y + y’) &#x3D; - x_1(y - y’)<br>$$<br>推导完毕.</p>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AD%A6%E4%B9%A0/">学习</a><a class="post-meta__tags" href="/tags/%E8%AE%B0%E5%BD%95/">记录</a><a class="post-meta__tags" href="/tags/Python/">Python</a><a class="post-meta__tags" href="/tags/%E7%AC%94%E8%AE%B0/">笔记</a><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></div><div class="post_share"><div class="social-share" data-image="https://image.discover304.top/ai/AI-cover-black-white.webp" data-sites="facebook,twitter,wechat,weibo,qzone,qq,linkedin"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> Donate<div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/img/wechat.jpg" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/alipay.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/11/25/2021q4/103-2-ml-lo/"><img class="prev-cover" src="https://image.discover304.top/ai/AI-cover-black-white.webp" onerror="onerror=null;src='/img/404.png'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">【机器学习】第三部分壹：逻辑回归</div></div></a></div><div class="next-post pull-right"><a href="/2021/11/25/2021q4/103-1-ml-lr/"><img class="next-cover" src="https://image.discover304.top/ai/AI-cover-black-white.webp" onerror="onerror=null;src='/img/404.png'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">【机器学习】第二部分上：线性回归</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2021/11/25/2021q4/103-0-ml/" title="【机器学习】第一部分：概述"><img class="cover" src="https://image.discover304.top/ai/AI-cover-black-white.webp" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2021-12-25</div><div class="title">【机器学习】第一部分：概述</div></div></a></div><div><a href="/2021/11/25/2021q4/103-1-ml-lr/" title="【机器学习】第二部分上：线性回归"><img class="cover" src="https://image.discover304.top/ai/AI-cover-black-white.webp" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2021-12-25</div><div class="title">【机器学习】第二部分上：线性回归</div></div></a></div><div><a href="/2021/11/25/2021q4/103-2-ml-bays/" title="【机器学习】第三部分肆：朴素贝叶斯"><img class="cover" src="https://image.discover304.top/ai/AI-cover-black-white.webp" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2021-12-25</div><div class="title">【机器学习】第三部分肆：朴素贝叶斯</div></div></a></div><div><a href="/2021/11/25/2021q4/103-2-ml-svm/" title="【机器学习】第三部分叁：支持向量机（SVM）"><img class="cover" src="https://image.discover304.top/ai/AI-cover-black-white.webp" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2021-12-25</div><div class="title">【机器学习】第三部分叁：支持向量机（SVM）</div></div></a></div><div><a href="/2021/11/25/2021q4/103-2-ml-lo/" title="【机器学习】第三部分壹：逻辑回归"><img class="cover" src="https://image.discover304.top/ai/AI-cover-black-white.webp" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2021-12-25</div><div class="title">【机器学习】第三部分壹：逻辑回归</div></div></a></div><div><a href="/2021/11/25/2021q4/103-2-ml-dt/" title="【机器学习】第三部分贰：决策树分类"><img class="cover" src="https://image.discover304.top/ai/AI-cover-black-white.webp" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2021-12-25</div><div class="title">【机器学习】第三部分贰：决策树分类</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside_content" id="aside_content"><div class="card-widget card-info"><div class="card-content"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/head.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">✨YangSier✨</div><div class="author-info__description">Love Everything You Like.</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">261</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">90</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">29</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://space.bilibili.com/98639326"><i class="fab fa-bilibili"></i><span>Bilibili Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/YangSierCode000" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://blog.csdn.net/Discover304" target="_blank" title="CSDN"><i class="fa-solid fa-c"></i></a><a class="social-icon" href="https://www.zhihu.com/people/discover-56-86-75" target="_blank" title="知乎"><i class="fa-brands fa-zhihu"></i></a><a class="social-icon" href="mailto:hobart.yang@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://jq.qq.com/?_wv=1027&amp;k=EaGddTQg" target="_blank" title="QQ"><i class="fa-brands fa-qq"></i></a></div></div></div><div class="card-widget card-announcement"><div class="card-content"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">✨动态更新：<p style="text-align:center">享受精彩大学生活中。</p>✨聊天划水QQ群：<p style="text-align:center"><a target="_blank" rel="noopener" href="https://jq.qq.com/?_wv=1027&k=EaGddTQg"><strong>兔叽の魔术工房</strong></a><br>942-848-525</p>✨我们的口号是：<p style="text-align:center; color:#39C5BB">人工降神，机械飞升！</p><a target="_blank" rel="noopener" href='https://space.bilibili.com/98639326'><img src='/img/mikulittletrans.png'></a></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="card-content"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E5%9B%9E%E5%BD%92"><span class="toc-text">决策树回归</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%9B%86%E6%88%90%E7%AE%97%E6%B3%95"><span class="toc-text">集成算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#AdaBoost%E6%A8%A1%E5%9E%8B%EF%BC%88%E6%AD%A3%E5%90%91%E6%BF%80%E5%8A%B1%EF%BC%89"><span class="toc-text">AdaBoost模型（正向激励）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GBDT"><span class="toc-text">GBDT</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%87%AA%E5%8A%A9%E8%81%9A%E5%90%88%EF%BC%88BootStrap%EF%BC%89"><span class="toc-text">自助聚合（BootStrap）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"><span class="toc-text">随机森林</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%A1%A5%E5%85%85%E7%9F%A5%E8%AF%86"><span class="toc-text">补充知识</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#R2%E7%B3%BB%E6%95%B0%E8%AF%A6%E7%BB%86%E8%AE%A1%E7%AE%97"><span class="toc-text">R2系数详细计算</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E6%B1%82%E5%AF%BC%E8%BF%87%E7%A8%8B"><span class="toc-text">线性回归损失函数求导过程</span></a></li></ol></li></ol></div></div></div><div class="card-widget card-recent-post"><div class="card-content"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/06/25/183-rl-call/" title="ICLR2024 Emergent Communication With Conversational Repair"><img src="https://api.btstu.cn/sjbz/api.php?lx=dongman&amp;format=images" onerror="this.onerror=null;this.src='/img/404.png'" alt="ICLR2024 Emergent Communication With Conversational Repair"/></a><div class="content"><a class="title" href="/2024/06/25/183-rl-call/" title="ICLR2024 Emergent Communication With Conversational Repair">ICLR2024 Emergent Communication With Conversational Repair</a><time datetime="2024-06-25T07:30:48.635Z" title="Updated 2024-06-25 15:30:48">2024-06-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/02/05/181-2/" title="PMR Basic Assumptions for Efficient Model Representation"><img src="https://api.btstu.cn/sjbz/api.php?lx=dongman&amp;format=images" onerror="this.onerror=null;this.src='/img/404.png'" alt="PMR Basic Assumptions for Efficient Model Representation"/></a><div class="content"><a class="title" href="/2024/02/05/181-2/" title="PMR Basic Assumptions for Efficient Model Representation">PMR Basic Assumptions for Efficient Model Representation</a><time datetime="2024-05-31T09:58:47.688Z" title="Updated 2024-05-31 17:58:47">2024-05-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/12/17/2021q4/118-ros-note-code-naming/" title="【机器人】ROS1程序运行指北：启动、重命名、launch"><img src="https://image.discover304.top/bai_gu_gu_head.jpg?imageView2/2/h/300" onerror="this.onerror=null;this.src='/img/404.png'" alt="【机器人】ROS1程序运行指北：启动、重命名、launch"/></a><div class="content"><a class="title" href="/2021/12/17/2021q4/118-ros-note-code-naming/" title="【机器人】ROS1程序运行指北：启动、重命名、launch">【机器人】ROS1程序运行指北：启动、重命名、launch</a><time datetime="2024-03-10T04:03:46.235Z" title="Updated 2024-03-10 12:03:46">2024-03-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/12/17/2021q4/118-ros-note-code-serv/" title="【机器人】ROS1工程案例：服务和动作"><img src="https://image.discover304.top/bai_gu_gu_head.jpg?imageView2/2/h/300" onerror="this.onerror=null;this.src='/img/404.png'" alt="【机器人】ROS1工程案例：服务和动作"/></a><div class="content"><a class="title" href="/2021/12/17/2021q4/118-ros-note-code-serv/" title="【机器人】ROS1工程案例：服务和动作">【机器人】ROS1工程案例：服务和动作</a><time datetime="2024-03-10T04:03:46.235Z" title="Updated 2024-03-10 12:03:46">2024-03-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/12/17/2021q4/118-ros-note-code-type/" title="【机器人】ROS1工程案例：自定义消息类型"><img src="https://image.discover304.top/bai_gu_gu_head.jpg?imageView2/2/h/300" onerror="this.onerror=null;this.src='/img/404.png'" alt="【机器人】ROS1工程案例：自定义消息类型"/></a><div class="content"><a class="title" href="/2021/12/17/2021q4/118-ros-note-code-type/" title="【机器人】ROS1工程案例：自定义消息类型">【机器人】ROS1工程案例：自定义消息类型</a><time datetime="2024-03-10T04:03:46.235Z" title="Updated 2024-03-10 12:03:46">2024-03-10</time></div></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(https://image.discover304.top/ai/AI-cover-black-white.webp)"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By ✨YangSier✨</div><div><a target="_blank" href="https://beian.miit.gov.cn/" style="display:inline-block;text-decoration:none;height:20px;line-height:20px;"><p style="float:left;height:20px;line-height:20px;margin: 0px 0px 0px 5px; color:#939393;"> 冀ICP备2021025381号-1</p></a></div><div><a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=13060602001430" style="display:inline-block;text-decoration:none;height:20px;line-height:20px;"><img src="/img/beian.png" style="float:left;"/><p style="float:left;height:20px;line-height:20px;margin: 0px 0px 0px 5px; color:#939393;">冀公网安备 13060602001430号</p></a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="Switch Between Traditional Chinese And Simplified Chinese">繁</button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.spacingElementById('content-inner')
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.spacingElementById('content-inner')
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> {preloader.endLoading()})</script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>if (document.getElementsByClassName('mermaid').length) {
  if (window.mermaidJsLoad) mermaid.init()
  else {
    getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(() => {
      window.mermaidJsLoad = true
      mermaid.initialize({
        theme: 'neutral',
      })
      false && mermaid.init()
    })
  }
}</script><script>function loadValine () {
  function initValine () {
    let initData = {
      el: '#vcomment',
      appId: 'A9RWVELPcIotgfbpp9KLGXQM-gzGzoHsz',
      appKey: 'MLgPQW5h0DPgE8jNkeREKubU',
      placeholder: '欢迎留言呀。（网址是选填，可以留空）',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'zh-CN',
      recordIP: true,
      serverURLs: 'https://a9rwvelp.lc-cn-n1-shared.com',
      emojiCDN: 'https://cdn.jsdelivr.net/gh/GamerNoTitle/ValineCDN@master/',
      emojiMaps: {"QQ1":"QQ/aini.gif","QQ2":"QQ/aixin.gif","QQ3":"QQ/aoman.gif","QQ4":"QQ/baiyan.gif","QQ5":"QQ/bangbangtang.gif","QQ6":"QQ/baojin.gif","QQ7":"QQ/baoquan.gif","QQ8":"QQ/bishi.gif","QQ9":"QQ/bizui.gif","QQ11":"QQ/cahan.gif","QQ12":"QQ/caidao.gif","QQ13":"QQ/chi.gif","QQ14":"QQ/ciya.gif","QQ15":"QQ/dabing.gif","QQ16":"QQ/daku.gif","QQ17":"QQ/dan.gif","QQ18":"QQ/deyi.gif","QQ19":"QQ/doge.gif","QQ20":"QQ/fadai.gif","QQ21":"QQ/fanu.gif","QQ22":"QQ/fendou.gif","QQ23":"QQ/ganga.gif","QQ24":"QQ/gouyin.gif","QQ25":"QQ/guzhang.gif","QQ26":"QQ/haixiu.gif","QQ27":"QQ/hanxiao.gif","QQ28":"QQ/haobang.gif","QQ29":"QQ/haqian.gif","QQ30":"QQ/hecai.gif","QQ31":"QQ/hexie.gif","QQ32":"QQ/huaixiao.gif","QQ33":"QQ/jie.gif","QQ34":"QQ/jingkong.gif","QQ35":"QQ/jingxi.gif","QQ36":"QQ/jingya.gif","QQ37":"QQ/juhua.gif","QQ38":"QQ/keai.gif","QQ39":"QQ/kelian.gif","QQ40":"QQ/koubi.gif","QQ41":"QQ/ku.gif","QQ42":"QQ/kuaikule.gif","QQ43":"QQ/kulou.gif","QQ44":"QQ/kun.gif","QQ45":"QQ/lanqiu.gif","QQ46":"QQ/leiben.gif","QQ47":"QQ/lenghan.gif","QQ48":"QQ/liuhan.gif","QQ49":"QQ/liulei.gif","QQ50":"QQ/nanguo.gif","QQ51":"QQ/OK.gif","QQ52":"QQ/penxue.gif","QQ53":"QQ/piezui.gif","QQ54":"QQ/pijiu.gif","QQ55":"QQ/qiang.gif","QQ56":"QQ/qiaoda.gif","QQ57":"QQ/qinqin.gif","QQ58":"QQ/qiudale.gif","QQ59":"QQ/quantou.gif","QQ60":"QQ/saorao.gif","QQ61":"QQ/se.gif","QQ62":"QQ/shengli.gif","QQ63":"QQ/shouqiang.gif","QQ64":"QQ/shuai.gif","QQ65":"QQ/shui.gif","QQ66":"QQ/tiaopi.gif","QQ67":"QQ/touxiao.gif","QQ68":"QQ/tu.gif","QQ69":"QQ/tuosai.gif","QQ70":"QQ/weiqu.gif","QQ71":"QQ/weixiao.gif","QQ72":"QQ/woshou.gif","QQ73":"QQ/wozuimei.gif","QQ74":"QQ/wunai.gif","QQ75":"QQ/xia.gif","QQ76":"QQ/xiaojiujie.gif","QQ77":"QQ/xiaoku.gif","QQ78":"QQ/xiaoyanger.gif","QQ79":"QQ/xieyanxiao.gif","QQ80":"QQ/xigua.gif","QQ81":"QQ/xu.gif","QQ82":"QQ/yangtuo.gif","QQ83":"QQ/yinxian.gif","QQ84":"QQ/yiwen.gif","QQ85":"QQ/youhengheng.gif","QQ86":"QQ/youling.gif","QQ87":"QQ/yun.gif","QQ88":"QQ/zaijian.gif","QQ89":"QQ/zhayanjian.gif","QQ90":"QQ/zhemo.gif","QQ91":"QQ/zhouma.gif","QQ92":"QQ/zhuakuang.gif","QQ93":"QQ/zuohengheng.gif","bilibiliHotKey1":"bilibiliHotKey/1.jpg","bilibiliHotKey2":"bilibiliHotKey/10.jpg","bilibiliHotKey3":"bilibiliHotKey/11.jpg","bilibiliHotKey4":"bilibiliHotKey/12.jpg","bilibiliHotKey5":"bilibiliHotKey/13.jpg","bilibiliHotKey6":"bilibiliHotKey/14.jpg","bilibiliHotKey7":"bilibiliHotKey/15.jpg","bilibiliHotKey8":"bilibiliHotKey/16.jpg","bilibiliHotKey9":"bilibiliHotKey/17.jpg","bilibiliHotKey10":"bilibiliHotKey/18.jpg","bilibiliHotKey11":"bilibiliHotKey/19.jpg","bilibiliHotKey12":"bilibiliHotKey/2.jpg","bilibiliHotKey13":"bilibiliHotKey/20.jpg","bilibiliHotKey14":"bilibiliHotKey/21.jpg","bilibiliHotKey15":"bilibiliHotKey/22.jpg","bilibiliHotKey16":"bilibiliHotKey/23.jpg","bilibiliHotKey17":"bilibiliHotKey/24.jpg","bilibiliHotKey18":"bilibiliHotKey/25.jpg","bilibiliHotKey19":"bilibiliHotKey/26.jpg","bilibiliHotKey20":"bilibiliHotKey/27.jpg","bilibiliHotKey21":"bilibiliHotKey/28.jpg","bilibiliHotKey22":"bilibiliHotKey/29.jpg","bilibiliHotKey23":"bilibiliHotKey/3.jpg","bilibiliHotKey24":"bilibiliHotKey/30.jpg","bilibiliHotKey25":"bilibiliHotKey/31.jpg","bilibiliHotKey26":"bilibiliHotKey/32.jpg","bilibiliHotKey27":"bilibiliHotKey/4.jpg","bilibiliHotKey28":"bilibiliHotKey/5.jpg","bilibiliHotKey29":"bilibiliHotKey/6.jpg","bilibiliHotKey30":"bilibiliHotKey/7.jpg","bilibiliHotKey31":"bilibiliHotKey/8.jpg","bilibiliHotKey32":"bilibiliHotKey/9.jpg","Menhera-chan1":"Menhera-chan/1.jpg","Menhera-chan2":"Menhera-chan/10.jpg","Menhera-chan3":"Menhera-chan/100.jpg","Menhera-chan4":"Menhera-chan/101.jpg","Menhera-chan5":"Menhera-chan/102.jpg","Menhera-chan6":"Menhera-chan/103.jpg","Menhera-chan7":"Menhera-chan/104.jpg","Menhera-chan8":"Menhera-chan/105.jpg","Menhera-chan9":"Menhera-chan/106.jpg","Menhera-chan10":"Menhera-chan/107.jpg","Menhera-chan11":"Menhera-chan/108.jpg","Menhera-chan12":"Menhera-chan/109.jpg","Menhera-chan13":"Menhera-chan/11.jpg","Menhera-chan14":"Menhera-chan/110.jpg","Menhera-chan15":"Menhera-chan/111.jpg","Menhera-chan16":"Menhera-chan/112.jpg","Menhera-chan17":"Menhera-chan/113.jpg","Menhera-chan18":"Menhera-chan/114.jpg","Menhera-chan19":"Menhera-chan/115.jpg","Menhera-chan20":"Menhera-chan/116.jpg","Menhera-chan21":"Menhera-chan/117.jpg","Menhera-chan22":"Menhera-chan/118.jpg","Menhera-chan23":"Menhera-chan/119.jpg","Menhera-chan24":"Menhera-chan/12.jpg","Menhera-chan25":"Menhera-chan/120.jpg","Menhera-chan26":"Menhera-chan/13.jpg","Menhera-chan27":"Menhera-chan/14.jpg","Menhera-chan28":"Menhera-chan/15.jpg","Menhera-chan29":"Menhera-chan/16.jpg","Menhera-chan30":"Menhera-chan/17.jpg","Menhera-chan31":"Menhera-chan/18.jpg","Menhera-chan32":"Menhera-chan/19.jpg","Menhera-chan33":"Menhera-chan/2.jpg","Menhera-chan34":"Menhera-chan/20.jpg","Menhera-chan35":"Menhera-chan/21.jpg","Menhera-chan36":"Menhera-chan/22.jpg","Menhera-chan37":"Menhera-chan/23.jpg","Menhera-chan38":"Menhera-chan/24.jpg","Menhera-chan39":"Menhera-chan/25.jpg","Menhera-chan40":"Menhera-chan/26.jpg","Menhera-chan41":"Menhera-chan/27.jpg","Menhera-chan42":"Menhera-chan/28.jpg","Menhera-chan43":"Menhera-chan/29.jpg","Menhera-chan44":"Menhera-chan/3.jpg","Menhera-chan45":"Menhera-chan/30.jpg","Menhera-chan46":"Menhera-chan/31.jpg","Menhera-chan47":"Menhera-chan/32.jpg","Menhera-chan48":"Menhera-chan/33.jpg","Menhera-chan49":"Menhera-chan/34.jpg","Menhera-chan50":"Menhera-chan/35.jpg","Menhera-chan51":"Menhera-chan/36.jpg","Menhera-chan52":"Menhera-chan/37.jpg","Menhera-chan53":"Menhera-chan/38.jpg","Menhera-chan54":"Menhera-chan/39.jpg","Menhera-chan55":"Menhera-chan/4.jpg","Menhera-chan56":"Menhera-chan/40.jpg","Menhera-chan57":"Menhera-chan/41.jpg","Menhera-chan58":"Menhera-chan/42.jpg","Menhera-chan59":"Menhera-chan/43.jpg","Menhera-chan60":"Menhera-chan/44.jpg","Menhera-chan61":"Menhera-chan/45.jpg","Menhera-chan62":"Menhera-chan/46.jpg","Menhera-chan63":"Menhera-chan/47.jpg","Menhera-chan64":"Menhera-chan/48.jpg","Menhera-chan65":"Menhera-chan/49.jpg","Menhera-chan66":"Menhera-chan/5.jpg","Menhera-chan67":"Menhera-chan/50.jpg","Menhera-chan68":"Menhera-chan/51.jpg","Menhera-chan69":"Menhera-chan/52.jpg","Menhera-chan70":"Menhera-chan/53(1).jpg","Menhera-chan71":"Menhera-chan/53.jpg","Menhera-chan72":"Menhera-chan/54.jpg","Menhera-chan73":"Menhera-chan/55.jpg","Menhera-chan74":"Menhera-chan/56.jpg","Menhera-chan75":"Menhera-chan/57.jpg","Menhera-chan76":"Menhera-chan/58.jpg","Menhera-chan77":"Menhera-chan/59.jpg","Menhera-chan78":"Menhera-chan/6.jpg","Menhera-chan79":"Menhera-chan/60.jpg","Menhera-chan80":"Menhera-chan/61.jpg","Menhera-chan81":"Menhera-chan/62.jpg","Menhera-chan82":"Menhera-chan/63.jpg","Menhera-chan83":"Menhera-chan/64.jpg","Menhera-chan84":"Menhera-chan/65.jpg","Menhera-chan85":"Menhera-chan/66.jpg","Menhera-chan86":"Menhera-chan/67.jpg","Menhera-chan87":"Menhera-chan/68.jpg","Menhera-chan88":"Menhera-chan/69.jpg","Menhera-chan89":"Menhera-chan/7.jpg","Menhera-chan90":"Menhera-chan/70.jpg","Menhera-chan91":"Menhera-chan/71.jpg","Menhera-chan92":"Menhera-chan/72.jpg","Menhera-chan93":"Menhera-chan/73.jpg","Menhera-chan94":"Menhera-chan/74.jpg","Menhera-chan95":"Menhera-chan/75.jpg","Menhera-chan96":"Menhera-chan/76.jpg","Menhera-chan97":"Menhera-chan/77.jpg","Menhera-chan98":"Menhera-chan/78.jpg","Menhera-chan99":"Menhera-chan/79.jpg","Menhera-chan100":"Menhera-chan/8.jpg","Menhera-chan101":"Menhera-chan/80.jpg","Menhera-chan102":"Menhera-chan/81.jpg","Menhera-chan103":"Menhera-chan/82.jpg","Menhera-chan104":"Menhera-chan/83.jpg","Menhera-chan105":"Menhera-chan/84.jpg","Menhera-chan106":"Menhera-chan/85.jpg","Menhera-chan107":"Menhera-chan/86.jpg","Menhera-chan108":"Menhera-chan/87.jpg","Menhera-chan109":"Menhera-chan/88.jpg","Menhera-chan110":"Menhera-chan/89.jpg","Menhera-chan111":"Menhera-chan/9.jpg","Menhera-chan112":"Menhera-chan/90.jpg","Menhera-chan113":"Menhera-chan/91.jpg","Menhera-chan114":"Menhera-chan/92.jpg","Menhera-chan115":"Menhera-chan/93.jpg","Menhera-chan116":"Menhera-chan/94.jpg","Menhera-chan117":"Menhera-chan/95.jpg","Menhera-chan118":"Menhera-chan/96.jpg","Menhera-chan119":"Menhera-chan/97.jpg","Menhera-chan120":"Menhera-chan/98.jpg","Menhera-chan121":"Menhera-chan/99.jpg","Sweetie-Bunny1":"Sweetie-Bunny/12311678.png","Sweetie-Bunny2":"Sweetie-Bunny/12311679.png","Sweetie-Bunny3":"Sweetie-Bunny/12311680.png","Sweetie-Bunny4":"Sweetie-Bunny/12311681.png","Sweetie-Bunny5":"Sweetie-Bunny/12311682.png","Sweetie-Bunny6":"Sweetie-Bunny/12311683.png","Sweetie-Bunny7":"Sweetie-Bunny/12311684.png","Sweetie-Bunny8":"Sweetie-Bunny/12311685.png","Sweetie-Bunny9":"Sweetie-Bunny/12311686.png","Sweetie-Bunny10":"Sweetie-Bunny/12311687.png","Sweetie-Bunny11":"Sweetie-Bunny/12311688.png","Sweetie-Bunny12":"Sweetie-Bunny/12311689.png","Sweetie-Bunny13":"Sweetie-Bunny/12311690.png","Sweetie-Bunny14":"Sweetie-Bunny/12311691.png","Sweetie-Bunny15":"Sweetie-Bunny/12311692.png","Sweetie-Bunny16":"Sweetie-Bunny/12311693.png","Sweetie-Bunny17":"Sweetie-Bunny/12311694.png","Sweetie-Bunny18":"Sweetie-Bunny/12311695.png","Sweetie-Bunny19":"Sweetie-Bunny/12311696.png","Sweetie-Bunny20":"Sweetie-Bunny/12311697.png","Sweetie-Bunny21":"Sweetie-Bunny/12311698.png","Sweetie-Bunny22":"Sweetie-Bunny/12311699.png","Sweetie-Bunny23":"Sweetie-Bunny/12311700.png","Sweetie-Bunny24":"Sweetie-Bunny/12311701.png","Sweetie-Bunny25":"Sweetie-Bunny/12311702.png","Sweetie-Bunny26":"Sweetie-Bunny/12311703.png","Sweetie-Bunny27":"Sweetie-Bunny/12311704.png","Sweetie-Bunny28":"Sweetie-Bunny/12311705.png","Sweetie-Bunny29":"Sweetie-Bunny/12311706.png","Sweetie-Bunny30":"Sweetie-Bunny/12311707.png","Sweetie-Bunny31":"Sweetie-Bunny/12311708.png","Sweetie-Bunny32":"Sweetie-Bunny/12311709.png","Sweetie-Bunny33":"Sweetie-Bunny/12311710.png","Sweetie-Bunny34":"Sweetie-Bunny/12311711.png","Sweetie-Bunny35":"Sweetie-Bunny/12311712.png","Sweetie-Bunny36":"Sweetie-Bunny/12311713.png","Sweetie-Bunny37":"Sweetie-Bunny/12311714.png","Sweetie-Bunny38":"Sweetie-Bunny/12311715.png","Sweetie-Bunny39":"Sweetie-Bunny/12311716.png","Sweetie-Bunny40":"Sweetie-Bunny/12311717.png","Majotabi1":"Majotabi/367516718.png","Majotabi2":"Majotabi/367516719.png","Majotabi3":"Majotabi/367516720.png","Majotabi4":"Majotabi/367516721.png","Majotabi5":"Majotabi/367516722.png","Majotabi6":"Majotabi/367516723.png","Majotabi7":"Majotabi/367516724.png","Majotabi8":"Majotabi/367516725.png","Majotabi9":"Majotabi/367516726.png","Majotabi10":"Majotabi/367516727.png","Majotabi11":"Majotabi/367516728.png","Majotabi12":"Majotabi/367516729.png","Majotabi13":"Majotabi/367516730.png","Majotabi14":"Majotabi/367516731.png","Majotabi15":"Majotabi/367516732.png","Majotabi16":"Majotabi/367516733.png","Majotabi17":"Majotabi/367516734.png","Majotabi18":"Majotabi/367516735.png","Majotabi19":"Majotabi/367516736.png","Majotabi20":"Majotabi/367516737.png","Majotabi21":"Majotabi/367516738.png","Majotabi22":"Majotabi/367516739.png","Majotabi23":"Majotabi/367516740.png","Majotabi24":"Majotabi/367516741.png","Majotabi25":"Majotabi/367516742.png","Majotabi26":"Majotabi/367516743.png","Majotabi27":"Majotabi/367516744.png","Majotabi28":"Majotabi/367516745.png","Majotabi29":"Majotabi/367516746.png","Majotabi30":"Majotabi/367516747.png","Majotabi31":"Majotabi/367516748.png","Majotabi32":"Majotabi/367516749.png","Majotabi33":"Majotabi/367516750.png","Majotabi34":"Majotabi/367516751.png","Majotabi35":"Majotabi/367516752.png","Majotabi36":"Majotabi/367516753.png","Majotabi37":"Majotabi/367516754.png","Majotabi38":"Majotabi/367516755.png","Majotabi39":"Majotabi/367516756.png","Majotabi40":"Majotabi/367516757.png","Snow-Miku1":"Snow-Miku/3583066@2x.png","Snow-Miku2":"Snow-Miku/3583067@2x.png","Snow-Miku3":"Snow-Miku/3583068@2x.png","Snow-Miku4":"Snow-Miku/3583069@2x.png","Snow-Miku5":"Snow-Miku/3583070@2x.png","Snow-Miku6":"Snow-Miku/3583071@2x.png","Snow-Miku7":"Snow-Miku/3583072@2x.png","Snow-Miku8":"Snow-Miku/3583073@2x.png","Snow-Miku9":"Snow-Miku/3583074@2x.png","Snow-Miku10":"Snow-Miku/3583075@2x.png","Snow-Miku11":"Snow-Miku/3583076@2x.png","Snow-Miku12":"Snow-Miku/3583077@2x.png","Snow-Miku13":"Snow-Miku/3583078@2x.png","Snow-Miku14":"Snow-Miku/3583079@2x.png","Snow-Miku15":"Snow-Miku/3583080@2x.png","Snow-Miku16":"Snow-Miku/3583081@2x.png","Snow-Miku17":"Snow-Miku/3583082@2x.png","Snow-Miku18":"Snow-Miku/3583083@2x.png","Snow-Miku19":"Snow-Miku/3583084@2x.png","Snow-Miku20":"Snow-Miku/3583085@2x.png","Snow-Miku21":"Snow-Miku/3583086@2x.png","Snow-Miku22":"Snow-Miku/3583087@2x.png","Snow-Miku23":"Snow-Miku/3583088@2x.png","Snow-Miku24":"Snow-Miku/3583089@2x.png","Snow-Miku25":"Snow-Miku/3583090@2x.png","Snow-Miku26":"Snow-Miku/3583091@2x.png","Snow-Miku27":"Snow-Miku/3583092@2x.png","Snow-Miku28":"Snow-Miku/3583093@2x.png","Snow-Miku29":"Snow-Miku/3583094@2x.png","Snow-Miku30":"Snow-Miku/3583095@2x.png","Snow-Miku31":"Snow-Miku/3583096@2x.png","Snow-Miku32":"Snow-Miku/3583097@2x.png","Snow-Miku33":"Snow-Miku/3583098@2x.png","Snow-Miku34":"Snow-Miku/3583099@2x.png","Snow-Miku35":"Snow-Miku/3583100@2x.png","Snow-Miku36":"Snow-Miku/3583101@2x.png","Snow-Miku37":"Snow-Miku/3583102@2x.png","Snow-Miku38":"Snow-Miku/3583103@2x.png","Snow-Miku39":"Snow-Miku/3583104@2x.png","Snow-Miku40":"Snow-Miku/3583105@2x.png"},
      enableQQ: true,
      path: window.location.pathname,
    }

    if (true) { 
      initData.requiredFields= ('nick,mail'.split(','))
    }
    
    if (false) {
      const otherData = false
      initData = Object.assign({}, initData, otherData)
    }
    
    const valine = new Valine(initData)
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.querySelector('#vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script>(function(){
  const bp = document.createElement('script');
  const curProtocol = window.location.protocol.split(':')[0];
  if (curProtocol === 'https') {
    bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
  }
  else{
    bp.src = 'http://push.zhanzhang.baidu.com/push.js';
  }
  bp.dataset.pjax = ''
  const s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(bp, s);
})()</script></div></body></html>