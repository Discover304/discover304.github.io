<!DOCTYPE html><html lang="en" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>【深度学习】光学字符识别（OCR） | Yang's Harbor</title><meta name="keywords" content="学习,记录,Python,笔记,深度学习"><meta name="author" content="✨YangSier✨,hobart.yang@qq.com"><meta name="copyright" content="✨YangSier✨"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="一、基本理论1. 什么是OCR1）定义OCR （Optical Character Recognition，光学字符识别）是指对图片中的文字进行查找、提取、识别的一种技术，通过检测暗、亮的模式确定其形状，然后用字符识别方法将形状翻译成计算机文字的过程。 2）一般步骤 文字检测：解决的问题是哪里有文字，文字的范围有多少 文字识别：对定位好的文字区域进行识别，主要解决的问题是每个文字是什么，将图像中的">
<meta property="og:type" content="article">
<meta property="og:title" content="【深度学习】光学字符识别（OCR）">
<meta property="og:url" content="https://discover304.top/2021/12/13/2021q4/113-1-dl-ocr/index.html">
<meta property="og:site_name" content="Yang&#39;s Harbor">
<meta property="og:description" content="一、基本理论1. 什么是OCR1）定义OCR （Optical Character Recognition，光学字符识别）是指对图片中的文字进行查找、提取、识别的一种技术，通过检测暗、亮的模式确定其形状，然后用字符识别方法将形状翻译成计算机文字的过程。 2）一般步骤 文字检测：解决的问题是哪里有文字，文字的范围有多少 文字识别：对定位好的文字区域进行识别，主要解决的问题是每个文字是什么，将图像中的">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://img2.huashi6.com/images/resource/thumbnail/2021/12/05/1496_54694744582.jpg?imageMogr2/quality/100/interlace/1/thumbnail/1000x%3E">
<meta property="article:published_time" content="2021-12-13T00:56:03.000Z">
<meta property="article:modified_time" content="2021-12-25T06:39:02.000Z">
<meta property="article:author" content="✨YangSier✨">
<meta property="article:tag" content="学习">
<meta property="article:tag" content="记录">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="笔记">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img2.huashi6.com/images/resource/thumbnail/2021/12/05/1496_54694744582.jpg?imageMogr2/quality/100/interlace/1/thumbnail/1000x%3E"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://discover304.top/2021/12/13/2021q4/113-1-dl-ocr/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="preconnect" href="//zz.bdstatic.com"/><meta name="google-site-verification" content="ilqpfk3vkgzDNNikz_V37-DOvRyi5wv4Hoi_eyBqvTg"/><meta name="msvalidate.01" content="49D9A50CCF9744E17274791468EDB517"/><meta name="baidu-site-verification" content="code-V24KosyVh1"/><meta name="360-site-verification" content="bd8859c3d74dfa3e8aeee9db30c94bd2"/><meta name="yandex-verification" content="f28ec9bbd50c56f5"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8030f6052f2fed6a4704d96619f090d6";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><link rel="stylesheet" href="/css/font.css" media="print" onload="this.media='all'"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'days',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: {"limitCount":200,"languages":{"author":"Author: ✨YangSier✨","link":"Link: ","source":"Source: Yang's Harbor","info":"Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source."}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"Traditional Chinese Activated Manually","cht_to_chs":"Simplified Chinese Activated Manually","day_to_night":"Dark Mode Activated Manually","night_to_day":"Light Mode Activated Manually","bgLight":"#ffc910","bgDark":"#02c3f6","position":"bottom-left"},
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isanchor: true
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}

// https://stackoverflow.com/questions/16839698/jquery-getscript-alternative-in-native-javascript
const getScript = url => new Promise((resolve, reject) => {
  const script = document.createElement('script')
  script.src = url
  script.async = true
  script.onerror = reject
  script.onload = script.onreadystatechange = function() {
    const loadState = this.readyState
    if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
    script.onload = script.onreadystatechange = null
    resolve()
  }
  document.head.appendChild(script)
})</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-12-25 14:39:02'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
   if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }
  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified
    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }const asideStatus = saveToLocal.get('aside-status')
if (asideStatus !== undefined) {
   if (asideStatus === 'hide') {
     document.documentElement.classList.add('hide-aside')
   } else {
     document.documentElement.classList.remove('hide-aside')
   }
}})()</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Yang's Harbor" type="application/atom+xml">
</head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/head.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">244</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">88</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">24</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Links</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> Articles</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archive</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Category</span></a></li><li><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></li></ul></div></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://img2.huashi6.com/images/resource/thumbnail/2021/12/05/1496_54694744582.jpg?imageMogr2/quality/100/interlace/1/thumbnail/1000x%3E)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Yang's Harbor</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Links</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> Articles</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archive</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Category</span></a></li><li><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">【深度学习】光学字符识别（OCR）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2021-12-13T00:56:03.000Z" title="Created 2021-12-13 08:56:03">2021-12-13</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2021-12-25T06:39:02.000Z" title="Updated 2021-12-25 14:39:02">2021-12-25</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/NoteBook/">NoteBook</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/NoteBook/PythonNote/">PythonNote</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">6.5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>20min</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="一、基本理论"><a href="#一、基本理论" class="headerlink" title="一、基本理论"></a>一、基本理论</h2><h3 id="1-什么是OCR"><a href="#1-什么是OCR" class="headerlink" title="1. 什么是OCR"></a>1. 什么是OCR</h3><h4 id="1）定义"><a href="#1）定义" class="headerlink" title="1）定义"></a>1）定义</h4><p>OCR （Optical Character Recognition，光学字符识别）是指对图片中的文字进行查找、提取、识别的一种技术，通过检测暗、亮的模式确定其形状，然后用字符识别方法将形状翻译成计算机文字的过程。</p>
<h4 id="2）一般步骤"><a href="#2）一般步骤" class="headerlink" title="2）一般步骤"></a>2）一般步骤</h4><ul>
<li>文字检测：解决的问题是哪里有文字，文字的范围有多少</li>
<li>文字识别：对定位好的文字区域进行识别，主要解决的问题是每个文字是什么，将图像中的文字区域进转化为字符信息。</li>
</ul>
<p><img src="https://image.discover304.top/dl/advcv/OCR%E4%B8%80%E8%88%AC%E6%AD%A5%E9%AA%A4.png" alt="OCR一般步骤"></p>
<p><img src="https://image.discover304.top/dl/advcv/OCR_Detection_recorgnize.png" alt="OCR_Detection_recorgnize"></p>
<h4 id="3）OCR的难点"><a href="#3）OCR的难点" class="headerlink" title="3）OCR的难点"></a>3）OCR的难点</h4><p>文本检测，尤其是复杂自然场景下的文本检测，非常具有挑战性，主要难点有：</p>
<ul>
<li>文本存在多种分布，文本排布形式多样；</li>
<li>文本大小、长度不固定；</li>
<li>文本存在多个方向；</li>
<li>多种语言混合。</li>
</ul>
<h4 id="4）OCR与目标检测的区别"><a href="#4）OCR与目标检测的区别" class="headerlink" title="4）OCR与目标检测的区别"></a>4）OCR与目标检测的区别</h4><ul>
<li>文本大多数以长矩形形式存在，即长宽比一般较大或较小，这与普通的目标检测中的物体不一样（这些长宽比较接近1）</li>
<li>普通物体（比如猫）存在明显的闭合边缘轮廓，而文本没有</li>
<li>文本中包含多个文字，而文字之间是有间隔的，如果检测做得不好，我们就会把每个字都当成文本行给框出来而非整行作为文本框，这与我们的期望不一样</li>
</ul>
<h4 id="5）评估指标"><a href="#5）评估指标" class="headerlink" title="5）评估指标"></a>5）评估指标</h4><ul>
<li>拒识率：把应该识别的文字，当成不能识别的文字</li>
<li>误识率：不应该作为文字的作为文字来识别</li>
<li>识别速度：一般可接受范围在50~500ms</li>
<li>稳定性：识别结果稳定性</li>
</ul>
<h4 id="6）应用"><a href="#6）应用" class="headerlink" title="6）应用"></a>6）应用</h4><ul>
<li>文档&#x2F;书籍扫描、车牌识别、证件识别、卡识别、票据识别</li>
<li>教育场景文字识别（例如拍照搜题）</li>
<li>文字识别笔</li>
<li>旅游翻译APP</li>
<li>盲人相机</li>
<li>自动导航</li>
</ul>
<h2 id="二、文字检测技术"><a href="#二、文字检测技术" class="headerlink" title="二、文字检测技术"></a>二、文字检测技术</h2><h3 id="1-CTPN（2016）"><a href="#1-CTPN（2016）" class="headerlink" title="1. CTPN（2016）"></a>1. CTPN（2016）</h3><h4 id="1）概述"><a href="#1）概述" class="headerlink" title="1）概述"></a>1）概述</h4><p>CTPN全称Detecting Text in Natural Image with Connectionist Text Proposal Network（基于连接文本提议网络的自然图像文本检测），是发表于2016年的用于OCR的一篇著名论文。直到今天这个网络框架一直是OCR系统中做文本检测的一个常用网络，极大地影响了后面文本检测算法的方向。该模型在自然环境下水平文字的检测方面有这良好的表现。其基本思想是先使用固定宽度（16像素）的小文本框对图像进行检测，得到一系列含有文字的区域，然后对这些区域进行合并，合并成大的、完整的文本框。</p>
<h4 id="2）具体步骤"><a href="#2）具体步骤" class="headerlink" title="2）具体步骤"></a>2）具体步骤</h4><p>CTPN主要包含以下几个步骤：</p>
<ul>
<li>检测文本。使用固定宽度为16像素的小区域（proposal）在原图像上移动检测，每个proposal使用10个锚点高度在11~273之间（每次除以0.7）。检测器在每个窗口位置输出k个锚点的文本&#x2F;非文本分数和预测的y轴坐标（v）；</li>
</ul>
<p><img src="https://image.discover304.top/dl/advcv/CTPN_%E5%9B%BE2.png" alt="CTPN_图2"></p>
<center><font size=2>左：RPN提议。右：细粒度的文本提议。</font></center>

<ul>
<li><p>利用RNN连接多个proposal。检测出文本区域后，将这些小的文本区域进行连接。为了避免对与文本模式类似的非文本目标（窗口，砖块，树叶等）的误检，使用了双向LSTM（LSTM是RNN变种）利用前后两个方向上的信息对proposal进行连接。引入RNN进行连接操作，大大减少了错误检测，同时还能够恢复很多包含非常弱的文本信息的遗漏文本proposal；</p>
</li>
<li><p>边沿细化。完成连接后，对边沿进行细化处理，当两个水平边的proposal没有完全被实际文本行区域覆盖，或者某些边的提议被丢弃。通过连接其文本&#x2F;非文本分数为&gt;0.7的连续文本提议，文本行的构建非常简单。</p>
<p><img src="https://image.discover304.top/dl/advcv/CTPN_%E5%85%AC%E5%BC%8F4.png" alt="CTPN_公式4"></p>
</li>
<li><p>文本行构建如下：首先，我们为提议$(B_j)$定义一个配对邻居作$(B_i)$为$B_j−&gt;B_i$，当（i）是最接$(B_j)$近$(B_i)$的水平距离，（ii）该距离小于50像素，并且（iii）它们的垂直重叠是&gt;0.7时。其次，如果$B_j−&gt;B_i$和$B_i−&gt;B_j$，则将两个提议分组为一对。然后通过顺序连接具有相同提议的对来构建文本行；</p>
</li>
</ul>
<p><img src="https://image.discover304.top/dl/advcv/CTPN_%E5%9B%BE4.png" alt="CTPN_图4"></p>
<center><font size=2>CTPN检测有（红色框）和没有（黄色虚线框）边缘细化。细粒度提议边界框的颜色表示文本/非文本分数。</font></center>

<h4 id="3）网络结构"><a href="#3）网络结构" class="headerlink" title="3）网络结构"></a>3）网络结构</h4><p><img src="https://image.discover304.top/dl/advcv/CTPN_%E5%9B%BE1.png" alt="CTPN_图1"></p>
<ul>
<li>VGG16+Conv5：CTPN的基础网络使用了VGG16用于特征提取，在VGG的最后一个卷积层Conv5，CTPN用了3×3的卷积核来对该feature map做卷积，这个Conv5 特征图的尺寸由输入图像来决定，而卷积时的步长却限定为16，感受野被固定为228个像素；</li>
<li>卷积后的特征将送入BLSTM继续学习，最后接上一层全连接层FC输出我们要预测的参数：2K个纵向坐标y，2k个分数，k个x的水平偏移量。</li>
</ul>
<h4 id="4）损失函数"><a href="#4）损失函数" class="headerlink" title="4）损失函数"></a>4）损失函数</h4><p>CTPN有三个输出共同连接到最后的FC层，这三个输出同时预测文本&#x2F;非文本分数（s），垂直坐标（$v&#x3D;\lbrace v_c,v_h \rbrace$）和边缘细化偏移（o）。损失函数形式为：</p>
<p><img src="https://image.discover304.top/dl/advcv/CTPN_%E5%85%AC%E5%BC%8F5.png" alt="CTPN_公式5"></p>
<p>其中每个锚点都是一个训练样本，i是一个小批量数据中一个锚点的索引。$s_i$是预测的锚点i作为实际文本的预测概率。$s_i^*&#x3D; \lbrace 0,1 \rbrace$是真实值。j是y坐标回归中有效锚点集合中锚点的索引，定义如下。有效的锚点是定义的正锚点($s_j^*&#x3D;1$，如下所述），或者与实际文本提议重叠的交并比（IoU）&gt;0.5。$v_j$和$v_j^*$是与第j个锚点关联的预测的和真实的y坐标。k是边缘锚点的索引，其被定义为在实际文本行边界框的左侧或右侧水平距离（例如32个像素）内的一组锚点。$o_k$和$o_k^*$是与第k个锚点关联的x轴的预测和实际偏移量$L^{cl}_s$是我们使用Softmax损失区分文本和非文本的分类损失。$L^{re}_v$和$L^{re}_o$是回归损失。$\lambda_1$和$\lambda_2$是损失权重，用来平衡不同的任务，将它们经验地设置为1.0和2.0。$N_s,N_v,N_o$是标准化参数，表示$L^{cl}_s，L^{re}_v，L^{re}_o$分别使用的锚点总数。</p>
<h4 id="5）性能"><a href="#5）性能" class="headerlink" title="5）性能"></a>5）性能</h4><h5 id="①-时间性能"><a href="#①-时间性能" class="headerlink" title="① 时间性能"></a>① 时间性能</h5><p>使用单个GPU，CTPN（用于整个检测处理）的执行时间为每张图像大约0.14s。没有RNN连接的CTPN每张图像GPU时间大约需要0.13s。因此，所提出的网内循环机制稍微增加了模型计算，并获得了相当大的性能增益。</p>
<h5 id="②-准确率"><a href="#②-准确率" class="headerlink" title="② 准确率"></a>② 准确率</h5><p>CTPN在自然环境下的文字检测中取得了优异的效果。如下图所示：</p>
<p><img src="https://image.discover304.top/dl/advcv/CTPN_%E5%9B%BE5.png" alt="CTPN_图5"></p>
<p>CTPN在五个基准数据集上进行了全面评估。在ICDAR 2013上，它的性能优于最近的TextFlow和FASText，将F-measure从0.80提高到了0.88。精确度和召回率都有显著提高，改进分别超过+5%和+7%。CTPN在检测小文本方面也有较好表现。在多个数据集下评估效果如下表所示：</p>
<p><img src="https://image.discover304.top/dl/advcv/CTPN_%E8%A1%A82.png" alt="CTPN_表2"></p>
<h4 id="6）缺陷"><a href="#6）缺陷" class="headerlink" title="6）缺陷"></a>6）缺陷</h4><ul>
<li>针对极小尺度文本检测有遗漏。如下图所示：</li>
</ul>
<p><img src="https://image.discover304.top/dl/advcv/CTPN_%E5%9B%BE6.png" alt="CTPN_图6"></p>
<center><font size=2>在极小尺度的情况下（红色框内）CTPN检测结果，其中一些真实边界框被遗漏。黄色边界箱是真实值。</font></center>

<ul>
<li>对于非水平的文本的检测效果并不好。</li>
</ul>
<h3 id="2-SegLink-2017"><a href="#2-SegLink-2017" class="headerlink" title="2. SegLink(2017)"></a>2. SegLink(2017)</h3><h4 id="1）概述-1"><a href="#1）概述-1" class="headerlink" title="1）概述"></a>1）概述</h4><p>对于普通目标检测，我们并不需要对其做所谓的多方向目标检测。但文本检测任务则不一样，文本的特点就是高宽比特别大或特别小，而且文本通常存在一定的旋转角度，如果我们对于带角度的文本仍然使用通用目标检测思路，通过四个参数（x,y,w,h）来指定一个目标的位置（如下图红色框），显然误差比较大，而绿色框才是理想的检测效果。那如何才能实现带角度的文本检测呢？让模型再学习一个表示角度的参数θ，即模型要回归的参数从原来的(x,y,w,h)变成(x,y,w,h,θ)。</p>
<p><img src="https://image.discover304.top/dl/advcv/%E5%B8%A6%E8%A7%92%E5%BA%A6%E7%9A%84%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B.png" alt="带角度的文本检测"></p>
<p>Seglink是一种多方向文本检测方法，该方法既融入CTPN小尺度候选框的思路，又加入了SSD算法的思路，达到了自然场景下文本检测较好的效果。Seglink核心是将文本检测转换成两个局部元素的检测：segment和link。segment 是一个有方向的box，覆盖文本内容的一部分，而link则连接了两个相邻的segments，表达了这两个segment是否属于同一个文本。该算法通过在多尺度上进行segment和link的检测，最终按照links的表达将相关的segment合并成最终的bounding box。如下图所示。</p>
<p><img src="https://image.discover304.top/dl/advcv/segment%E5%92%8Clink%E8%BF%87%E7%A8%8B.png" alt="segment和link过程"></p>
<h4 id="2）网络结构"><a href="#2）网络结构" class="headerlink" title="2）网络结构"></a>2）网络结构</h4><p>网络使用预先训练的VGG-16网络作为主干（从conv1到pool5）。之后，VGG-16的全连接层被替换为卷积层（fc6替换为conv6；fc7替换为conv7）。接着是一些额外的卷积层（conv8_1到conv11），用于进行多尺度检测。结构如下图所示。</p>
<p><img src="https://image.discover304.top/dl/advcv/SegLink%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84.png" alt="SegLink网络结构"></p>
<p>检测到的定向框称为Segment，用$s&#x3D;（x_s，y_s，w_s，h_s，θ_s）$表示。预测器产生7个通道segment检测。其中，2个通道用来判断有没有文本（分类），其余5个用来计算定向框的几何偏移（回归）。</p>
<h4 id="3）link-链接"><a href="#3）link-链接" class="headerlink" title="3）link(链接)"></a>3）link(链接)</h4><p>在检测到segment之后，会进行link，将segment合在一起。</p>
<ul>
<li>层内链接（with-in layer link）：每个segment检测与其统一特征层周围的8个segment是否同属于一个字，如果属于则链接在一起。</li>
<li>跨层链接（cross layer link）：跨层link使用相邻索引连接两个特征图层上的segment。</li>
</ul>
<p>层内链接和跨层链接示意图如下图所示：</p>
<p><img src="https://image.discover304.top/dl/advcv/SegLink_%E5%9B%BE3.png" alt="SegLink_图3"></p>
<h4 id="4）预测参数表示"><a href="#4）预测参数表示" class="headerlink" title="4）预测参数表示"></a>4）预测参数表示</h4><p>预测器针对每个feature map输出参数总数为（2+5+16+8&#x3D;31）。假设当前的feature map的尺度为(w,h)，那么该层卷积后输出为w×h×31。这些参数包括：</p>
<ul>
<li>每个segment内的分类分数，即判断框内有字符还是无字符的分数（2分类），共2个参数；</li>
<li>segment的位置信息$(x,y,w,h,θ)$，共5个参数；</li>
<li>同层（within-layer）的每个segment的link的分数，表示该方向有link还是没link（2分类问题），而一个segment有八邻域所以有八个方向，参数一共有2×8&#x3D;16；</li>
<li>相邻层(cross-layer)之间也存在link，同样是该方向有link还是没link（2分类问题），而link的个数是4个，所以参数总数为2×4&#x3D;8。如下图所示：</li>
</ul>
<p><img src="https://image.discover304.top/dl/advcv/SegLink_%E5%9B%BE4.png" alt="SegLink_图4"></p>
<h4 id="5）和并segment和link"><a href="#5）和并segment和link" class="headerlink" title="5）和并segment和link"></a>5）和并segment和link</h4><p>网络会生成许多segment和link（数量取决于图像大小），需要将这些segment和link进行合并。合并之前，先根据置信度得分进行过滤。以过滤后的segment为节点，过滤后的link为边，在其上构造一个图。合并算法如下表所示：</p>
<p><img src="https://image.discover304.top/dl/advcv/SegLink_%E7%AE%97%E6%B3%951.png" alt="SegLink_算法1"></p>
<p>合并算法：</p>
<ul>
<li>设有一个集合B，里面有很多相关联的segment待合并；</li>
<li>每一个segment都有角度θ，求集合B中所有segment角度的平均值$θ_b$;</li>
<li>求一条直线L，使得所有segment的中心到这条直线的距离最小（最小二乘法线性回归）；</li>
<li>每个segment的中心向直线L做垂直投影；</li>
<li>从所有投影点中选出相距最远的两个点，记做$（x_p,y_p）$和$（x_q,y_q）$；</li>
<li>最终合并好的文本框的位置参数记为$(x_b,y_b,w_b,h_b,θ_b)$，则</li>
</ul>
<p>$$<br>x_b&#x3D;\frac{x_p + x_q}{2} \<br>y_b&#x3D;\frac{y_q + y_q}{2}<br>$$</p>
<ul>
<li>文本行的宽度$w_b$就是两个最远点的距离（即$(x_p,y_p)$和$(x_q,y_q)）$再加上最远两个点所处的segment的宽度的一半($W_p$和$W_q$)；</li>
<li>文本行高度$h_b$就是所有segment高度求平均值。</li>
</ul>
<p>如下图所示，橙色直线是拟合出的最佳直线，红色点表示segment的中心，黄点表示红点在直线上的投影，绿框就是合并后的完整本文框：</p>
<p><img src="https://image.discover304.top/dl/advcv/segment%E5%92%8Clink%E5%90%88%E5%B9%B6.png" alt="segment和link合并"></p>
<h4 id="6）损失函数"><a href="#6）损失函数" class="headerlink" title="6）损失函数"></a>6）损失函数</h4><p>SegLink所使用的损失函数由三个部分构成，是否是text的二分类的softmax损失，box的smooth L1 regression损失，是否link的二类的softmax损失。λ１和λ２控制权重，最后都设为1。</p>
<p><img src="https://image.discover304.top/dl/advcv/SegLink_%E5%85%AC%E5%BC%8F10.png"></p>
<h4 id="7）性能"><a href="#7）性能" class="headerlink" title="7）性能"></a>7）性能</h4><p>① 英语单语文本检测</p>
<p>英语单语文本检测效果明显好于其它模型。如下表：</p>
<p><img src="https://image.discover304.top/dl/advcv/SegLink_%E8%A1%A81.png" alt="SegLink_表1"></p>
<p>即使在杂乱的背景下也有较好的表现。如图：</p>
<p><img src="https://image.discover304.top/dl/advcv/SegLink_%E5%9B%BE6.png" alt="SegLink_图6"></p>
<p>② 多种语言文本检测</p>
<p>SegLink在多语种场景检测中准确率、速度都有较好表现。如下表所示：</p>
<p><img src="https://image.discover304.top/dl/advcv/SegLink_%E8%A1%A82.png" alt="SegLink_表2"></p>
<p><img src="https://image.discover304.top/dl/advcv/SegLink_%E5%9B%BE7.png" alt="SegLink_图7"></p>
<h4 id="8）局限"><a href="#8）局限" class="headerlink" title="8）局限"></a>8）局限</h4><p>① 水平文字检测效果不及CTPN</p>
<p><img src="https://image.discover304.top/dl/advcv/SegLink_%E8%A1%A83.png" alt="SegLink_表3"></p>
<p>② 无法检测到字符间距非常大的文本和弯曲文本</p>
<p><img src="https://image.discover304.top/dl/advcv/SegLink_%E5%9B%BE8.png" alt="SegLink_图8"></p>
<h2 id="三、文字识别技术"><a href="#三、文字识别技术" class="headerlink" title="三、文字识别技术"></a>三、文字识别技术</h2><h3 id="1-CRNN-CTC-2015"><a href="#1-CRNN-CTC-2015" class="headerlink" title="1. CRNN+CTC(2015)"></a>1. CRNN+CTC(2015)</h3><h4 id="1）特点"><a href="#1）特点" class="headerlink" title="1）特点"></a>1）特点</h4><p>（1）与大多数现有的组件需要单独训练和协调的算法相比，它是端对端训练的。</p>
<p>（2）它自然地处理任意长度的序列，不涉及字符分割或水平尺度归一化。</p>
<p>（3）它不仅限于任何预定义的词汇，并且在无词典和基于词典的场景文本识别任务中都取得了显著的表现。</p>
<p>（4）它产生了一个有效而小得多的模型，这对于现实世界的应用场景更为实用。</p>
<h4 id="2）网络结构-1"><a href="#2）网络结构-1" class="headerlink" title="2）网络结构"></a>2）网络结构</h4><ul>
<li>卷积层：从输入图像中提取特征序列；</li>
<li>循环层：预测每一帧的标签分布；</li>
<li>转录层：将每一帧的预测变为最终的标签序列。</li>
</ul>
<p><img src="https://image.discover304.top/dl/advcv/RCNN_CTC.jpg" alt="RCNN_CTC"></p>
<center><font size=2>图1。网络架构。架构包括三部分：1) 卷积层，从输入图像中提取特征序列；2) 循环层，预测每一帧的标签分布；3) 转录层，将每一帧的预测变为最终的标签序列。</font></center>

<h4 id="3）特征提取"><a href="#3）特征提取" class="headerlink" title="3）特征提取"></a>3）特征提取</h4><p>在CRNN模型中，通过采用标准CNN模型（去除全连接层）中的卷积层和最大池化层来构造卷积层的组件。这样的组件用于从输入图像中提取序列特征表示。在进入网络之前，所有的图像需要缩放到相同的高度。然后从卷积层组件产生的特征图中提取特征向量序列，这些特征向量序列作为循环层的输入。具体地，特征序列的每一个特征向量在特征图上按列从左到右生成。这意味着第i个特征向量是所有特征图第i列的连接。在我们的设置中每列的宽度固定为单个像素。由于卷积层，最大池化层和元素激活函数在局部区域上执行，因此它们是平移不变的。因此，特征图的每列对应于原始图像的一个矩形区域（称为感受野），并且这些矩形区域与特征图上从左到右的相应列具有相同的顺序。如图2所示，特征序列中的每个向量关联一个感受野，并且可以被认为是该区域的图像描述符。</p>
<p><img src="https://image.discover304.top/dl/advcv/%E6%84%9F%E5%8F%97%E9%87%8E.png" alt="感受野"></p>
<center><font size=2>图2。感受野。提取的特征序列中的每一个向量关联输入图像的一个感受野，可认为是该区域的特征向量。</font></center>

<h4 id="4）序列标注"><a href="#4）序列标注" class="headerlink" title="4）序列标注"></a>4）序列标注</h4><p>一个深度双向循环神经网络是建立在卷积层的顶部，作为循环层。循环层预测特征序列$x &#x3D; x_1,…,x_T$中每一帧$x_t$的标签分布$y_t$。循环层的优点是三重的。首先，RNN具有很强的捕获序列内上下文信息的能力。对于基于图像的序列识别使用上下文提示比独立处理每个符号更稳定且更有帮助。以场景文本识别为例，宽字符可能需要一些连续的帧来完全描述（参见图2）。此外，一些模糊的字符在观察其上下文时更容易区分，例如，通过对比字符高度更容易识别“il”而不是分别识别它们中的每一个。其次，RNN可以将误差差值反向传播到其输入，即卷积层，从而允许我们在统一的网络中共同训练循环层和卷积层。第三，RNN能够从头到尾对任意长度的序列进行操作。</p>
<p>传统的RNN单元在其输入和输出层之间具有自连接的隐藏层。每次接收到序列中的帧$x_t$时，它将使用非线性函数来更新其内部状态$h_t$，该非线性函数同时接收当前输入$x_t$和过去状态$h_{t−1}$作为其输入：$h_t &#x3D; g(x_t, h_{t−1})$。那么预测$y_t$是基于$h_t$的。以这种方式，过去的上下文$\lbrace x_{t\prime} \rbrace _{t \prime &lt; t}$被捕获并用于预测。然而，传统的RNN单元有梯度消失的问题，这限制了其可以存储的上下文范围，并给训练过程增加了负担。长短时记忆（LSTM）是一种专门设计用于解决这个问题的RNN单元。LSTM（图3所示）由一个存储单元和三个多重门组成，即输入，输出和遗忘门。在概念上，存储单元存储过去的上下文，并且输入和输出门允许单元长时间地存储上下文。同时，单元中的存储可以被遗忘门清除。LSTM的特殊设计允许它捕获长距离依赖，这经常发生在基于图像的序列中。</p>
<p><img src="https://image.discover304.top/dl/advcv/RNN_LSTM.png" alt="RNN_LSTM"></p>
<center><font size=2>图3。(a) 基本的LSTM单元的结构。LSTM包括单元模块和三个门，即输入门，输出门和遗忘门。（b）我们论文中使用的深度双向LSTM结构。合并前向（从左到右）和后向（从右到左）LSTM的结果到双向LSTM中。在深度双向LSTM中堆叠多个双向LSTM结果。</font></center>

<p>LSTM是定向的，它只使用过去的上下文。然而，在基于图像的序列中，两个方向的上下文是相互有用且互补的。因此，将两个LSTM，一个向前和一个向后组合到一个双向LSTM中。此外，可以堆叠多个双向LSTM，得到如图3.b所示的深双向LSTM。深层结构允许比浅层抽象更高层次的抽象，并且在语音识别任务中取得了显著的性能改进。</p>
<h4 id="5）转录"><a href="#5）转录" class="headerlink" title="5）转录"></a>5）转录</h4><p>转录是将RNN所做的每帧预测转换成标签序列的过程。数学上，转录是根据每帧预测找到具有最高概率的标签序列。在实践中，存在两种转录模式，即无词典转录和基于词典的转录。词典是一组标签序列，预测受拼写检查字典约束。在无词典模式中，预测时没有任何词典。在基于词典的模式中，通过选择具有最高概率的标签序列进行预测。</p>
<h5 id="①-标签序列的概率"><a href="#①-标签序列的概率" class="headerlink" title="① 标签序列的概率"></a>① 标签序列的概率</h5><p>采用”联接时间分类“（CTC）层中定义的条件概率。按照每帧预测$y&#x3D;y_1,…,y_T$对标签序列$l$定义概率，并忽略$l$中每个标签所在的位置。因此，当我们使用这种概率的负对数似然作为训练网络的目标函数时，我们只需要图像及其相应的标签序列，避免了标注单个字符位置的劳动。</p>
<p>条件概率的公式简要描述如下：输入是序列$y &#x3D; y_1,…,y_T$，其中$T$是序列长度。这里，每个$y_t \in\Re^{|{\cal L}’|}$是在集合${\cal L}’ &#x3D; {\cal L} \cup$上的概率分布，其中${\cal L}$包含了任务中的所有标签（例如，所有英文字符），以及由<code>-</code>表示的“空白”标签。序列到序列的映射函数${\cal B}$定义在序列$\boldsymbol{\pi}\in{\cal L}’^{T}$上，其中$T$是长度。${\cal B}$将$\boldsymbol{\pi}$映射到$\mathbf{l}$上，首先删除重复的标签，然后删除<code>blank</code>。例如，${\cal B}$将“–hh-e-l-ll-oo–”（<code>-</code>表示<code>blank</code>）映射到“hello”。然后，条件概率被定义为由${\cal B}$映射到$\mathbf{l}$上的所有$\boldsymbol{\pi}$的概率之和：</p>
<p>$$<br>\begin{equation}<br>p(\mathbf{l}|\mathbf{y})&#x3D;\sum_{\boldsymbol{\pi}:{\cal B}(\boldsymbol{\pi})&#x3D;\mathbf{l}}p(\boldsymbol{\pi}|\mathbf{y}),\tag{1}<br>\end{equation}<br>$$</p>
<p>$\boldsymbol{\pi}$的概率定义为$p(\boldsymbol{\pi}|\mathbf{y})&#x3D;\prod_{t&#x3D;1}^{T}y_{\pi_{t}}^{t}$，$y_{\pi_{t}}^{t}$是时刻$t$时有标签$\pi_{t}$的概率。由于存在指数级数量的求和项，直接计算方程1在计算上是不可行的。然而，使用CTC中描述的前向算法可以有效计算方程。</p>
<h5 id="②-无字典转录"><a href="#②-无字典转录" class="headerlink" title="② 无字典转录"></a>② 无字典转录</h5><p>在这种模式下，将具有方程1中定义的最高概率的序列$\mathbf{l}^{<em>}$作为预测。由于不存在用于精确找到解的可行方法，我们采用CTC中的策略。序列$\mathbf{l}^{</em>}$通过$\mathbf{l}^{<em>}\approx{\cal B}(\arg\max_{\boldsymbol{\pi}}p(\boldsymbol{\pi}|\mathbf{y}))$近似发现，即在每个时间戳$t$采用最大概率的标签$\pi_{t}$，并将结果序列映射到$\mathbf{l}^{</em>}$。</p>
<h5 id="③-基于词典的转录"><a href="#③-基于词典的转录" class="headerlink" title="③ 基于词典的转录"></a>③ 基于词典的转录</h5><p>在基于字典的模式中，每个测试采样与词典${\cal D}$相关联。基本上，通过选择词典中具有方程1中定义的最高条件概率的序列来识别标签序列，即$\mathbf{l}^{*}&#x3D;\arg\max_{\mathbf{l}\in{\cal D}}p(\mathbf{l}|\mathbf{y})$。然而，对于大型词典，例如5万个词的Hunspell拼写检查词典，对词典进行详尽的搜索是非常耗时的，即对词典中的所有序列计算方程1，并选择概率最高的一个。为了解决这个问题，我们观察到，通过无词典转录预测的标签序列通常在编辑距离度量下接近于实际结果。这表示我们可以将搜索限制在最近邻候选目标${\cal N}_{\delta}(\mathbf{l}’)$，其中$\delta$是最大编辑距离，$\mathbf{l}’$是在无词典模式下从$\mathbf{y}$转录的序列：</p>
<p>$$<br>\begin{equation}<br>\mathbf{l}^{*}&#x3D;\arg\max_{\mathbf{l}\in{\cal N}_{\delta}(\mathbf{l}’)}p(\mathbf{l}|\mathbf{y}).\tag{2}<br>\end{equation}<br>$$</p>
<p>可以使用BK树数据结构有效地找到候选目标${\cal N}_{\delta}(\mathbf{l}’)$，这是一种专门适用于离散度量空间的度量树。BK树的搜索时间复杂度为$O(\log|{\cal D}|)$，其中$|{\cal D}|$是词典大小。因此，这个方案很容易扩展到非常大的词典。在我们的方法中，一个词典离线构造一个BK树。然后，我们使用树执行快速在线搜索，通过查找具有小于或等于$\delta$编辑距离来查询序列。</p>
<h4 id="6）网络训练"><a href="#6）网络训练" class="headerlink" title="6）网络训练"></a>6）网络训练</h4><p>${\cal X}&#x3D; \lbrace I_i,\mathbf{l}<em>i \rbrace <em>i $表示训练集，$I</em>{i}$是训练图像，$\mathbf{l}</em>{i}$是真实的标签序列。目标是最小化真实条件概率的负对数似然：</p>
<p>$$<br>\begin{equation}<br>{\cal O}&#x3D;-\sum_{I_{i},\mathbf{l}<em>{i}\in{\cal X}}\log p(\mathbf{l}</em>{i}|\mathbf{y}_{i}),\tag{3}<br>\end{equation}<br>$$</p>
<p>$\mathbf{y}<em>{i}$是循环层和卷积层从$I</em>{i}$生成的序列。目标函数直接从图像和它的真实标签序列计算代价值。因此，网络可以在成对的图像和序列上进行端对端训练，去除了在训练图像中手动标记所有单独组件的过程。</p>
<p>网络使用随机梯度下降（SGD）进行训练。梯度由反向传播算法计算。特别地，在转录层中，误差使用前向算法进行反向传播。在循环层中，应用随时间反向传播（BPTT）来计算误差。</p>
<p>为了优化，使用ADADELTA自动计算每维的学习率。与传统的动量方法相比，ADADELTA不需要手动设置学习率。更重要的是，我们发现使用ADADELTA的优化收敛速度比动量方法快。</p>
<p><img src="https://image.discover304.top/dl/advcv/OCR_RNN_LSTM%E7%BD%91%E7%BB%9C%E8%AF%A6%E6%83%85.png" alt="OCR_RNN_LSTM网络详情"></p>
<center><font size=2>网络详细结构</font></center>

<h4 id="7）结论"><a href="#7）结论" class="headerlink" title="7）结论"></a>7）结论</h4><p>该模型在4个公共测试数据集上取得了较好的成绩，跟其它基于深度学习模型相比，具有明显提升。如下表所示：</p>
<p><img src="https://image.discover304.top/dl/advcv/OCR_RNN_LSTM%E6%B5%8B%E8%AF%95%E6%80%A7%E8%83%BD.png" alt="OCR_RNN_LSTM测试性能"></p>
<ul>
<li>IIIT5k，SVT，IC03，IC13表示4个数据集</li>
<li>50，1k，50k和Full表示使用的字典，None表示识别没有字典</li>
</ul>
<p>识别图像中的乐谱被称为光学音乐识别（OMR）问题。在乐谱识别方面，CRNN大大优于两个商业系统。Capella Scan和PhotoScore系统在干净的数据集上表现相当不错，但是它们的性能在合成和现实世界数据方面显著下降。主要原因是它们依赖于强大的二值化来检五线谱和音符，但是由于光线不良，噪音破坏和杂乱的背景，二值化步骤经常会在合成数据和现实数据上失败。另一方面，CRNN使用对噪声和扭曲具有鲁棒性的卷积特征。此外，CRNN中的循环层可以利用乐谱中的上下文信息。每个音符不仅自身被识别，而且被附近的音符识别。因此，通过将一些音符与附近的音符进行比较可以识别它们，例如对比他们的垂直位置。</p>
<p><img src="https://image.discover304.top/dl/advcv/OCR_RNN_LSTM%E4%B9%90%E8%B0%B1%E8%AF%86%E5%88%AB%E6%80%A7%E8%83%BD.png"></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:hobart.yang@qq.com">✨YangSier✨</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://discover304.top/2021/12/13/2021q4/113-1-dl-ocr/">https://discover304.top/2021/12/13/2021q4/113-1-dl-ocr/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0anime</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AD%A6%E4%B9%A0/">学习</a><a class="post-meta__tags" href="/tags/%E8%AE%B0%E5%BD%95/">记录</a><a class="post-meta__tags" href="/tags/Python/">Python</a><a class="post-meta__tags" href="/tags/%E7%AC%94%E8%AE%B0/">笔记</a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></div><div class="post_share"><div class="social-share" data-image="https://img2.huashi6.com/images/resource/thumbnail/2021/12/05/1496_54694744582.jpg?imageMogr2/quality/100/interlace/1/thumbnail/1000x%3E" data-sites="facebook,twitter,wechat,weibo,qzone,qq,linkedin"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> Donate<div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/img/wechat.jpg" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/alipay.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/12/13/2021q4/113-2-dl-ss/"><img class="prev-cover" src="https://img2.huashi6.com/images/resource/thumbnail/2021/12/05/1496_54694744582.jpg?imageMogr2/quality/100/interlace/1/thumbnail/1000x%3E" onerror="onerror=null;src='/img/404.png'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">【深度学习】图像语义分割</div></div></a></div><div class="next-post pull-right"><a href="/2021/12/12/2021q4/115-new-book-1212/"><img class="next-cover" src="https://img2.huashi6.com/images/resource/2018/02/22/673h94923p0.jpg?imageMogr2/quality/100/interlace/1/thumbnail/1000x%3E" onerror="onerror=null;src='/img/404.png'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">双十二新书整理</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2021/11/30/2021q4/107-0-dl/" title="【深度学习】概述"><img class="cover" src="https://image.discover304.top/ai/dl/machine-girl.jpg?imageView2/2/h/300" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2021-12-25</div><div class="title">【深度学习】概述</div></div></a></div><div><a href="/2021/11/30/2021q4/107-1-dl-loss-gd/" title="【深度学习】基础 贰：损失函数与梯度下降"><img class="cover" src="https://image.discover304.top/ai/dl/machine-girl.jpg?imageView2/2/h/300" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2021-12-25</div><div class="title">【深度学习】基础 贰：损失函数与梯度下降</div></div></a></div><div><a href="/2021/11/30/2021q4/107-1-dl-perceptron/" title="【深度学习】基础 壹：感知机与神经网络"><img class="cover" src="https://image.discover304.top/ai/dl/machine-girl.jpg?imageView2/2/h/300" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2021-12-25</div><div class="title">【深度学习】基础 壹：感知机与神经网络</div></div></a></div><div><a href="/2021/12/01/2021q4/108-0-dl-ex/" title="【深度学习】实例第一部分：基础理论"><img class="cover" src="https://image.discover304.top/ai/dl/space_work.jpg?imageView2/2/h/300" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2021-12-25</div><div class="title">【深度学习】实例第一部分：基础理论</div></div></a></div><div><a href="/2021/11/30/2021q4/107-1-dl-cnn/" title="【深度学习】基础 肆：卷积神经网络"><img class="cover" src="https://image.discover304.top/ai/dl/machine-girl.jpg?imageView2/2/h/300" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2021-12-25</div><div class="title">【深度学习】基础 肆：卷积神经网络</div></div></a></div><div><a href="/2021/12/01/2021q4/108-1-dl-ex/" title="【深度学习】实例第二部分：OpenCV"><img class="cover" src="https://image.discover304.top/ai/dl/space_work.jpg?imageView2/2/h/300" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2023-10-24</div><div class="title">【深度学习】实例第二部分：OpenCV</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside_content" id="aside_content"><div class="card-widget card-info"><div class="card-content"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/head.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">✨YangSier✨</div><div class="author-info__description">Love Everything You Like.</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">244</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">88</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">24</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://space.bilibili.com/98639326"><i class="fab fa-bilibili"></i><span>Bilibili Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Discover304" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://blog.csdn.net/Discover304" target="_blank" title="CSDN"><i class="fa-solid fa-c"></i></a><a class="social-icon" href="https://www.zhihu.com/people/discover-56-86-75" target="_blank" title="知乎"><i class="fa-brands fa-zhihu"></i></a><a class="social-icon" href="mailto:hobart.yang@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://jq.qq.com/?_wv=1027&amp;k=EaGddTQg" target="_blank" title="QQ"><i class="fa-brands fa-qq"></i></a></div></div></div><div class="card-widget card-announcement"><div class="card-content"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">✨动态更新：<p style="text-align:center">享受精彩大学生活中。</p>✨聊天划水QQ群：<p style="text-align:center"><a target="_blank" rel="noopener" href="https://jq.qq.com/?_wv=1027&k=EaGddTQg"><strong>兔叽の魔术工房</strong></a><br>942-848-525</p>✨我们的口号是：<p style="text-align:center; color:#39C5BB">人工降神，机械飞升！</p><a target="_blank" rel="noopener" href='https://space.bilibili.com/98639326'><img src='/img/mikulittletrans.png'></a></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="card-content"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%9F%BA%E6%9C%AC%E7%90%86%E8%AE%BA"><span class="toc-text">一、基本理论</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E4%BB%80%E4%B9%88%E6%98%AFOCR"><span class="toc-text">1. 什么是OCR</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%EF%BC%89%E5%AE%9A%E4%B9%89"><span class="toc-text">1）定义</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2%EF%BC%89%E4%B8%80%E8%88%AC%E6%AD%A5%E9%AA%A4"><span class="toc-text">2）一般步骤</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3%EF%BC%89OCR%E7%9A%84%E9%9A%BE%E7%82%B9"><span class="toc-text">3）OCR的难点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4%EF%BC%89OCR%E4%B8%8E%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-text">4）OCR与目标检测的区别</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5%EF%BC%89%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87"><span class="toc-text">5）评估指标</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6%EF%BC%89%E5%BA%94%E7%94%A8"><span class="toc-text">6）应用</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E6%96%87%E5%AD%97%E6%A3%80%E6%B5%8B%E6%8A%80%E6%9C%AF"><span class="toc-text">二、文字检测技术</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-CTPN%EF%BC%882016%EF%BC%89"><span class="toc-text">1. CTPN（2016）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%EF%BC%89%E6%A6%82%E8%BF%B0"><span class="toc-text">1）概述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2%EF%BC%89%E5%85%B7%E4%BD%93%E6%AD%A5%E9%AA%A4"><span class="toc-text">2）具体步骤</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3%EF%BC%89%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="toc-text">3）网络结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4%EF%BC%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-text">4）损失函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5%EF%BC%89%E6%80%A7%E8%83%BD"><span class="toc-text">5）性能</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%91%A0-%E6%97%B6%E9%97%B4%E6%80%A7%E8%83%BD"><span class="toc-text">① 时间性能</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%91%A1-%E5%87%86%E7%A1%AE%E7%8E%87"><span class="toc-text">② 准确率</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6%EF%BC%89%E7%BC%BA%E9%99%B7"><span class="toc-text">6）缺陷</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-SegLink-2017"><span class="toc-text">2. SegLink(2017)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%EF%BC%89%E6%A6%82%E8%BF%B0-1"><span class="toc-text">1）概述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2%EF%BC%89%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="toc-text">2）网络结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3%EF%BC%89link-%E9%93%BE%E6%8E%A5"><span class="toc-text">3）link(链接)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4%EF%BC%89%E9%A2%84%E6%B5%8B%E5%8F%82%E6%95%B0%E8%A1%A8%E7%A4%BA"><span class="toc-text">4）预测参数表示</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5%EF%BC%89%E5%92%8C%E5%B9%B6segment%E5%92%8Clink"><span class="toc-text">5）和并segment和link</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6%EF%BC%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-text">6）损失函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7%EF%BC%89%E6%80%A7%E8%83%BD"><span class="toc-text">7）性能</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8%EF%BC%89%E5%B1%80%E9%99%90"><span class="toc-text">8）局限</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E6%96%87%E5%AD%97%E8%AF%86%E5%88%AB%E6%8A%80%E6%9C%AF"><span class="toc-text">三、文字识别技术</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-CRNN-CTC-2015"><span class="toc-text">1. CRNN+CTC(2015)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%EF%BC%89%E7%89%B9%E7%82%B9"><span class="toc-text">1）特点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2%EF%BC%89%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84-1"><span class="toc-text">2）网络结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3%EF%BC%89%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="toc-text">3）特征提取</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4%EF%BC%89%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8"><span class="toc-text">4）序列标注</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5%EF%BC%89%E8%BD%AC%E5%BD%95"><span class="toc-text">5）转录</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%91%A0-%E6%A0%87%E7%AD%BE%E5%BA%8F%E5%88%97%E7%9A%84%E6%A6%82%E7%8E%87"><span class="toc-text">① 标签序列的概率</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%91%A1-%E6%97%A0%E5%AD%97%E5%85%B8%E8%BD%AC%E5%BD%95"><span class="toc-text">② 无字典转录</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%91%A2-%E5%9F%BA%E4%BA%8E%E8%AF%8D%E5%85%B8%E7%9A%84%E8%BD%AC%E5%BD%95"><span class="toc-text">③ 基于词典的转录</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6%EF%BC%89%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83"><span class="toc-text">6）网络训练</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7%EF%BC%89%E7%BB%93%E8%AE%BA"><span class="toc-text">7）结论</span></a></li></ol></li></ol></li></ol></div></div></div><div class="card-widget card-recent-post"><div class="card-content"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/11/28/2023q4/174-1-hp-checklist/" title="174-1-Hp-Checklist"><img src="https://image.discover304.top/wallpaper/anime-anime-girls-original-characters-short-hair-wallpaper-preview.jpg?imageView2/2/h/600" onerror="this.onerror=null;this.src='/img/404.png'" alt="174-1-Hp-Checklist"/></a><div class="content"><a class="title" href="/2023/11/28/2023q4/174-1-hp-checklist/" title="174-1-Hp-Checklist">174-1-Hp-Checklist</a><time datetime="2023-11-28T02:14:10.000Z" title="Created 2023-11-28 10:14:10">2023-11-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/10/23/2023q4/174-0-hp-papers/" title="Paper Reading List"><img src="https://image.discover304.top/1698088169210.png?imageView2/2/h/400" onerror="this.onerror=null;this.src='/img/404.png'" alt="Paper Reading List"/></a><div class="content"><a class="title" href="/2023/10/23/2023q4/174-0-hp-papers/" title="Paper Reading List">Paper Reading List</a><time datetime="2023-10-23T11:35:40.000Z" title="Created 2023-10-23 19:35:40">2023-10-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/04/24/2023q1/173-nginx-docker-blog-page-depoly/" title="【模板】Hexo Docker Nginx 个人博客服务器部署"><img src="https://image.discover304.top/s16001804242023.png?imageView2/2/h/300" onerror="this.onerror=null;this.src='/img/404.png'" alt="【模板】Hexo Docker Nginx 个人博客服务器部署"/></a><div class="content"><a class="title" href="/2023/04/24/2023q1/173-nginx-docker-blog-page-depoly/" title="【模板】Hexo Docker Nginx 个人博客服务器部署">【模板】Hexo Docker Nginx 个人博客服务器部署</a><time datetime="2023-04-24T06:39:24.000Z" title="Created 2023-04-24 14:39:24">2023-04-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/11/2022q4/171-other-thought/" title="【思考】其他思考"><img src="https://image.discover304.top/blog-img/s19305112112022.png" onerror="this.onerror=null;this.src='/img/404.png'" alt="【思考】其他思考"/></a><div class="content"><a class="title" href="/2022/12/11/2022q4/171-other-thought/" title="【思考】其他思考">【思考】其他思考</a><time datetime="2022-12-11T11:08:17.000Z" title="Created 2022-12-11 19:08:17">2022-12-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/11/2022q4/170-key-thought/" title="【思考】核心思考"><img src="https://image.discover304.top/blog-img/s19294112112022.png" onerror="this.onerror=null;this.src='/img/404.png'" alt="【思考】核心思考"/></a><div class="content"><a class="title" href="/2022/12/11/2022q4/170-key-thought/" title="【思考】核心思考">【思考】核心思考</a><time datetime="2022-12-11T11:08:06.000Z" title="Created 2022-12-11 19:08:06">2022-12-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/09/2022q4/169-new-r/" title="R: Getting Into Project of R"><img src="https://image.discover304.top/blog-img/s18350812112022.png" onerror="this.onerror=null;this.src='/img/404.png'" alt="R: Getting Into Project of R"/></a><div class="content"><a class="title" href="/2022/12/09/2022q4/169-new-r/" title="R: Getting Into Project of R">R: Getting Into Project of R</a><time datetime="2022-12-09T09:44:06.000Z" title="Created 2022-12-09 17:44:06">2022-12-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/11/28/2022q3/167-2-sp-review/" title="SP Modules Review Contents (3)"><img src="https://image.discover304.top/blog-img/s11220010012022.png?imageView2/2/h/300" onerror="this.onerror=null;this.src='/img/404.png'" alt="SP Modules Review Contents (3)"/></a><div class="content"><a class="title" href="/2022/11/28/2022q3/167-2-sp-review/" title="SP Modules Review Contents (3)">SP Modules Review Contents (3)</a><time datetime="2022-11-28T07:24:39.000Z" title="Created 2022-11-28 15:24:39">2022-11-28</time></div></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(https://img2.huashi6.com/images/resource/thumbnail/2021/12/05/1496_54694744582.jpg?imageMogr2/quality/100/interlace/1/thumbnail/1000x%3E)"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By ✨YangSier✨</div><div><a target="_blank" href="https://beian.miit.gov.cn/" style="display:inline-block;text-decoration:none;height:20px;line-height:20px;"><p style="float:left;height:20px;line-height:20px;margin: 0px 0px 0px 5px; color:#939393;"> 冀ICP备2021025381号-1</p></a></div><div><a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=13060602001430" style="display:inline-block;text-decoration:none;height:20px;line-height:20px;"><img src="/img/beian.png" style="float:left;"/><p style="float:left;height:20px;line-height:20px;margin: 0px 0px 0px 5px; color:#939393;">冀公网安备 13060602001430号</p></a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="Switch Between Traditional Chinese And Simplified Chinese">繁</button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.spacingElementById('content-inner')
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.spacingElementById('content-inner')
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> {preloader.endLoading()})</script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>if (document.getElementsByClassName('mermaid').length) {
  if (window.mermaidJsLoad) mermaid.init()
  else {
    getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(() => {
      window.mermaidJsLoad = true
      mermaid.initialize({
        theme: 'neutral',
      })
      false && mermaid.init()
    })
  }
}</script><script>function loadValine () {
  function initValine () {
    let initData = {
      el: '#vcomment',
      appId: 'A9RWVELPcIotgfbpp9KLGXQM-gzGzoHsz',
      appKey: 'MLgPQW5h0DPgE8jNkeREKubU',
      placeholder: '欢迎留言呀。（网址是选填，可以留空）',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'zh-CN',
      recordIP: true,
      serverURLs: 'https://a9rwvelp.lc-cn-n1-shared.com',
      emojiCDN: 'https://cdn.jsdelivr.net/gh/GamerNoTitle/ValineCDN@master/',
      emojiMaps: {"QQ1":"QQ/aini.gif","QQ2":"QQ/aixin.gif","QQ3":"QQ/aoman.gif","QQ4":"QQ/baiyan.gif","QQ5":"QQ/bangbangtang.gif","QQ6":"QQ/baojin.gif","QQ7":"QQ/baoquan.gif","QQ8":"QQ/bishi.gif","QQ9":"QQ/bizui.gif","QQ11":"QQ/cahan.gif","QQ12":"QQ/caidao.gif","QQ13":"QQ/chi.gif","QQ14":"QQ/ciya.gif","QQ15":"QQ/dabing.gif","QQ16":"QQ/daku.gif","QQ17":"QQ/dan.gif","QQ18":"QQ/deyi.gif","QQ19":"QQ/doge.gif","QQ20":"QQ/fadai.gif","QQ21":"QQ/fanu.gif","QQ22":"QQ/fendou.gif","QQ23":"QQ/ganga.gif","QQ24":"QQ/gouyin.gif","QQ25":"QQ/guzhang.gif","QQ26":"QQ/haixiu.gif","QQ27":"QQ/hanxiao.gif","QQ28":"QQ/haobang.gif","QQ29":"QQ/haqian.gif","QQ30":"QQ/hecai.gif","QQ31":"QQ/hexie.gif","QQ32":"QQ/huaixiao.gif","QQ33":"QQ/jie.gif","QQ34":"QQ/jingkong.gif","QQ35":"QQ/jingxi.gif","QQ36":"QQ/jingya.gif","QQ37":"QQ/juhua.gif","QQ38":"QQ/keai.gif","QQ39":"QQ/kelian.gif","QQ40":"QQ/koubi.gif","QQ41":"QQ/ku.gif","QQ42":"QQ/kuaikule.gif","QQ43":"QQ/kulou.gif","QQ44":"QQ/kun.gif","QQ45":"QQ/lanqiu.gif","QQ46":"QQ/leiben.gif","QQ47":"QQ/lenghan.gif","QQ48":"QQ/liuhan.gif","QQ49":"QQ/liulei.gif","QQ50":"QQ/nanguo.gif","QQ51":"QQ/OK.gif","QQ52":"QQ/penxue.gif","QQ53":"QQ/piezui.gif","QQ54":"QQ/pijiu.gif","QQ55":"QQ/qiang.gif","QQ56":"QQ/qiaoda.gif","QQ57":"QQ/qinqin.gif","QQ58":"QQ/qiudale.gif","QQ59":"QQ/quantou.gif","QQ60":"QQ/saorao.gif","QQ61":"QQ/se.gif","QQ62":"QQ/shengli.gif","QQ63":"QQ/shouqiang.gif","QQ64":"QQ/shuai.gif","QQ65":"QQ/shui.gif","QQ66":"QQ/tiaopi.gif","QQ67":"QQ/touxiao.gif","QQ68":"QQ/tu.gif","QQ69":"QQ/tuosai.gif","QQ70":"QQ/weiqu.gif","QQ71":"QQ/weixiao.gif","QQ72":"QQ/woshou.gif","QQ73":"QQ/wozuimei.gif","QQ74":"QQ/wunai.gif","QQ75":"QQ/xia.gif","QQ76":"QQ/xiaojiujie.gif","QQ77":"QQ/xiaoku.gif","QQ78":"QQ/xiaoyanger.gif","QQ79":"QQ/xieyanxiao.gif","QQ80":"QQ/xigua.gif","QQ81":"QQ/xu.gif","QQ82":"QQ/yangtuo.gif","QQ83":"QQ/yinxian.gif","QQ84":"QQ/yiwen.gif","QQ85":"QQ/youhengheng.gif","QQ86":"QQ/youling.gif","QQ87":"QQ/yun.gif","QQ88":"QQ/zaijian.gif","QQ89":"QQ/zhayanjian.gif","QQ90":"QQ/zhemo.gif","QQ91":"QQ/zhouma.gif","QQ92":"QQ/zhuakuang.gif","QQ93":"QQ/zuohengheng.gif","bilibiliHotKey1":"bilibiliHotKey/1.jpg","bilibiliHotKey2":"bilibiliHotKey/10.jpg","bilibiliHotKey3":"bilibiliHotKey/11.jpg","bilibiliHotKey4":"bilibiliHotKey/12.jpg","bilibiliHotKey5":"bilibiliHotKey/13.jpg","bilibiliHotKey6":"bilibiliHotKey/14.jpg","bilibiliHotKey7":"bilibiliHotKey/15.jpg","bilibiliHotKey8":"bilibiliHotKey/16.jpg","bilibiliHotKey9":"bilibiliHotKey/17.jpg","bilibiliHotKey10":"bilibiliHotKey/18.jpg","bilibiliHotKey11":"bilibiliHotKey/19.jpg","bilibiliHotKey12":"bilibiliHotKey/2.jpg","bilibiliHotKey13":"bilibiliHotKey/20.jpg","bilibiliHotKey14":"bilibiliHotKey/21.jpg","bilibiliHotKey15":"bilibiliHotKey/22.jpg","bilibiliHotKey16":"bilibiliHotKey/23.jpg","bilibiliHotKey17":"bilibiliHotKey/24.jpg","bilibiliHotKey18":"bilibiliHotKey/25.jpg","bilibiliHotKey19":"bilibiliHotKey/26.jpg","bilibiliHotKey20":"bilibiliHotKey/27.jpg","bilibiliHotKey21":"bilibiliHotKey/28.jpg","bilibiliHotKey22":"bilibiliHotKey/29.jpg","bilibiliHotKey23":"bilibiliHotKey/3.jpg","bilibiliHotKey24":"bilibiliHotKey/30.jpg","bilibiliHotKey25":"bilibiliHotKey/31.jpg","bilibiliHotKey26":"bilibiliHotKey/32.jpg","bilibiliHotKey27":"bilibiliHotKey/4.jpg","bilibiliHotKey28":"bilibiliHotKey/5.jpg","bilibiliHotKey29":"bilibiliHotKey/6.jpg","bilibiliHotKey30":"bilibiliHotKey/7.jpg","bilibiliHotKey31":"bilibiliHotKey/8.jpg","bilibiliHotKey32":"bilibiliHotKey/9.jpg","Menhera-chan1":"Menhera-chan/1.jpg","Menhera-chan2":"Menhera-chan/10.jpg","Menhera-chan3":"Menhera-chan/100.jpg","Menhera-chan4":"Menhera-chan/101.jpg","Menhera-chan5":"Menhera-chan/102.jpg","Menhera-chan6":"Menhera-chan/103.jpg","Menhera-chan7":"Menhera-chan/104.jpg","Menhera-chan8":"Menhera-chan/105.jpg","Menhera-chan9":"Menhera-chan/106.jpg","Menhera-chan10":"Menhera-chan/107.jpg","Menhera-chan11":"Menhera-chan/108.jpg","Menhera-chan12":"Menhera-chan/109.jpg","Menhera-chan13":"Menhera-chan/11.jpg","Menhera-chan14":"Menhera-chan/110.jpg","Menhera-chan15":"Menhera-chan/111.jpg","Menhera-chan16":"Menhera-chan/112.jpg","Menhera-chan17":"Menhera-chan/113.jpg","Menhera-chan18":"Menhera-chan/114.jpg","Menhera-chan19":"Menhera-chan/115.jpg","Menhera-chan20":"Menhera-chan/116.jpg","Menhera-chan21":"Menhera-chan/117.jpg","Menhera-chan22":"Menhera-chan/118.jpg","Menhera-chan23":"Menhera-chan/119.jpg","Menhera-chan24":"Menhera-chan/12.jpg","Menhera-chan25":"Menhera-chan/120.jpg","Menhera-chan26":"Menhera-chan/13.jpg","Menhera-chan27":"Menhera-chan/14.jpg","Menhera-chan28":"Menhera-chan/15.jpg","Menhera-chan29":"Menhera-chan/16.jpg","Menhera-chan30":"Menhera-chan/17.jpg","Menhera-chan31":"Menhera-chan/18.jpg","Menhera-chan32":"Menhera-chan/19.jpg","Menhera-chan33":"Menhera-chan/2.jpg","Menhera-chan34":"Menhera-chan/20.jpg","Menhera-chan35":"Menhera-chan/21.jpg","Menhera-chan36":"Menhera-chan/22.jpg","Menhera-chan37":"Menhera-chan/23.jpg","Menhera-chan38":"Menhera-chan/24.jpg","Menhera-chan39":"Menhera-chan/25.jpg","Menhera-chan40":"Menhera-chan/26.jpg","Menhera-chan41":"Menhera-chan/27.jpg","Menhera-chan42":"Menhera-chan/28.jpg","Menhera-chan43":"Menhera-chan/29.jpg","Menhera-chan44":"Menhera-chan/3.jpg","Menhera-chan45":"Menhera-chan/30.jpg","Menhera-chan46":"Menhera-chan/31.jpg","Menhera-chan47":"Menhera-chan/32.jpg","Menhera-chan48":"Menhera-chan/33.jpg","Menhera-chan49":"Menhera-chan/34.jpg","Menhera-chan50":"Menhera-chan/35.jpg","Menhera-chan51":"Menhera-chan/36.jpg","Menhera-chan52":"Menhera-chan/37.jpg","Menhera-chan53":"Menhera-chan/38.jpg","Menhera-chan54":"Menhera-chan/39.jpg","Menhera-chan55":"Menhera-chan/4.jpg","Menhera-chan56":"Menhera-chan/40.jpg","Menhera-chan57":"Menhera-chan/41.jpg","Menhera-chan58":"Menhera-chan/42.jpg","Menhera-chan59":"Menhera-chan/43.jpg","Menhera-chan60":"Menhera-chan/44.jpg","Menhera-chan61":"Menhera-chan/45.jpg","Menhera-chan62":"Menhera-chan/46.jpg","Menhera-chan63":"Menhera-chan/47.jpg","Menhera-chan64":"Menhera-chan/48.jpg","Menhera-chan65":"Menhera-chan/49.jpg","Menhera-chan66":"Menhera-chan/5.jpg","Menhera-chan67":"Menhera-chan/50.jpg","Menhera-chan68":"Menhera-chan/51.jpg","Menhera-chan69":"Menhera-chan/52.jpg","Menhera-chan70":"Menhera-chan/53(1).jpg","Menhera-chan71":"Menhera-chan/53.jpg","Menhera-chan72":"Menhera-chan/54.jpg","Menhera-chan73":"Menhera-chan/55.jpg","Menhera-chan74":"Menhera-chan/56.jpg","Menhera-chan75":"Menhera-chan/57.jpg","Menhera-chan76":"Menhera-chan/58.jpg","Menhera-chan77":"Menhera-chan/59.jpg","Menhera-chan78":"Menhera-chan/6.jpg","Menhera-chan79":"Menhera-chan/60.jpg","Menhera-chan80":"Menhera-chan/61.jpg","Menhera-chan81":"Menhera-chan/62.jpg","Menhera-chan82":"Menhera-chan/63.jpg","Menhera-chan83":"Menhera-chan/64.jpg","Menhera-chan84":"Menhera-chan/65.jpg","Menhera-chan85":"Menhera-chan/66.jpg","Menhera-chan86":"Menhera-chan/67.jpg","Menhera-chan87":"Menhera-chan/68.jpg","Menhera-chan88":"Menhera-chan/69.jpg","Menhera-chan89":"Menhera-chan/7.jpg","Menhera-chan90":"Menhera-chan/70.jpg","Menhera-chan91":"Menhera-chan/71.jpg","Menhera-chan92":"Menhera-chan/72.jpg","Menhera-chan93":"Menhera-chan/73.jpg","Menhera-chan94":"Menhera-chan/74.jpg","Menhera-chan95":"Menhera-chan/75.jpg","Menhera-chan96":"Menhera-chan/76.jpg","Menhera-chan97":"Menhera-chan/77.jpg","Menhera-chan98":"Menhera-chan/78.jpg","Menhera-chan99":"Menhera-chan/79.jpg","Menhera-chan100":"Menhera-chan/8.jpg","Menhera-chan101":"Menhera-chan/80.jpg","Menhera-chan102":"Menhera-chan/81.jpg","Menhera-chan103":"Menhera-chan/82.jpg","Menhera-chan104":"Menhera-chan/83.jpg","Menhera-chan105":"Menhera-chan/84.jpg","Menhera-chan106":"Menhera-chan/85.jpg","Menhera-chan107":"Menhera-chan/86.jpg","Menhera-chan108":"Menhera-chan/87.jpg","Menhera-chan109":"Menhera-chan/88.jpg","Menhera-chan110":"Menhera-chan/89.jpg","Menhera-chan111":"Menhera-chan/9.jpg","Menhera-chan112":"Menhera-chan/90.jpg","Menhera-chan113":"Menhera-chan/91.jpg","Menhera-chan114":"Menhera-chan/92.jpg","Menhera-chan115":"Menhera-chan/93.jpg","Menhera-chan116":"Menhera-chan/94.jpg","Menhera-chan117":"Menhera-chan/95.jpg","Menhera-chan118":"Menhera-chan/96.jpg","Menhera-chan119":"Menhera-chan/97.jpg","Menhera-chan120":"Menhera-chan/98.jpg","Menhera-chan121":"Menhera-chan/99.jpg","Sweetie-Bunny1":"Sweetie-Bunny/12311678.png","Sweetie-Bunny2":"Sweetie-Bunny/12311679.png","Sweetie-Bunny3":"Sweetie-Bunny/12311680.png","Sweetie-Bunny4":"Sweetie-Bunny/12311681.png","Sweetie-Bunny5":"Sweetie-Bunny/12311682.png","Sweetie-Bunny6":"Sweetie-Bunny/12311683.png","Sweetie-Bunny7":"Sweetie-Bunny/12311684.png","Sweetie-Bunny8":"Sweetie-Bunny/12311685.png","Sweetie-Bunny9":"Sweetie-Bunny/12311686.png","Sweetie-Bunny10":"Sweetie-Bunny/12311687.png","Sweetie-Bunny11":"Sweetie-Bunny/12311688.png","Sweetie-Bunny12":"Sweetie-Bunny/12311689.png","Sweetie-Bunny13":"Sweetie-Bunny/12311690.png","Sweetie-Bunny14":"Sweetie-Bunny/12311691.png","Sweetie-Bunny15":"Sweetie-Bunny/12311692.png","Sweetie-Bunny16":"Sweetie-Bunny/12311693.png","Sweetie-Bunny17":"Sweetie-Bunny/12311694.png","Sweetie-Bunny18":"Sweetie-Bunny/12311695.png","Sweetie-Bunny19":"Sweetie-Bunny/12311696.png","Sweetie-Bunny20":"Sweetie-Bunny/12311697.png","Sweetie-Bunny21":"Sweetie-Bunny/12311698.png","Sweetie-Bunny22":"Sweetie-Bunny/12311699.png","Sweetie-Bunny23":"Sweetie-Bunny/12311700.png","Sweetie-Bunny24":"Sweetie-Bunny/12311701.png","Sweetie-Bunny25":"Sweetie-Bunny/12311702.png","Sweetie-Bunny26":"Sweetie-Bunny/12311703.png","Sweetie-Bunny27":"Sweetie-Bunny/12311704.png","Sweetie-Bunny28":"Sweetie-Bunny/12311705.png","Sweetie-Bunny29":"Sweetie-Bunny/12311706.png","Sweetie-Bunny30":"Sweetie-Bunny/12311707.png","Sweetie-Bunny31":"Sweetie-Bunny/12311708.png","Sweetie-Bunny32":"Sweetie-Bunny/12311709.png","Sweetie-Bunny33":"Sweetie-Bunny/12311710.png","Sweetie-Bunny34":"Sweetie-Bunny/12311711.png","Sweetie-Bunny35":"Sweetie-Bunny/12311712.png","Sweetie-Bunny36":"Sweetie-Bunny/12311713.png","Sweetie-Bunny37":"Sweetie-Bunny/12311714.png","Sweetie-Bunny38":"Sweetie-Bunny/12311715.png","Sweetie-Bunny39":"Sweetie-Bunny/12311716.png","Sweetie-Bunny40":"Sweetie-Bunny/12311717.png","Majotabi1":"Majotabi/367516718.png","Majotabi2":"Majotabi/367516719.png","Majotabi3":"Majotabi/367516720.png","Majotabi4":"Majotabi/367516721.png","Majotabi5":"Majotabi/367516722.png","Majotabi6":"Majotabi/367516723.png","Majotabi7":"Majotabi/367516724.png","Majotabi8":"Majotabi/367516725.png","Majotabi9":"Majotabi/367516726.png","Majotabi10":"Majotabi/367516727.png","Majotabi11":"Majotabi/367516728.png","Majotabi12":"Majotabi/367516729.png","Majotabi13":"Majotabi/367516730.png","Majotabi14":"Majotabi/367516731.png","Majotabi15":"Majotabi/367516732.png","Majotabi16":"Majotabi/367516733.png","Majotabi17":"Majotabi/367516734.png","Majotabi18":"Majotabi/367516735.png","Majotabi19":"Majotabi/367516736.png","Majotabi20":"Majotabi/367516737.png","Majotabi21":"Majotabi/367516738.png","Majotabi22":"Majotabi/367516739.png","Majotabi23":"Majotabi/367516740.png","Majotabi24":"Majotabi/367516741.png","Majotabi25":"Majotabi/367516742.png","Majotabi26":"Majotabi/367516743.png","Majotabi27":"Majotabi/367516744.png","Majotabi28":"Majotabi/367516745.png","Majotabi29":"Majotabi/367516746.png","Majotabi30":"Majotabi/367516747.png","Majotabi31":"Majotabi/367516748.png","Majotabi32":"Majotabi/367516749.png","Majotabi33":"Majotabi/367516750.png","Majotabi34":"Majotabi/367516751.png","Majotabi35":"Majotabi/367516752.png","Majotabi36":"Majotabi/367516753.png","Majotabi37":"Majotabi/367516754.png","Majotabi38":"Majotabi/367516755.png","Majotabi39":"Majotabi/367516756.png","Majotabi40":"Majotabi/367516757.png","Snow-Miku1":"Snow-Miku/3583066@2x.png","Snow-Miku2":"Snow-Miku/3583067@2x.png","Snow-Miku3":"Snow-Miku/3583068@2x.png","Snow-Miku4":"Snow-Miku/3583069@2x.png","Snow-Miku5":"Snow-Miku/3583070@2x.png","Snow-Miku6":"Snow-Miku/3583071@2x.png","Snow-Miku7":"Snow-Miku/3583072@2x.png","Snow-Miku8":"Snow-Miku/3583073@2x.png","Snow-Miku9":"Snow-Miku/3583074@2x.png","Snow-Miku10":"Snow-Miku/3583075@2x.png","Snow-Miku11":"Snow-Miku/3583076@2x.png","Snow-Miku12":"Snow-Miku/3583077@2x.png","Snow-Miku13":"Snow-Miku/3583078@2x.png","Snow-Miku14":"Snow-Miku/3583079@2x.png","Snow-Miku15":"Snow-Miku/3583080@2x.png","Snow-Miku16":"Snow-Miku/3583081@2x.png","Snow-Miku17":"Snow-Miku/3583082@2x.png","Snow-Miku18":"Snow-Miku/3583083@2x.png","Snow-Miku19":"Snow-Miku/3583084@2x.png","Snow-Miku20":"Snow-Miku/3583085@2x.png","Snow-Miku21":"Snow-Miku/3583086@2x.png","Snow-Miku22":"Snow-Miku/3583087@2x.png","Snow-Miku23":"Snow-Miku/3583088@2x.png","Snow-Miku24":"Snow-Miku/3583089@2x.png","Snow-Miku25":"Snow-Miku/3583090@2x.png","Snow-Miku26":"Snow-Miku/3583091@2x.png","Snow-Miku27":"Snow-Miku/3583092@2x.png","Snow-Miku28":"Snow-Miku/3583093@2x.png","Snow-Miku29":"Snow-Miku/3583094@2x.png","Snow-Miku30":"Snow-Miku/3583095@2x.png","Snow-Miku31":"Snow-Miku/3583096@2x.png","Snow-Miku32":"Snow-Miku/3583097@2x.png","Snow-Miku33":"Snow-Miku/3583098@2x.png","Snow-Miku34":"Snow-Miku/3583099@2x.png","Snow-Miku35":"Snow-Miku/3583100@2x.png","Snow-Miku36":"Snow-Miku/3583101@2x.png","Snow-Miku37":"Snow-Miku/3583102@2x.png","Snow-Miku38":"Snow-Miku/3583103@2x.png","Snow-Miku39":"Snow-Miku/3583104@2x.png","Snow-Miku40":"Snow-Miku/3583105@2x.png"},
      enableQQ: true,
      path: window.location.pathname,
    }

    if (true) { 
      initData.requiredFields= ('nick,mail'.split(','))
    }
    
    if (false) {
      const otherData = false
      initData = Object.assign({}, initData, otherData)
    }
    
    const valine = new Valine(initData)
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.querySelector('#vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script>(function(){
  const bp = document.createElement('script');
  const curProtocol = window.location.protocol.split(':')[0];
  if (curProtocol === 'https') {
    bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
  }
  else{
    bp.src = 'http://push.zhanzhang.baidu.com/push.js';
  }
  bp.dataset.pjax = ''
  const s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(bp, s);
})()</script></div></body></html>