<!DOCTYPE html><html lang="en" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>【深度学习】生成对抗网络（GAN） | Ⅹ. Harbor</title><meta name="keywords" content="记录,Python,学习,笔记,深度学习"><meta name="author" content="✨白拾ShiroX✨,hobart.yang@qq.com"><meta name="copyright" content="✨白拾ShiroX✨"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="一、概述生成对抗网络（Generative Adversarial Networks）是一种无监督深度学习模型，用来通过计算机生成数据，由Ian J. Goodfellow等人于2014年提出。模型通过框架中（至少）两个模块：生成模型（Generative Model）和判别模型（Discriminative Model）的互相博弈学习产生相当好的输出。生成对抗网络被认为是当前最具前景、最具活跃度">
<meta property="og:type" content="article">
<meta property="og:title" content="【深度学习】生成对抗网络（GAN）">
<meta property="og:url" content="https://discover304.top/2021/12/13/2021q4/113-3-dl-gan/index.html">
<meta property="og:site_name" content="Ⅹ. Harbor">
<meta property="og:description" content="一、概述生成对抗网络（Generative Adversarial Networks）是一种无监督深度学习模型，用来通过计算机生成数据，由Ian J. Goodfellow等人于2014年提出。模型通过框架中（至少）两个模块：生成模型（Generative Model）和判别模型（Discriminative Model）的互相博弈学习产生相当好的输出。生成对抗网络被认为是当前最具前景、最具活跃度">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://img2.huashi6.com/images/resource/thumbnail/2021/12/05/1496_54694744582.jpg?imageMogr2/quality/100/interlace/1/thumbnail/1000x%3E">
<meta property="article:published_time" content="2021-12-13T01:00:14.000Z">
<meta property="article:modified_time" content="2021-12-25T06:38:50.000Z">
<meta property="article:author" content="✨白拾ShiroX✨">
<meta property="article:tag" content="记录">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="学习">
<meta property="article:tag" content="笔记">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img2.huashi6.com/images/resource/thumbnail/2021/12/05/1496_54694744582.jpg?imageMogr2/quality/100/interlace/1/thumbnail/1000x%3E"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://discover304.top/2021/12/13/2021q4/113-3-dl-gan/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="preconnect" href="//zz.bdstatic.com"/><meta name="google-site-verification" content="ilqpfk3vkgzDNNikz_V37-DOvRyi5wv4Hoi_eyBqvTg"/><meta name="msvalidate.01" content="49D9A50CCF9744E17274791468EDB517"/><meta name="baidu-site-verification" content="code-V24KosyVh1"/><meta name="360-site-verification" content="bd8859c3d74dfa3e8aeee9db30c94bd2"/><meta name="yandex-verification" content="f28ec9bbd50c56f5"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script async="async" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script>(adsbygoogle = window.adsbygoogle || []).push({
  google_ad_client: 'ca-pub-1849044985266192',
  enable_page_level_ads: 'true'
});</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8030f6052f2fed6a4704d96619f090d6";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><link rel="stylesheet" href="/css/font.css" media="print" onload="this.media='all'"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: {"limitDay":365,"position":"bottom","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'days',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: {"limitCount":200,"languages":{"author":"Author: ✨白拾ShiroX✨","link":"Link: ","source":"Source: Ⅹ. Harbor","info":"Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source."}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"Traditional Chinese Activated Manually","cht_to_chs":"Simplified Chinese Activated Manually","day_to_night":"Dark Mode Activated Manually","night_to_day":"Light Mode Activated Manually","bgLight":"#ffc910","bgDark":"#02c3f6","position":"bottom-left"},
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isanchor: true
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}

// https://stackoverflow.com/questions/16839698/jquery-getscript-alternative-in-native-javascript
const getScript = url => new Promise((resolve, reject) => {
  const script = document.createElement('script')
  script.src = url
  script.async = true
  script.onerror = reject
  script.onload = script.onreadystatechange = function() {
    const loadState = this.readyState
    if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
    script.onload = script.onreadystatechange = null
    resolve()
  }
  document.head.appendChild(script)
})</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-12-25 14:38:50'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
   if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }
  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified
    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }const asideStatus = saveToLocal.get('aside-status')
if (asideStatus !== undefined) {
   if (asideStatus === 'hide') {
     document.documentElement.classList.add('hide-aside')
   } else {
     document.documentElement.classList.remove('hide-aside')
   }
}const fontSizeVal = saveToLocal.get('global-font-size')
if (fontSizeVal !== undefined) {
  document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
}})()</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Ⅹ. Harbor" type="application/atom+xml">
</head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/head.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">281</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">145</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">29</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-link"></i><span> Connection</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/link/"><i class="fa-fw fas fa-address-book"></i><span> Friends</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://aierlab.tech"><i class="fa-fw fas fa-sitemap"></i><span> GroupSite</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-wrench"></i><span> Tools</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://wandb.ai/"><i class="fa-fw fas fa-newspaper"></i><span> WandB</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> Article</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archive</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Category</span></a></li><li><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></li></ul></div></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://img2.huashi6.com/images/resource/thumbnail/2021/12/05/1496_54694744582.jpg?imageMogr2/quality/100/interlace/1/thumbnail/1000x%3E)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Ⅹ. Harbor</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-link"></i><span> Connection</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/link/"><i class="fa-fw fas fa-address-book"></i><span> Friends</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://aierlab.tech"><i class="fa-fw fas fa-sitemap"></i><span> GroupSite</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-wrench"></i><span> Tools</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://wandb.ai/"><i class="fa-fw fas fa-newspaper"></i><span> WandB</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> Article</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archive</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Category</span></a></li><li><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">【深度学习】生成对抗网络（GAN）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2021-12-13T01:00:14.000Z" title="Created 2021-12-13 09:00:14">2021-12-13</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2021-12-25T06:38:50.000Z" title="Updated 2021-12-25 14:38:50">2021-12-25</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/NoteBook/">NoteBook</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/NoteBook/PythonNote/">PythonNote</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>26min</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h2><p>生成对抗网络（Generative Adversarial Networks）是一种无监督深度学习模型，用来通过计算机生成数据，由Ian J. Goodfellow等人于2014年提出。模型通过框架中（至少）两个模块：生成模型（Generative Model）和判别模型（Discriminative Model）的互相博弈学习产生相当好的输出。生成对抗网络被认为是当前最具前景、最具活跃度的模型之一，目前主要应用于样本数据生成、图像生成、图像修复、图像转换、文本生成等方向。</p>
<p>GAN这种全新的技术在生成方向上带给了人工智能领域全新的突破。在之后的几年中生GAN成为深度学习领域中的研究热点，近几年与GAN有关的论文数量也急速上升，目前数量仍然在持续增加中。</p>
<p><img src="https://image.discover304.top/dl/advcv/GAN%E6%95%B0%E9%87%8F%E5%A2%9E%E9%95%BF%E8%B6%8B%E5%8A%BF.png" alt="GAN数量增长趋势"></p>
<center><font size=2>GAN论文数量增长示意图</font></center>
2018年，对抗式神经网络的思想被《麻省理工科技评论》评选为2018年“全球十大突破性技术”（10 Breakthrough Technologies）之一。 Yann LeCun（“深度学习三巨头”之一，纽约大学教授，前Facebook首席人工智能科学家）称赞生成对抗网络是“过去20年中深度学习领域最酷的思想”，而在国内被大家熟知的前百度首席科学家Andrew Ng也把生成对抗网络看作“深度学习领域中一项非常重大的进步”。

<h2 id="二、GAN基本原理"><a href="#二、GAN基本原理" class="headerlink" title="二、GAN基本原理"></a>二、GAN基本原理</h2><h3 id="1-构成"><a href="#1-构成" class="headerlink" title="1. 构成"></a>1. 构成</h3><p>GAN由两个重要的部分构成：生成器(Generator，简写作G)和判别器(Discriminator，简写作D)。</p>
<ul>
<li>生成器：通过机器生成数据，目的是尽可能“骗过”判别器，生成的数据记做G(z)；</li>
<li>判别器：判断数据是真实数据还是「生成器」生成的数据，目的是尽可能找出「生成器」造的“假数据”。它的输入参数是x，x代表数据，输出D（x）代表x为真实数据的概率，如果为1，就代表100%是真实的数据，而输出为0，就代表不可能是真实的数据。</li>
</ul>
<p>这样，G和D构成了一个动态对抗（或博弈过程），随着训练（对抗）的进行，G生成的数据越来越接近真实数据，D鉴别数据的水平越来越高。在理想的状态下，G可以生成足以“以假乱真”的数据；而对于D来说，它难以判定生成器生成的数据究竟是不是真实的，因此D(G(z)) &#x3D; 0.5。训练完成后，我们得到了一个生成模型G，它可以用来生成以假乱真的数据。</p>
<p><img src="https://image.discover304.top/dl/advcv/GAN.jpeg" alt="GAN"></p>
<center><font size=2>GAN示意图</font></center>
### 2. 训练过程

<ul>
<li>第一阶段：固定「判别器D」，训练「生成器G」。使用一个性能不错的判别器，G不断生成“假数据”，然后给这个D去判断。开始时候，G还很弱，所以很容易被判别出来。但随着训练不断进行，G技能不断提升，最终骗过了D。这个时候，D基本属于“瞎猜”的状态，判断是否为假数据的概率为50%。</li>
<li>第二阶段：固定「生成器G」，训练「判别器D」。当通过了第一阶段，继续训练G就没有意义了。这时候我们固定G，然后开始训练D。通过不断训练，D提高了自己的鉴别能力，最终他可以准确判断出假数据。</li>
<li>重复第一阶段、第二阶段。通过不断的循环，「生成器G」和「判别器D」的能力都越来越强。最终我们得到了一个效果非常好的「生成器G」，就可以用它来生成数据。</li>
</ul>
<h3 id="3-GAN的优缺点"><a href="#3-GAN的优缺点" class="headerlink" title="3. GAN的优缺点"></a>3. GAN的优缺点</h3><p>1）优点</p>
<ul>
<li>能更好建模数据分布（图像更锐利、清晰）；</li>
<li>理论上，GANs 能训练任何一种生成器网络。其他的框架需要生成器网络有一些特定的函数形式，比如输出层是高斯的；</li>
<li>无需利用马尔科夫链反复采样，无需在学习过程中进行推断，没有复杂的变分下界，避开近似计算棘手的概率的难题。</li>
</ul>
<p>2）缺点</p>
<ul>
<li>模型难以收敛，不稳定。生成器和判别器之间需要很好的同步，但是在实际训练中很容易D收敛，G发散。D&#x2F;G 的训练需要精心的设计。</li>
<li>模式缺失（Mode Collapse）问题。GANs的学习过程可能出现模式缺失，生成器开始退化，总是生成同样的样本点，无法继续学习。</li>
</ul>
<h3 id="4-GAN的应用"><a href="#4-GAN的应用" class="headerlink" title="4. GAN的应用"></a>4. GAN的应用</h3><h4 id="1）生成数据集"><a href="#1）生成数据集" class="headerlink" title="1）生成数据集"></a>1）生成数据集</h4><p>人工智能的训练是需要大量的数据集，可以通过GAN自动生成低成本的数据集。</p>
<h4 id="2）人脸生成"><a href="#2）人脸生成" class="headerlink" title="2）人脸生成"></a>2）人脸生成</h4><p><img src="https://image.discover304.top/dl/advcv/GAN%E7%94%9F%E6%88%90%E4%BA%BA%E8%84%B8.png" alt="GAN生成人脸"></p>
<h4 id="3）物品生成"><a href="#3）物品生成" class="headerlink" title="3）物品生成"></a>3）物品生成</h4><p><img src="https://image.discover304.top/dl/advcv/GAN%E7%89%A9%E5%93%81%E7%94%9F%E6%88%90.png" alt="GAN物品生成"></p>
<h4 id="4）图像转换"><a href="#4）图像转换" class="headerlink" title="4）图像转换"></a>4）图像转换</h4><p><img src="https://image.discover304.top/dl/advcv/GAN%E5%9B%BE%E5%83%8F%E8%BD%AC%E6%8D%A2.png" alt="GAN图像转换"></p>
<h4 id="5）图像修复"><a href="#5）图像修复" class="headerlink" title="5）图像修复"></a>5）图像修复</h4><p><img src="https://image.discover304.top/dl/advcv/GAN%E7%85%A7%E7%89%87%E4%BF%AE%E5%A4%8D.png" alt="GAN照片修复"></p>
<h2 id="三、GAN的数学原理"><a href="#三、GAN的数学原理" class="headerlink" title="三、GAN的数学原理"></a>三、GAN的数学原理</h2><h3 id="1-GAN的数学推导"><a href="#1-GAN的数学推导" class="headerlink" title="1.GAN的数学推导"></a>1.GAN的数学推导</h3><p>生成模型会从一个输入空间将数据映射到生成空间（即通过输入数据，在函数作用下生成输出数据），写成公式的形式是x&#x3D;G（z）。通常，输入z会满足一个简单形式的随机分布（比如高斯分布或者均匀分布等），为了使得生成的数据分布能够尽可能地逼近真实数据分布，生成函数G会是一个神经网络的形式，通过神经网络可以模拟出各种完全不同的分布类型。</p>
<p>以下是生成对抗网络中的代价函数，以判别器D为例，代价函数写作$J^{（D）}$，形式如下所示:</p>
<p><img src="https://image.discover304.top/dl/advcv/GAN%E7%9A%84%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0.png" alt="GAN的代价函数"></p>
<p>其中，E表示期望概率，$x \sim P_{data}$表示x满足$P_{data}$分布。</p>
<p>对于生成器来说它与判别器是紧密相关的，我们可以把两者看作一个零和博弈，它们的代价综合应该是零，所以生成器的代价函数应满足如下等式：<br>$$<br>J^{(G)} &#x3D; -J^{(D)}<br>$$<br>这样一来，我们可以设置一个价值函数V来表示$J^{（G）}$和$J^{（D）}$：</p>
<p><img src="https://image.discover304.top/dl/advcv/GAN%E7%9A%84%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0%E5%8F%98%E5%BD%A2.png" alt="GAN的代价函数变形"></p>
<p>我们现在把问题变成了需要寻找一个合适的$V(θ^{(D)}，θ^{(G)})$使得$J^{（G）}$和$J^{（D）}$都尽可能小，也就是说**对于判别器而言越大越$V(θ^{(D)}，θ^{(G)})$好，而对于生成器来说则是越小越好$V(θ^{(D)}，θ^{(G)})$**，从而形成了两者之间的博弈关系。</p>
<p>在博弈论中，博弈双方的决策组合会形成一个纳什平衡点（Nash equilibrium），在这个博弈平衡点下博弈中的任何一方将无法通过自身的行为而增加自己的收益。在生成对抗网络中，我们要计算的纳什平衡点正是要寻找一个生成器G与判别器D使得各自的代价函数最小，从上面的推导中也可以得出我们希望找到一个$V(θ^{(D)}，θ^{(G)})$对于生成器来说最小而对判别器来说最大，我们可以把它定义成一个寻找极大极小值的问题，公式如下所示：</p>
<p><img src="https://image.discover304.top/dl/advcv/GAN%E6%9E%81%E5%A4%A7%E5%80%BC%E6%9E%81%E5%B0%8F%E5%80%BC.png" alt="GAN极大值极小值"></p>
<p>我们可以用图形化的方法理解一下这个极大极小值的概念，一个很好的例子就是鞍点（saddle point），如下图所示，即在一个方向是函数的极大值点，而在另一个方向是函数的极小值点。</p>
<p><img src="https://image.discover304.top/dl/advcv/%E9%9E%8D%E7%82%B9.png" alt="鞍点"></p>
<p>在上面公式的基础上，我们可以分别求出理想的判别器D*和生成器G*：</p>
<p><img src="https://image.discover304.top/dl/advcv/GAN%E7%90%86%E6%83%B3%E5%88%A4%E5%88%AB%E5%99%A8%E7%94%9F%E6%88%90%E5%99%A8.png" alt="GAN理想判别器生成器"></p>
<p>下面我们先来看一下如何求出理想的判别器，对于上述的D*，我们假定生成器G是固定的，令式子中的G（z）&#x3D;x。推导如下：</p>
<p><img src="https://image.discover304.top/dl/advcv/GAN%E7%90%86%E6%83%B3%E5%88%A4%E5%88%AB%E5%99%A8%E6%8E%A8%E5%AF%BC1.png" alt="GAN理想判别器推导1"></p>
<p>我们现在的目标是希望寻找一个D使得V最大，我们希望对于积分中的项$f（x）&#x3D;p_{data}（x）logD（x）＋p_g（x）log（1-D（x））$，无论x取何值都能最大。其中，我们已知$p_data$是固定的，之前我们也假定生成器G固定，所以$p_g$也是固定的，所以我们可以很容易地求出D以使得f（x）最大。我们假设x固定，f（x）对D（x）求导等于零，下面是求解D（x）的推导。</p>
<p><img src="https://image.discover304.top/dl/advcv/GAN%E7%90%86%E6%83%B3%E5%88%A4%E5%88%AB%E5%99%A8%E6%8E%A8%E5%AF%BC2.png" alt="GAN理想判别器推导2"></p>
<p>可以看出它是一个范围在0到1的值，这也符合我们判别器的模式，理想的判别器在接收到真实数据时应该判断为1，而对于生成数据则应该判断为0，当生成数据分布与真实数据分布非常接近的时候，应该输出的结果为1&#x2F;2.</p>
<p>找到了D*之后，我们再来推导一下生成器G*。现在先把D*（x）代入前面的积分式子中重新表示：</p>
<p><img src="https://image.discover304.top/dl/advcv/GAN%E7%94%9F%E6%88%90%E5%99%A8%E5%87%BD%E6%95%B0%E6%8E%A8%E5%AF%BC1.png" alt="GAN生成器函数推导1"></p>
<p>到了这一步，我们需要先介绍一个定义——Jensen–Shannon散度，我们这里简称JS散度。在概率统计中，JS散度也与前面提到的KL散度一样具备了测量两个概率分布相似程度的能力，它的计算方法基于KL散度，继承了KL散度的非负性等，但有一点重要的不同，JS散度具备了对称性。JS散度的公式如下，我们还是以P和Q作为例子，另外我们设定$M&#x3D;\frac{1}{2}(P+Q)$，KL为KL散度公式。</p>
<p><img src="https://image.discover304.top/dl/advcv/GAN%E7%94%9F%E6%88%90%E5%99%A8%E5%87%BD%E6%95%B0%E6%8E%A8%E5%AF%BC2.png" alt="GAN生成器函数推导2"></p>
<p>对于上面的$MaxV(G,D)$，由于JS散度是非负的，当且仅当$p_{data}&#x3D;p_g$的时候，上式可以取得全局最小值$-log（4）$。所以我们要求的最优生成器G*，正是要使得G*的分布$p_g&#x3D;p_{data}$.</p>
<h3 id="2-GAN的可视化理解"><a href="#2-GAN的可视化理解" class="headerlink" title="2. GAN的可视化理解"></a>2. GAN的可视化理解</h3><p>下面我们用一个可视化概率分布的例子来更深入地认识一下生成对抗网络。Ian Goodfellow的论中给出了这样一个GAN的可视化实现的例子：下图中的点线为真实数据分布，曲线为生成数据样本，生成对抗网络在这个例子中的目标在于，让曲线（也就是生成数据的分布）逐渐逼近点线（代表的真实数据分布）。</p>
<p><img src="https://image.discover304.top/dl/advcv/GAN%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E7%90%86%E8%A7%A3.png" alt="GAN的可视化理解"></p>
<p>虚线为生成对抗网络中的判别器，它被赋予了初步区分真实数据与生成数据的能力，并对于它的划分性能加上一定的白噪声，使得模拟环境更为真实。输入域为z（图中下方的直线）在这个例子里默认为一个均匀分布的数据，生成域为x（图中上方的直线）为不均匀分布数据，通过生成函数x&#x3D;G（z）形成一个映射关系，如图中的那些箭头所示，将均匀分布的数据映射成非均匀数据。</p>
<p>从a到d的四张图可以展现整个生成对抗网络的运作过程。在a图中，可以说是一种初始的状态，生成数据与真实数据还有比较大的差距，判别器具备初步划分是否为真实数据的能力，但是由于存在噪声，效果仍有缺陷。b图中，通过使用两类标签数据对于判别器的训练，判别器D开始逐渐向一个比较完善的方向收敛，最终呈现出图中的结果。当判别器逐渐完美后，我们开始迭代生成器G，如图c所示。通过判别器D的倒数梯度方向作为指导，我们让生成数据向真实数据的分布方向移动，让生成数据更容易被判别器判断为真实数据。在反复的一系列上述训练过程后，生成器与判别器会进入图d的最终状态，此时$p_g$会非常逼近甚至完全等于$p_{data}$，当达到理想的$p_g&#x3D;p_{data}$的时候，D与G都已经无法再更进一步优化了，此时G生成的数据已经达到了我们期望的目的，能够完全模拟出真实数据的分布，而D在这个状态下已经无法分辨两种数据分布（因为它们完全相同），此时$D(x)&#x3D;\frac{1}{2}$.</p>
<h2 id="四、DCGAN"><a href="#四、DCGAN" class="headerlink" title="四、DCGAN"></a>四、DCGAN</h2><h3 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h3><p>DCGAN的创始论文《Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks》（基于深层卷积生成对抗网络的无监督表示学习）发表于2015年，文章在GAN的基础之上提出了全新的DCGAN架构，该网络在训练过程中状态稳定，并可以有效实现高质量的图片生成及相关的生成模型应用。由于其具有非常强的实用性，在它之后的大量GAN模型都是基于DCGAN进行的改良版本。为了使得GAN能够很好地适应于卷积神经网络架构，DCGAN提出了四点架构设计规则，分别是：</p>
<ul>
<li>使用卷积层替代池化层。首先第一点是把传统卷积网络中的池化层全部去除，使用卷积层代替。对于判别器，我们使用步长卷积（strided convolution）来代替池化层；对于生成器，我们使用分数步长卷积（fractional-strided convolutions）来代替池化层。</li>
<li>去除全连接层。目前的研究趋势中我们会发现非常多的研究都在试图去除全连接层，常规的卷积神经网络往往会在卷积层后添加全连接层用以输出最终向量，但我们知道全连接层的缺点在于参数过多，当神经网络层数深了以后运算速度会变得非常慢，此外全连接层也会使得网络容易过度拟合。有研究使用了全局平均池化（global average pooling）来替代全连接层，可以使得模型更稳定，但也影响了收敛速度。论文中说的一种折中方案是将生成器的随机输入直接与卷积层特征输入进行连接，同样地对于判别器的输出层也是与卷积层的输出特征连接，具体的操作会在后面的框架结构介绍中说明。</li>
<li>使用批归一化（batch normalization）。由于深度学习的神经网络层数很多，每一层都会使得输出数据的分布发生变化，随着层数的增加网络的整体偏差会越来越大。批归一化的目标则是为了解决这一问题，通过对每一层的输入进行归一化处理，能够有效使得数据服从某个固定的数据分布。</li>
<li>使用恰当的激活函数。在DCGAN网络框架中，生成器和判别器使用了不同的激活函数来设计。生成器中使用ReLU函数，但对于输出层使用了Tanh激活函数，因为研究者们在实验中观察到使用有边界的激活函数可以让模型更快地进行学习，并能快速覆盖色彩空间。而在判别器中对所有层均使用LeakyReLU，在实际使用中尤其适用于高分辨率的图像判别模型。这些激活函数的选择是研究者在多次实验测试中得出的结论，可以有效使得DCGAN得到最优的结果。</li>
</ul>
<h3 id="2-网络结构"><a href="#2-网络结构" class="headerlink" title="2. 网络结构"></a>2. 网络结构</h3><p>下图是DCGAN生成器G的架构图，输入数据为100维的随机数据z，服从范围在[-1，1]的均匀分布，经过一系列分数步长卷积后，最后形成一幅64×64×3的RGB图片，与训练图片大小一致。</p>
<p><img src="https://image.discover304.top/dl/advcv/DCGAN_%E7%94%9F%E6%88%90%E5%99%A8%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84.png" alt="DCGAN_生成器网络结构"></p>
<p>对于判别器D的架构，基本是生成器G的反向操作，如下图所示。输入层为64×64×3的图像数据，经过一系列卷积层降低数据的维度，最终输出的是一个二分类数据。</p>
<p><img src="https://image.discover304.top/dl/advcv/DCGAN_%E5%88%A4%E5%88%AB%E5%99%A8%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84.png" alt="DCGAN_判别器网络结构"></p>
<h3 id="3-训练细节"><a href="#3-训练细节" class="headerlink" title="3. 训练细节"></a>3. 训练细节</h3><p>1）对于用于训练的图像数据样本，仅将数据缩放到[-1，1]的范围内，这个也是tanh的取值范围，并不做任何其他处理。</p>
<p>2）模型均采用Mini-Batch大小为128的批量随机梯度下降方法进行训练。权重的初始化使用满足均值为0、方差为0.02的高斯分布的随机变量。</p>
<p>3）对于激活函数LeakyReLU，其中Leak的部分设置斜率为0.2。</p>
<p>4）训练过程中使用Adam优化器进行超参数调优。学习率使用0.0002，动量β1取0.5，使得训练更加稳定。</p>
<h2 id="五、实现DCGAN"><a href="#五、实现DCGAN" class="headerlink" title="五、实现DCGAN"></a>五、实现DCGAN</h2><h3 id="1-任务目标"><a href="#1-任务目标" class="headerlink" title="1. 任务目标"></a>1. 任务目标</h3><p>实现DCGAN，并利用其合成卡通人物头像。</p>
<h3 id="2-数据集"><a href="#2-数据集" class="headerlink" title="2. 数据集"></a>2. 数据集</h3><p>样本内容：卡通人物头像</p>
<p>样本数量：51223个</p>
<p><img src="https://image.discover304.top/dl/advcv/avatar%E6%A0%B7%E6%9C%AC%E7%A4%BA%E4%BE%8B.png" alt="avatar样本示例"></p>
<h3 id="3-代码清单"><a href="#3-代码清单" class="headerlink" title="3. 代码清单"></a>3. 代码清单</h3><p>1）avatar.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> scipy.misc</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> glob <span class="keyword">import</span> glob</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Avatar(化身)类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Avatar</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.data_name = <span class="string">&#x27;faces&#x27;</span></span><br><span class="line">        <span class="variable language_">self</span>.source_shape = (<span class="number">96</span>, <span class="number">96</span>, <span class="number">3</span>)</span><br><span class="line">        <span class="variable language_">self</span>.resize_shape = (<span class="number">48</span>, <span class="number">48</span>, <span class="number">3</span>)</span><br><span class="line">        <span class="variable language_">self</span>.crop = <span class="literal">True</span>  <span class="comment"># 裁剪</span></span><br><span class="line">        <span class="variable language_">self</span>.img_shape = <span class="variable language_">self</span>.source_shape <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.crop <span class="keyword">else</span> <span class="variable language_">self</span>.resize_shape  <span class="comment"># 图片形状</span></span><br><span class="line">        <span class="variable language_">self</span>.img_list = <span class="variable language_">self</span>._get_img_list()  <span class="comment"># 加载所有图片</span></span><br><span class="line">        <span class="variable language_">self</span>.batch_size = <span class="number">64</span>  <span class="comment"># batch_size大小</span></span><br><span class="line">        <span class="variable language_">self</span>.batch_shape = (<span class="variable language_">self</span>.batch_size,) + <span class="variable language_">self</span>.img_shape</span><br><span class="line">        <span class="variable language_">self</span>.chunk_size = <span class="built_in">len</span>(<span class="variable language_">self</span>.img_list) // <span class="variable language_">self</span>.batch_size  <span class="comment"># 总批次数量 = 样本数 / 批次大小</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_img_list</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        加载所有图片样本路径</span></span><br><span class="line"><span class="string">        :return:所有图片样本路径列表</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        path = os.path.join(os.getcwd(), <span class="variable language_">self</span>.data_name, <span class="string">&#x27;*.jpg&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> glob(path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_img</span>(<span class="params">self, name</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        读取图像数据</span></span><br><span class="line"><span class="string">        :param name: 图片路径</span></span><br><span class="line"><span class="string">        :return: 图像数据</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">assert</span> name <span class="keyword">in</span> <span class="variable language_">self</span>.img_list</span><br><span class="line">        img = scipy.misc.imread(name).astype(np.float32)  <span class="comment"># 读取图像</span></span><br><span class="line">        <span class="keyword">assert</span> img.shape == <span class="variable language_">self</span>.source_shape</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._resize(img) <span class="keyword">if</span> <span class="variable language_">self</span>.crop <span class="keyword">else</span> img  <span class="comment"># 调整大小并返回</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_resize</span>(<span class="params">self, img</span>):</span><br><span class="line">        h, w = img.shape[:<span class="number">2</span>]</span><br><span class="line">        resize_h, resize_w = <span class="variable language_">self</span>.resize_shape[:<span class="number">2</span>]</span><br><span class="line">        crop_h, crop_w = <span class="variable language_">self</span>.source_shape[:<span class="number">2</span>]</span><br><span class="line">        j = <span class="built_in">int</span>(<span class="built_in">round</span>((h - crop_h) / <span class="number">2.</span>))</span><br><span class="line">        i = <span class="built_in">int</span>(<span class="built_in">round</span>((w - crop_w) / <span class="number">2.</span>))</span><br><span class="line">        cropped_image = scipy.misc.imresize(img[j:j + crop_h, i:i + crop_w], [resize_h, resize_w])</span><br><span class="line">        <span class="keyword">return</span> np.array(cropped_image) / <span class="number">127.5</span> - <span class="number">1.</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save_img</span>(<span class="params">image, path</span>):</span><br><span class="line">        scipy.misc.imsave(path, image)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">batches</span>(<span class="params">self</span>):</span><br><span class="line">        start = <span class="number">0</span></span><br><span class="line">        end = <span class="variable language_">self</span>.batch_size</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.chunk_size):</span><br><span class="line">            name_list = <span class="variable language_">self</span>.img_list[start:end]</span><br><span class="line">            imgs = [<span class="variable language_">self</span>._get_img(name) <span class="keyword">for</span> name <span class="keyword">in</span> name_list]</span><br><span class="line">            batches = np.zeros(<span class="variable language_">self</span>.batch_shape)</span><br><span class="line">            batches[::] = imgs</span><br><span class="line">            <span class="keyword">yield</span> batches</span><br><span class="line">            start += <span class="variable language_">self</span>.batch_size</span><br><span class="line">            end += <span class="variable language_">self</span>.batch_size</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    avatar = Avatar()</span><br><span class="line">    batch = avatar.batches()</span><br><span class="line">    b = <span class="built_in">next</span>(batch)</span><br><span class="line">    <span class="keyword">for</span> num <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(b)):</span><br><span class="line">        avatar.save_img(b[num], <span class="string">&#x27;samples&#x27;</span> + os.sep + <span class="built_in">str</span>(num) + <span class="string">&#x27;.jpg&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>2）avatar_model.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># DCGAN</span></span><br><span class="line"><span class="comment"># Date: 2020/04/30</span></span><br><span class="line"><span class="comment"># Author: wdb</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="comment"># from avatarDcgan.avatar import Avatar</span></span><br><span class="line"><span class="keyword">from</span> avatar <span class="keyword">import</span> Avatar  <span class="comment"># wdb 20200325</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AvatarModel</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.avatar = Avatar()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 真实图片shape (height, width, depth)</span></span><br><span class="line">        <span class="variable language_">self</span>.img_shape = <span class="variable language_">self</span>.avatar.img_shape  <span class="comment"># (48,48,3)</span></span><br><span class="line">        <span class="comment"># 一个batch图片shape (batch, height, width, depth)</span></span><br><span class="line">        <span class="variable language_">self</span>.batch_shape = <span class="variable language_">self</span>.avatar.batch_shape</span><br><span class="line">        <span class="comment"># 一个batch包含的图片数量</span></span><br><span class="line">        <span class="variable language_">self</span>.batch_size = <span class="variable language_">self</span>.avatar.batch_size</span><br><span class="line">        <span class="comment"># batch数量</span></span><br><span class="line">        <span class="variable language_">self</span>.chunk_size = <span class="variable language_">self</span>.avatar.chunk_size</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.noise_img_size = <span class="number">100</span>  <span class="comment"># 白噪声图片大小</span></span><br><span class="line">        <span class="variable language_">self</span>.gf_size = <span class="number">64</span>  <span class="comment"># 卷积转置通道数量</span></span><br><span class="line">        <span class="variable language_">self</span>.df_size = <span class="number">64</span>  <span class="comment"># 卷积输出通道数量</span></span><br><span class="line">        <span class="variable language_">self</span>.epoch_size = <span class="number">1</span>  <span class="comment"># 训练循环次数</span></span><br><span class="line">        <span class="variable language_">self</span>.learning_rate = <span class="number">0.0002</span>  <span class="comment"># 学习率</span></span><br><span class="line">        <span class="variable language_">self</span>.beta1 = <span class="number">0.5</span>  <span class="comment"># 优化指数衰减率</span></span><br><span class="line">        <span class="variable language_">self</span>.sample_size = <span class="number">64</span>  <span class="comment"># 生成图像数量(和avatar类中batch_size数量要一致, 不然生成图像报错)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">conv_out_size_same</span>(<span class="params">size, stride</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        计算每层高度、宽度</span></span><br><span class="line"><span class="string">        :param size:</span></span><br><span class="line"><span class="string">        :param stride:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">int</span>(math.ceil(<span class="built_in">float</span>(size) / <span class="built_in">float</span>(stride)))</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">linear</span>(<span class="params">images, output_size, stddev=<span class="number">0.02</span>, bias_start=<span class="number">0.0</span>, name=<span class="string">&quot;Linear&quot;</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        计算线性模型 wx + b</span></span><br><span class="line"><span class="string">        :param images: 输入数据 (x)</span></span><br><span class="line"><span class="string">        :param output_size: 输出值大小</span></span><br><span class="line"><span class="string">        :param stddev: 创建正态分布张量的标准差</span></span><br><span class="line"><span class="string">        :param bias_start: 偏置初始值</span></span><br><span class="line"><span class="string">        :param name: 变量作用域名称</span></span><br><span class="line"><span class="string">        :return: 返回计算结果及参数</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        shape = images.get_shape().as_list()  <span class="comment"># 取出输入数据形状并转换为列表</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(name):</span><br><span class="line">            w = tf.get_variable(<span class="string">&quot;w&quot;</span>,  <span class="comment"># 名称</span></span><br><span class="line">                                [shape[<span class="number">1</span>], output_size],  <span class="comment"># 矩阵行、列</span></span><br><span class="line">                                tf.float32,  <span class="comment"># 类型</span></span><br><span class="line">                                tf.random_normal_initializer(stddev=stddev))  <span class="comment"># 初始值</span></span><br><span class="line">            b = tf.get_variable(<span class="string">&quot;b&quot;</span>,  <span class="comment"># 名称</span></span><br><span class="line">                                [output_size],  <span class="comment"># 个数等于列数</span></span><br><span class="line">                                initializer=tf.constant_initializer(bias_start))  <span class="comment"># 初始值</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> tf.matmul(images, w) + b, w, b</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">batch_normailizer</span>(<span class="params">x, epsilon=<span class="number">1e-5</span>, momentum=<span class="number">0.9</span>, train=<span class="literal">True</span>, name=<span class="string">&quot;batch_norm&quot;</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        批量归一化</span></span><br><span class="line"><span class="string">        :param x: 输入</span></span><br><span class="line"><span class="string">        :param epsilon: 给一个很小的值，避免除数为0的情况</span></span><br><span class="line"><span class="string">        :param momentum: 衰减系数, 推荐使用0.9</span></span><br><span class="line"><span class="string">        :param train: 图否处于训练模式</span></span><br><span class="line"><span class="string">        :param name: 变量作用域名称</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(name):</span><br><span class="line">            <span class="keyword">return</span> tf.contrib.layers.batch_norm(x,  <span class="comment"># 输入</span></span><br><span class="line">                                                decay=momentum,  <span class="comment"># 衰减系数, 推荐使用0.9</span></span><br><span class="line">                                                updates_collections=<span class="literal">None</span>,</span><br><span class="line">                                                epsilon=epsilon,  <span class="comment"># 避免被零除</span></span><br><span class="line">                                                scale=<span class="literal">True</span>,  <span class="comment"># 是否缩放</span></span><br><span class="line">                                                is_training=train)  <span class="comment"># 图否处于训练模式</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">conv2d</span>(<span class="params">images, output_dim, stddev=<span class="number">0.02</span>, name=<span class="string">&quot;conv2d&quot;</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        二维卷积</span></span><br><span class="line"><span class="string">        :param images: 图像数据</span></span><br><span class="line"><span class="string">        :param output_dim: 输出数据大小</span></span><br><span class="line"><span class="string">        :param stddev: 创建正态分布张量的标准差</span></span><br><span class="line"><span class="string">        :param name: 变量作用域名称</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(name):</span><br><span class="line">            <span class="comment"># filter: [height, width, in_channels, output_channels]</span></span><br><span class="line">            filter_shape = [<span class="number">5</span>, <span class="number">5</span>, images.get_shape()[-<span class="number">1</span>], output_dim]</span><br><span class="line">            strides_shape = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>]  <span class="comment"># 步长</span></span><br><span class="line"></span><br><span class="line">            w = tf.get_variable(<span class="string">&quot;w&quot;</span>,  <span class="comment"># 名称</span></span><br><span class="line">                                filter_shape,</span><br><span class="line">                                initializer=tf.random_normal_initializer(stddev=stddev))  <span class="comment"># 初始值</span></span><br><span class="line">            b = tf.get_variable(<span class="string">&quot;b&quot;</span>,  <span class="comment"># 名称</span></span><br><span class="line">                                [output_dim],  <span class="comment"># 偏置数量</span></span><br><span class="line">                                initializer=tf.constant_initializer(<span class="number">0.0</span>))  <span class="comment"># 初始值</span></span><br><span class="line">            conv = tf.nn.conv2d(images, w, strides=strides_shape, padding=<span class="string">&quot;SAME&quot;</span>)  <span class="comment"># 卷积运算</span></span><br><span class="line">            conv = tf.reshape(tf.nn.bias_add(conv, b), conv.get_shape())</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> conv</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">deconv2d</span>(<span class="params">images, output_shape, stddev=<span class="number">0.02</span>, name=<span class="string">&quot;deconv2d&quot;</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        反向卷积(也称为转置卷积)</span></span><br><span class="line"><span class="string">        :param images: 图像数据</span></span><br><span class="line"><span class="string">        :param output_dim: 输出数据大小</span></span><br><span class="line"><span class="string">        :param stddev: 创建正态分布张量的标准差</span></span><br><span class="line"><span class="string">        :param name: 变量作用域名称</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(name):</span><br><span class="line">            <span class="comment"># 卷积核形状</span></span><br><span class="line">            filter_shape = [<span class="number">5</span>, <span class="number">5</span>, output_shape[-<span class="number">1</span>], images.get_shape()[-<span class="number">1</span>]]</span><br><span class="line">            strides_shape = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>]  <span class="comment"># 步长</span></span><br><span class="line"></span><br><span class="line">            w = tf.get_variable(<span class="string">&quot;w&quot;</span>,  <span class="comment"># 名称</span></span><br><span class="line">                                filter_shape,</span><br><span class="line">                                initializer=tf.random_normal_initializer(stddev=stddev))  <span class="comment"># 初始值</span></span><br><span class="line">            b = tf.get_variable(<span class="string">&quot;biases&quot;</span>,  <span class="comment"># 名称</span></span><br><span class="line">                                [output_shape[-<span class="number">1</span>]],  <span class="comment"># 偏置数量</span></span><br><span class="line">                                initializer=tf.constant_initializer(<span class="number">0.0</span>))  <span class="comment"># 初始值</span></span><br><span class="line">            deconv = tf.nn.conv2d_transpose(images,</span><br><span class="line">                                            w,</span><br><span class="line">                                            output_shape=output_shape,</span><br><span class="line">                                            strides=strides_shape)</span><br><span class="line">            deconv = tf.nn.bias_add(deconv, b)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> deconv, w, b</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">lrelu</span>(<span class="params">x, leak=<span class="number">0.2</span></span>):</span><br><span class="line">        <span class="keyword">return</span> tf.maximum(x, leak * x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">generator</span>(<span class="params">self, noise_imgs, train=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        生成器</span></span><br><span class="line"><span class="string">        :param noise_imgs: 输入(白噪声)</span></span><br><span class="line"><span class="string">        :param train: 是否为训练模式</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;generator&quot;</span>):</span><br><span class="line">            <span class="comment"># 计算每一层的高、宽</span></span><br><span class="line">            s_h, s_w, _ = <span class="variable language_">self</span>.img_shape  <span class="comment"># 48*48*3</span></span><br><span class="line">            s_h2, s_w2 = <span class="variable language_">self</span>.conv_out_size_same(s_h, <span class="number">2</span>), <span class="variable language_">self</span>.conv_out_size_same(s_w, <span class="number">2</span>)  <span class="comment"># 24,24</span></span><br><span class="line">            s_h4, s_w4 = <span class="variable language_">self</span>.conv_out_size_same(s_h2, <span class="number">2</span>), <span class="variable language_">self</span>.conv_out_size_same(s_w2, <span class="number">2</span>)  <span class="comment"># 12,12</span></span><br><span class="line">            s_h8, s_w8 = <span class="variable language_">self</span>.conv_out_size_same(s_h4, <span class="number">2</span>), <span class="variable language_">self</span>.conv_out_size_same(s_w4, <span class="number">2</span>)  <span class="comment"># 6,6</span></span><br><span class="line">            s_h16, s_w16 = <span class="variable language_">self</span>.conv_out_size_same(s_h8, <span class="number">2</span>), <span class="variable language_">self</span>.conv_out_size_same(s_w8, <span class="number">2</span>)  <span class="comment"># 3,3</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># layer 0: 输入层</span></span><br><span class="line">            <span class="comment"># 对输入噪音图片进行线性变换</span></span><br><span class="line">            z, h0_w, h0_b = <span class="variable language_">self</span>.linear(noise_imgs,</span><br><span class="line">                                        <span class="variable language_">self</span>.gf_size * <span class="number">8</span> * s_h16 * s_w16)  <span class="comment"># 64*8*3*3=4608</span></span><br><span class="line">            <span class="comment"># reshape为合适的输入层格式</span></span><br><span class="line">            h0 = tf.reshape(z, [-<span class="number">1</span>, s_h16, s_w16, <span class="variable language_">self</span>.gf_size * <span class="number">8</span>])  <span class="comment"># [-1, 3, 3, 512]</span></span><br><span class="line">            <span class="comment"># 批量归一化, 加快收敛速度</span></span><br><span class="line">            h0 = <span class="variable language_">self</span>.batch_normailizer(h0, train=train, name=<span class="string">&quot;g_bn0&quot;</span>)</span><br><span class="line">            h0 = tf.nn.relu(h0)  <span class="comment"># 激活</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># layer 1: 反卷积进行上采样(对图像填充数据进行放大)</span></span><br><span class="line">            h1, h1_w, h1_b = <span class="variable language_">self</span>.deconv2d(h0,</span><br><span class="line">                                           [<span class="variable language_">self</span>.batch_size, s_h8, s_w8, <span class="variable language_">self</span>.gf_size * <span class="number">4</span>],  <span class="comment"># [32,6,6,256]</span></span><br><span class="line">                                           name=<span class="string">&quot;g_h1&quot;</span>)</span><br><span class="line">            h1 = <span class="variable language_">self</span>.batch_normailizer(h1, train=train, name=<span class="string">&quot;g_bn1&quot;</span>)</span><br><span class="line">            h1 = tf.nn.relu(h1)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># layer 2: 反卷积</span></span><br><span class="line">            h2, h2_w, h2_b = <span class="variable language_">self</span>.deconv2d(h1,</span><br><span class="line">                                           [<span class="variable language_">self</span>.batch_size, s_h4, s_w4, <span class="variable language_">self</span>.gf_size * <span class="number">2</span>],  <span class="comment"># [32,12,12,128]</span></span><br><span class="line">                                           name=<span class="string">&quot;g_h2&quot;</span>)</span><br><span class="line">            h2 = <span class="variable language_">self</span>.batch_normailizer(h2, train=train, name=<span class="string">&quot;g_bn2&quot;</span>)</span><br><span class="line">            h2 = tf.nn.relu(h2)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># layer 3: 反卷积</span></span><br><span class="line">            h3, h3_w, h3_b = <span class="variable language_">self</span>.deconv2d(h2,</span><br><span class="line">                                           [<span class="variable language_">self</span>.batch_size, s_h2, s_w2, <span class="variable language_">self</span>.gf_size * <span class="number">1</span>],  <span class="comment"># [32,24,24,64]</span></span><br><span class="line">                                           name=<span class="string">&quot;g_h3&quot;</span>)</span><br><span class="line">            h3 = tf.nn.relu(h3)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># layer 4: 反卷积</span></span><br><span class="line">            h4, h4_w, h4_b = <span class="variable language_">self</span>.deconv2d(h3, <span class="variable language_">self</span>.batch_shape, name=<span class="string">&quot;g_h4&quot;</span>)  <span class="comment"># [32,48,48]</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> tf.nn.tanh(h4)  <span class="comment"># 激活函数计算并返回</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">discriminator</span>(<span class="params">self, real_imgs, reuse=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        判别器</span></span><br><span class="line"><span class="string">        :param real_imgs: 图像数据</span></span><br><span class="line"><span class="string">        :param reuse: 是否重用名字空间</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;discriminator&quot;</span>, reuse=reuse):</span><br><span class="line">            <span class="comment"># layer 0: 卷积</span></span><br><span class="line">            h0 = <span class="variable language_">self</span>.conv2d(real_imgs, <span class="variable language_">self</span>.df_size, name=<span class="string">&quot;d_h0_conv&quot;</span>)</span><br><span class="line">            h0 = <span class="variable language_">self</span>.lrelu(h0)  <span class="comment"># 激活</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># layer 1</span></span><br><span class="line">            h1 = <span class="variable language_">self</span>.conv2d(h0, <span class="variable language_">self</span>.df_size * <span class="number">2</span>, name=<span class="string">&quot;d_h1_conv&quot;</span>)</span><br><span class="line">            h1 = <span class="variable language_">self</span>.batch_normailizer(h1, name=<span class="string">&quot;d_bn1&quot;</span>)  <span class="comment"># 批量归一化</span></span><br><span class="line">            h1 = <span class="variable language_">self</span>.lrelu(h1)  <span class="comment"># 激活</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># layer 2</span></span><br><span class="line">            h2 = <span class="variable language_">self</span>.conv2d(h1, <span class="variable language_">self</span>.df_size * <span class="number">4</span>, name=<span class="string">&quot;d_h2_conv&quot;</span>)</span><br><span class="line">            h2 = <span class="variable language_">self</span>.batch_normailizer(h2, name=<span class="string">&quot;d_bn2&quot;</span>)  <span class="comment"># 批量归一化</span></span><br><span class="line">            h2 = <span class="variable language_">self</span>.lrelu(h2)  <span class="comment"># 激活</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># layer 3</span></span><br><span class="line">            h3 = <span class="variable language_">self</span>.conv2d(h2, <span class="variable language_">self</span>.df_size * <span class="number">8</span>, name=<span class="string">&quot;d_h3_conv&quot;</span>)</span><br><span class="line">            h3 = <span class="variable language_">self</span>.batch_normailizer(h3, name=<span class="string">&quot;d_bn3&quot;</span>)  <span class="comment"># 批量归一化</span></span><br><span class="line">            h3 = <span class="variable language_">self</span>.lrelu(h3)  <span class="comment"># 激活</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># layer 4</span></span><br><span class="line">            h4, _, _ = <span class="variable language_">self</span>.linear(tf.reshape(h3, [<span class="variable language_">self</span>.batch_size, -<span class="number">1</span>]),</span><br><span class="line">                                   <span class="number">1</span>,</span><br><span class="line">                                   name=<span class="string">&quot;d_h4_lin&quot;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> tf.nn.sigmoid(h4), h4</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">loss_graph</span>(<span class="params">real_logits, fake_logits</span>):</span><br><span class="line">        <span class="comment"># 生成器loss</span></span><br><span class="line">        <span class="comment"># 生成器希望判别器判断出来标签为1</span></span><br><span class="line">        gen_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_logits,</span><br><span class="line">                                                                          labels=tf.ones_like(fake_logits)))</span><br><span class="line">        <span class="comment"># 判别器识别生成的图片loss</span></span><br><span class="line">        <span class="comment"># 判别器希望识别出来的标签为0</span></span><br><span class="line">        fake_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_logits,</span><br><span class="line">                                                                           labels=tf.zeros_like(fake_logits)))</span><br><span class="line">        <span class="comment"># 判别器识别真实图片loss</span></span><br><span class="line">        <span class="comment"># 判别器希望识别出来标签全为1</span></span><br><span class="line">        real_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=real_logits,</span><br><span class="line">                                                                           labels=tf.ones_like(real_logits)))</span><br><span class="line">        <span class="comment"># 判别器总的loss</span></span><br><span class="line">        <span class="comment"># 对真实图片和生成图片总体判别结果</span></span><br><span class="line">        dis_loss = tf.add(fake_loss, real_loss)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> gen_loss, fake_loss, real_loss, dis_loss</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">optimizer_graph</span>(<span class="params">gen_loss, dis_loss, learning_rate, beta1</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        定义优化器</span></span><br><span class="line"><span class="string">        :param gen_loss: 生成器损失函数</span></span><br><span class="line"><span class="string">        :param dis_loss: 判别器损失函数</span></span><br><span class="line"><span class="string">        :param learning_rate: 学习率</span></span><br><span class="line"><span class="string">        :param beta1: 衰减率</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        train_vars = tf.trainable_variables()</span><br><span class="line">        <span class="comment"># 生成器变量</span></span><br><span class="line">        gen_vars = [var <span class="keyword">for</span> var <span class="keyword">in</span> train_vars <span class="keyword">if</span> var.name.startswith(<span class="string">&quot;generator&quot;</span>)]</span><br><span class="line">        <span class="comment"># 判别器变量</span></span><br><span class="line">        dis_vars = [var <span class="keyword">for</span> var <span class="keyword">in</span> train_vars <span class="keyword">if</span> var.name.startswith(<span class="string">&quot;discriminator&quot;</span>)]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 优化器</span></span><br><span class="line">        <span class="comment"># beta1: 衰减率</span></span><br><span class="line">        <span class="comment"># var_list: 优化的变量</span></span><br><span class="line">        gen_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate,</span><br><span class="line">                                               beta1=beta1).minimize(gen_loss, var_list=gen_vars)</span><br><span class="line">        dis_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate,</span><br><span class="line">                                               beta1=beta1).minimize(dis_loss, var_list=dis_vars)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> gen_optimizer, dis_optimizer</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        训练</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 真实图像</span></span><br><span class="line">        real_imgs = tf.placeholder(tf.float32, <span class="variable language_">self</span>.batch_shape, name=<span class="string">&quot;real_images&quot;</span>)</span><br><span class="line">        <span class="comment"># 白噪声图像</span></span><br><span class="line">        noise_imgs = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="variable language_">self</span>.noise_img_size], name=<span class="string">&quot;noise_images&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 生成图像</span></span><br><span class="line">        fake_imgs = <span class="variable language_">self</span>.generator(noise_imgs)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 判别</span></span><br><span class="line">        <span class="comment">## 对真实图像进行判别</span></span><br><span class="line">        real_outputs, real_logits = <span class="variable language_">self</span>.discriminator(real_imgs)</span><br><span class="line">        <span class="comment">## 对生成器生成的图像进行判别</span></span><br><span class="line">        fake_outputs, fake_logits = <span class="variable language_">self</span>.discriminator(fake_imgs, reuse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取损失函数</span></span><br><span class="line">        gen_loss, fake_loss, real_loss, dis_loss = <span class="variable language_">self</span>.loss_graph(real_logits, fake_logits)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 优化器</span></span><br><span class="line">        gen_optimizer, dis_optimizer = <span class="variable language_">self</span>.optimizer_graph(gen_loss,  <span class="comment"># 生成器损失函数</span></span><br><span class="line">                                                             dis_loss,  <span class="comment"># 判别器损失函数</span></span><br><span class="line">                                                             <span class="variable language_">self</span>.learning_rate,  <span class="comment"># 学习率</span></span><br><span class="line">                                                             <span class="variable language_">self</span>.beta1)  <span class="comment"># 衰减率</span></span><br><span class="line">        <span class="comment"># 开始训练</span></span><br><span class="line">        saver = tf.train.Saver()</span><br><span class="line">        step = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 限定占用GPU比率</span></span><br><span class="line">        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建Session，执行训练</span></span><br><span class="line">        <span class="comment"># 创建Session时通过config来设置参数</span></span><br><span class="line">        <span class="keyword">with</span> tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) <span class="keyword">as</span> sess:</span><br><span class="line">            sess.run(tf.global_variables_initializer())  <span class="comment"># 初始化</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 训练之前，加载增量模型</span></span><br><span class="line">            <span class="keyword">if</span> os.path.exists(<span class="string">&quot;./model/checkpoint&quot;</span>):</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;saver restore:&quot;</span>, os.getcwd())</span><br><span class="line">                <span class="comment"># 获取最后一个检查点文件并加载</span></span><br><span class="line">                saver.restore(sess, tf.train.latest_checkpoint(<span class="string">&quot;./model/&quot;</span>))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.epoch_size):</span><br><span class="line">                batches = <span class="variable language_">self</span>.avatar.batches()  <span class="comment"># 取出一个批次数据</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">for</span> batch_imgs <span class="keyword">in</span> batches:</span><br><span class="line">                    <span class="comment"># 产生一个批次的均匀分布的白噪声数据</span></span><br><span class="line">                    noises = np.random.uniform(-<span class="number">1</span>, <span class="number">1</span>,</span><br><span class="line">                                               size=(<span class="variable language_">self</span>.batch_size, <span class="variable language_">self</span>.noise_img_size)).astype(np.float32)</span><br><span class="line"></span><br><span class="line">                    _ = sess.run(dis_optimizer, feed_dict=&#123;real_imgs: batch_imgs, noise_imgs: noises&#125;)</span><br><span class="line">                    _ = sess.run(gen_optimizer, feed_dict=&#123;noise_imgs: noises&#125;)</span><br><span class="line">                    _ = sess.run(gen_optimizer, feed_dict=&#123;noise_imgs: noises&#125;)</span><br><span class="line"></span><br><span class="line">                    step += <span class="number">1</span></span><br><span class="line">                    <span class="built_in">print</span>(datetime.now().strftime(<span class="string">&quot;%c&quot;</span>), epoch, step)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 每一轮训练结束计算loss</span></span><br><span class="line">                <span class="comment">## 总判别器loss</span></span><br><span class="line">                loss_dis = sess.run(dis_loss, feed_dict=&#123;real_imgs: batch_imgs, noise_imgs: noises&#125;)</span><br><span class="line">                <span class="comment">## 判别器对真实图片loss</span></span><br><span class="line">                loss_real = sess.run(real_loss, feed_dict=&#123;real_imgs: batch_imgs, noise_imgs: noises&#125;)</span><br><span class="line">                <span class="comment">## 判别器对生成的图片loss</span></span><br><span class="line">                loss_fake = sess.run(fake_loss, feed_dict=&#123;real_imgs: batch_imgs, noise_imgs: noises&#125;)</span><br><span class="line">                <span class="comment">## 生成器loss</span></span><br><span class="line">                loss_gen = sess.run(gen_loss, feed_dict=&#123;noise_imgs: noises&#125;)</span><br><span class="line"></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;&quot;</span>)</span><br><span class="line">                <span class="built_in">print</span>(datetime.now().strftime(<span class="string">&#x27;%c&#x27;</span>), <span class="string">&#x27; epoch:&#x27;</span>, epoch, <span class="string">&#x27; step:&#x27;</span>, step, <span class="string">&#x27; loss_dis:&#x27;</span>, loss_dis,</span><br><span class="line">                      <span class="string">&#x27; loss_real:&#x27;</span>, loss_real, <span class="string">&#x27; loss_fake:&#x27;</span>, loss_fake, <span class="string">&#x27; loss_gen:&#x27;</span>, loss_gen)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 训练结束保存模型</span></span><br><span class="line">            model_path = <span class="string">&quot;./model/&quot;</span> + <span class="string">&quot;avatar.model&quot;</span></span><br><span class="line">            saver.save(sess, model_path, global_step=step)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">gen</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        生成图像</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        noise_imgs = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="variable language_">self</span>.noise_img_size],</span><br><span class="line">                                    name=<span class="string">&quot;noise_imgs&quot;</span>)  <span class="comment"># 白噪声</span></span><br><span class="line">        sample_imgs = <span class="variable language_">self</span>.generator(noise_imgs, train=<span class="literal">False</span>)  <span class="comment"># 生成</span></span><br><span class="line">        saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">            sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">            saver.restore(sess, tf.train.latest_checkpoint(<span class="string">&quot;./model/&quot;</span>))  <span class="comment"># 加载模型</span></span><br><span class="line">            <span class="comment"># 生成白噪声</span></span><br><span class="line">            sample_noise = np.random.uniform(-<span class="number">1</span>, <span class="number">1</span>,</span><br><span class="line">                                             size=(<span class="variable language_">self</span>.sample_size, <span class="variable language_">self</span>.noise_img_size))</span><br><span class="line">            <span class="comment"># 执行生成图像操作</span></span><br><span class="line">            samples = sess.run(sample_imgs, feed_dict=&#123;noise_imgs: sample_noise&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 爆存生成的图像</span></span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(samples)):</span><br><span class="line">            <span class="variable language_">self</span>.avatar.save_img(samples[num], <span class="string">&quot;samples&quot;</span> + os.sep + <span class="built_in">str</span>(num) + <span class="string">&quot;.jpg&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>3）avatar_train.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> avatar_model <span class="keyword">import</span> AvatarModel <span class="comment"># wdb 20200325</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    avatar = AvatarModel()</span><br><span class="line">    avatar.train()</span><br></pre></td></tr></table></figure>

<p>4）avatar_gen.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> avatar_model <span class="keyword">import</span> AvatarModel  <span class="comment"># wdb 20200325</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    avatar = AvatarModel()</span><br><span class="line">    avatar.gen()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;图片生成完成.&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="4-实验结果"><a href="#4-实验结果" class="headerlink" title="4. 实验结果"></a>4. 实验结果</h3><p>为了加快训练速度，实际只采用了8903个样本进行训练，执行每20轮一次增量训练。实验结果如下：</p>
<ul>
<li>1轮训练</li>
</ul>
<p><img src="https://image.discover304.top/dl/advcv/avatar_1.png" alt="avatar_1"></p>
<ul>
<li>5轮训练</li>
</ul>
<p><img src="https://image.discover304.top/dl/advcv/avatar_5.png" alt="avatar_5"></p>
<ul>
<li>10轮训练</li>
</ul>
<p><img src="https://image.discover304.top/dl/advcv/avatar_10.png" alt="avatar_10"></p>
<ul>
<li>20轮训练</li>
</ul>
<p><img src="https://image.discover304.top/dl/advcv/avatar_20.png" alt="avatar_20"></p>
<ul>
<li>40轮训练</li>
</ul>
<p><img src="https://image.discover304.top/dl/advcv/avatar_40.png" alt="avatar_40"></p>
<ul>
<li>60轮训练</li>
</ul>
<p><img src="https://image.discover304.top/dl/advcv/avatar_60.png" alt="avatar_60"></p>
<h2 id="六、其它GAN模型"><a href="#六、其它GAN模型" class="headerlink" title="六、其它GAN模型"></a>六、其它GAN模型</h2><p>1）文本生成图像：GAWWN</p>
<p><img src="https://image.discover304.top/dl/advcv/GAWGAN.png" alt="GAWGAN"></p>
<p>2）匹配数据图像转换：Pix2Pix</p>
<p><img src="https://image.discover304.top/dl/advcv/pix2pix.png" alt="pix2pix"></p>
<p>3）非匹配数据图像转换：CycleGAN，用于实现两个领域图片互转</p>
<p><img src="https://image.discover304.top/dl/advcv/CycleGAN.png" alt="CycleGAN"></p>
<p>4）多领域图像转换：StarGAN</p>
<p><img src="https://image.discover304.top/dl/advcv/starGAN.png" alt="starGAN"></p>
<h2 id="七、参考资源"><a href="#七、参考资源" class="headerlink" title="七、参考资源"></a>七、参考资源</h2><h3 id="1-在线视频"><a href="#1-在线视频" class="headerlink" title="1. 在线视频"></a>1. 在线视频</h3><p>1）李宏毅GAN教程：https://www.ixigua.com/pseries/6783110584444387843/?logTag=cZwYY0OhI8vRiNppza2UW</p>
<h3 id="2-书籍"><a href="#2-书籍" class="headerlink" title="2. 书籍"></a>2. 书籍</h3><p>1）《生成对抗网络入门指南》，史丹青编著，机械工业出版社</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:hobart.yang@qq.com">✨白拾ShiroX✨</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://discover304.top/2021/12/13/2021q4/113-3-dl-gan/">https://discover304.top/2021/12/13/2021q4/113-3-dl-gan/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0anime</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%AE%B0%E5%BD%95/">记录</a><a class="post-meta__tags" href="/tags/Python/">Python</a><a class="post-meta__tags" href="/tags/%E5%AD%A6%E4%B9%A0/">学习</a><a class="post-meta__tags" href="/tags/%E7%AC%94%E8%AE%B0/">笔记</a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></div><div class="post_share"><div class="social-share" data-image="https://img2.huashi6.com/images/resource/thumbnail/2021/12/05/1496_54694744582.jpg?imageMogr2/quality/100/interlace/1/thumbnail/1000x%3E" data-sites="facebook,twitter,wechat,weibo,qzone,qq,linkedin"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> Donate<div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/img/wechat.jpg" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/alipay.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/12/13/2021q4/113-4-dl-face/"><img class="prev-cover" src="https://img2.huashi6.com/images/resource/thumbnail/2021/12/05/1496_54694744582.jpg?imageMogr2/quality/100/interlace/1/thumbnail/1000x%3E" onerror="onerror=null;src='/img/404.png'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">【深度学习】人脸检测与人脸识别</div></div></a></div><div class="next-post pull-right"><a href="/2021/12/13/2021q4/113-2-dl-ss/"><img class="next-cover" src="https://img2.huashi6.com/images/resource/thumbnail/2021/12/05/1496_54694744582.jpg?imageMogr2/quality/100/interlace/1/thumbnail/1000x%3E" onerror="onerror=null;src='/img/404.png'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">【深度学习】图像语义分割</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2021/11/30/2021q4/107-1-dl-perceptron/" title="【深度学习】基础 壹：感知机与神经网络"><img class="cover" src="https://image.discover304.top/ai/dl/machine-girl.jpg?imageView2/2/h/300" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2021-12-25</div><div class="title">【深度学习】基础 壹：感知机与神经网络</div></div></a></div><div><a href="/2021/11/30/2021q4/107-1-dl-loss-gd/" title="【深度学习】基础 贰：损失函数与梯度下降"><img class="cover" src="https://image.discover304.top/ai/dl/machine-girl.jpg?imageView2/2/h/300" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2021-12-25</div><div class="title">【深度学习】基础 贰：损失函数与梯度下降</div></div></a></div><div><a href="/2021/11/30/2021q4/107-0-dl/" title="【深度学习】概述"><img class="cover" src="https://image.discover304.top/ai/dl/machine-girl.jpg?imageView2/2/h/300" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2021-12-25</div><div class="title">【深度学习】概述</div></div></a></div><div><a href="/2021/11/30/2021q4/107-1-dl-back/" title="【深度学习】基础 叁：反向传播算法"><img class="cover" src="https://image.discover304.top/ai/dl/machine-girl.jpg?imageView2/2/h/300" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2021-12-25</div><div class="title">【深度学习】基础 叁：反向传播算法</div></div></a></div><div><a href="/2021/12/01/2021q4/108-0-dl-ex/" title="【深度学习】实例第一部分：基础理论"><img class="cover" src="https://image.discover304.top/ai/dl/space_work.jpg?imageView2/2/h/300" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2021-12-25</div><div class="title">【深度学习】实例第一部分：基础理论</div></div></a></div><div><a href="/2021/12/02/2021q4/107-2-dl/" title="【深度学习】图像操作：OpenCV"><img class="cover" src="https://image.discover304.top/ai/dl/02/dog-end-world.jpg?imageView2/2/h/300" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2021-12-25</div><div class="title">【深度学习】图像操作：OpenCV</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside_content" id="aside_content"><div class="card-widget card-info"><div class="card-content"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/head.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">✨白拾ShiroX✨</div><div class="author-info__description">Love Everything You Like.</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">281</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">145</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">29</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://space.bilibili.com/98639326"><i class="fab fa-bilibili"></i><span>Bilibili Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/YangSierCode000" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://x.com/ShiroHiro2024" target="_blank" title="X"><i class="fab fa-x"></i></a><a class="social-icon" href="https://www.youtube.com/channel/UCuQQr55i3VCQuCPMTQnpzDA" target="_blank" title="YouTube"><i class="fab fa-youtube"></i></a><a class="social-icon" href="https://blog.csdn.net/Discover304" target="_blank" title="CSDN"><i class="fa-solid fa-c"></i></a><a class="social-icon" href="https://www.zhihu.com/people/discover-56-86-75" target="_blank" title="知乎"><i class="fa-brands fa-zhihu"></i></a><a class="social-icon" href="mailto:hobart.yang@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://jq.qq.com/?_wv=1027&amp;k=EaGddTQg" target="_blank" title="QQ"><i class="fa-brands fa-qq"></i></a></div></div></div><div class="card-widget card-announcement"><div class="card-content"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">✨动态更新：<p style="text-align:center">享受精彩大学生活中。</p>✨聊天划水QQ群：<p style="text-align:center"><a target="_blank" rel="noopener" href="https://jq.qq.com/?_wv=1027&k=EaGddTQg"><strong>兔叽の魔术工房</strong></a><br>942-848-525</p>✨我们的口号是：<p style="text-align:center; color:#39C5BB">人工降神，机械飞升！</p><a target="_blank" rel="noopener" href='https://space.bilibili.com/98639326'><img src='/img/mikulittletrans.png'></a></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="card-content"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E6%A6%82%E8%BF%B0"><span class="toc-text">一、概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81GAN%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86"><span class="toc-text">二、GAN基本原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%9E%84%E6%88%90"><span class="toc-text">1. 构成</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-GAN%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-text">3. GAN的优缺点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-GAN%E7%9A%84%E5%BA%94%E7%94%A8"><span class="toc-text">4. GAN的应用</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%EF%BC%89%E7%94%9F%E6%88%90%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-text">1）生成数据集</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2%EF%BC%89%E4%BA%BA%E8%84%B8%E7%94%9F%E6%88%90"><span class="toc-text">2）人脸生成</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3%EF%BC%89%E7%89%A9%E5%93%81%E7%94%9F%E6%88%90"><span class="toc-text">3）物品生成</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4%EF%BC%89%E5%9B%BE%E5%83%8F%E8%BD%AC%E6%8D%A2"><span class="toc-text">4）图像转换</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5%EF%BC%89%E5%9B%BE%E5%83%8F%E4%BF%AE%E5%A4%8D"><span class="toc-text">5）图像修复</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81GAN%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86"><span class="toc-text">三、GAN的数学原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-GAN%E7%9A%84%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC"><span class="toc-text">1.GAN的数学推导</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-GAN%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E7%90%86%E8%A7%A3"><span class="toc-text">2. GAN的可视化理解</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81DCGAN"><span class="toc-text">四、DCGAN</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%A6%82%E8%BF%B0"><span class="toc-text">1. 概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="toc-text">2. 网络结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E8%AE%AD%E7%BB%83%E7%BB%86%E8%8A%82"><span class="toc-text">3. 训练细节</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E5%AE%9E%E7%8E%B0DCGAN"><span class="toc-text">五、实现DCGAN</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E4%BB%BB%E5%8A%A1%E7%9B%AE%E6%A0%87"><span class="toc-text">1. 任务目标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-text">2. 数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E4%BB%A3%E7%A0%81%E6%B8%85%E5%8D%95"><span class="toc-text">3. 代码清单</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="toc-text">4. 实验结果</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD%E3%80%81%E5%85%B6%E5%AE%83GAN%E6%A8%A1%E5%9E%8B"><span class="toc-text">六、其它GAN模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%83%E3%80%81%E5%8F%82%E8%80%83%E8%B5%84%E6%BA%90"><span class="toc-text">七、参考资源</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%9C%A8%E7%BA%BF%E8%A7%86%E9%A2%91"><span class="toc-text">1. 在线视频</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E4%B9%A6%E7%B1%8D"><span class="toc-text">2. 书籍</span></a></li></ol></li></ol></div></div></div><div class="card-widget card-recent-post"><div class="card-content"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/02/21/000/" title="【整理】有趣的资料和网站"><img src="https://image.discover304.top/info-girl-see-cropped.jpg?imageView2/2/h/300" onerror="this.onerror=null;this.src='/img/404.png'" alt="【整理】有趣的资料和网站"/></a><div class="content"><a class="title" href="/2022/02/21/000/" title="【整理】有趣的资料和网站">【整理】有趣的资料和网站</a><time datetime="2024-09-21T16:30:45.995Z" title="Updated 2024-09-22 00:30:45">2024-09-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/08/19/188-1-mbzuai-help-link/" title="MBZUAI Quick Access Links"><img src="https://image.discover304.top/1726926639202.png?imageView2/2/h/300" onerror="this.onerror=null;this.src='/img/404.png'" alt="MBZUAI Quick Access Links"/></a><div class="content"><a class="title" href="/2024/08/19/188-1-mbzuai-help-link/" title="MBZUAI Quick Access Links">MBZUAI Quick Access Links</a><time datetime="2024-09-21T13:50:51.419Z" title="Updated 2024-09-21 21:50:51">2024-09-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/09/21/2024q3/195-moe/" title="Navigating the Complexity of Mixture of Experts (MoE) in Multi-Modal Systems"><img src="https://image.discover304.top/1726926461860.png?imageView2/2/h/300" onerror="this.onerror=null;this.src='/img/404.png'" alt="Navigating the Complexity of Mixture of Experts (MoE) in Multi-Modal Systems"/></a><div class="content"><a class="title" href="/2024/09/21/2024q3/195-moe/" title="Navigating the Complexity of Mixture of Experts (MoE) in Multi-Modal Systems">Navigating the Complexity of Mixture of Experts (MoE) in Multi-Modal Systems</a><time datetime="2024-09-21T13:47:51.709Z" title="Updated 2024-09-21 21:47:51">2024-09-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/09/19/2024q3/194-sustainablility/" title="Expanding Sustainability: Space Migration, Long-Lasting Products, and Humanity's Future"><img src="https://image.discover304.top/1726775487424.png?imageView2/2/h/300" onerror="this.onerror=null;this.src='/img/404.png'" alt="Expanding Sustainability: Space Migration, Long-Lasting Products, and Humanity's Future"/></a><div class="content"><a class="title" href="/2024/09/19/2024q3/194-sustainablility/" title="Expanding Sustainability: Space Migration, Long-Lasting Products, and Humanity's Future">Expanding Sustainability: Space Migration, Long-Lasting Products, and Humanity's Future</a><time datetime="2024-09-19T19:51:45.662Z" title="Updated 2024-09-20 03:51:45">2024-09-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/09/08/193-AI701/" title="192-AI701"><img src="https://api.btstu.cn/sjbz/api.php?lx=dongman&amp;format=images" onerror="this.onerror=null;this.src='/img/404.png'" alt="192-AI701"/></a><div class="content"><a class="title" href="/2024/09/08/193-AI701/" title="192-AI701">192-AI701</a><time datetime="2024-09-08T10:54:12.001Z" title="Updated 2024-09-08 18:54:12">2024-09-08</time></div></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(https://img2.huashi6.com/images/resource/thumbnail/2021/12/05/1496_54694744582.jpg?imageMogr2/quality/100/interlace/1/thumbnail/1000x%3E)"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By ✨白拾ShiroX✨</div><div><a target="_blank" href="https://beian.miit.gov.cn/" style="display:inline-block;text-decoration:none;height:20px;line-height:20px;"><p style="float:left;height:20px;line-height:20px;margin: 0px 0px 0px 5px; color:#939393;"> 冀ICP备2021025381号-1</p></a></div><div><a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=13060602001430" style="display:inline-block;text-decoration:none;height:20px;line-height:20px;"><img src="/img/beian.png" style="float:left;"/><p style="float:left;height:20px;line-height:20px;margin: 0px 0px 0px 5px; color:#939393;">冀公网安备 13060602001430号</p></a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="Increase font size"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="Decrease font size"><i class="fas fa-minus"></i></button><button id="translateLink" type="button" title="Switch Between Traditional Chinese And Simplified Chinese">繁</button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.spacingElementById('content-inner')
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.spacingElementById('content-inner')
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> {preloader.endLoading()})</script><div class="js-pjax"><script>if (document.getElementsByClassName('mermaid').length) {
  if (window.mermaidJsLoad) mermaid.init()
  else {
    getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(() => {
      window.mermaidJsLoad = true
      mermaid.initialize({
        theme: 'neutral',
      })
      false && mermaid.init()
    })
  }
}</script><script>function loadValine () {
  function initValine () {
    let initData = {
      el: '#vcomment',
      appId: 'A9RWVELPcIotgfbpp9KLGXQM-gzGzoHsz',
      appKey: 'MLgPQW5h0DPgE8jNkeREKubU',
      placeholder: '欢迎留言呀。（网址是选填，可以留空）',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'zh-CN',
      recordIP: true,
      serverURLs: 'https://a9rwvelp.lc-cn-n1-shared.com',
      emojiCDN: 'https://cdn.jsdelivr.net/gh/GamerNoTitle/ValineCDN@master/',
      emojiMaps: {"QQ1":"QQ/aini.gif","QQ2":"QQ/aixin.gif","QQ3":"QQ/aoman.gif","QQ4":"QQ/baiyan.gif","QQ5":"QQ/bangbangtang.gif","QQ6":"QQ/baojin.gif","QQ7":"QQ/baoquan.gif","QQ8":"QQ/bishi.gif","QQ9":"QQ/bizui.gif","QQ11":"QQ/cahan.gif","QQ12":"QQ/caidao.gif","QQ13":"QQ/chi.gif","QQ14":"QQ/ciya.gif","QQ15":"QQ/dabing.gif","QQ16":"QQ/daku.gif","QQ17":"QQ/dan.gif","QQ18":"QQ/deyi.gif","QQ19":"QQ/doge.gif","QQ20":"QQ/fadai.gif","QQ21":"QQ/fanu.gif","QQ22":"QQ/fendou.gif","QQ23":"QQ/ganga.gif","QQ24":"QQ/gouyin.gif","QQ25":"QQ/guzhang.gif","QQ26":"QQ/haixiu.gif","QQ27":"QQ/hanxiao.gif","QQ28":"QQ/haobang.gif","QQ29":"QQ/haqian.gif","QQ30":"QQ/hecai.gif","QQ31":"QQ/hexie.gif","QQ32":"QQ/huaixiao.gif","QQ33":"QQ/jie.gif","QQ34":"QQ/jingkong.gif","QQ35":"QQ/jingxi.gif","QQ36":"QQ/jingya.gif","QQ37":"QQ/juhua.gif","QQ38":"QQ/keai.gif","QQ39":"QQ/kelian.gif","QQ40":"QQ/koubi.gif","QQ41":"QQ/ku.gif","QQ42":"QQ/kuaikule.gif","QQ43":"QQ/kulou.gif","QQ44":"QQ/kun.gif","QQ45":"QQ/lanqiu.gif","QQ46":"QQ/leiben.gif","QQ47":"QQ/lenghan.gif","QQ48":"QQ/liuhan.gif","QQ49":"QQ/liulei.gif","QQ50":"QQ/nanguo.gif","QQ51":"QQ/OK.gif","QQ52":"QQ/penxue.gif","QQ53":"QQ/piezui.gif","QQ54":"QQ/pijiu.gif","QQ55":"QQ/qiang.gif","QQ56":"QQ/qiaoda.gif","QQ57":"QQ/qinqin.gif","QQ58":"QQ/qiudale.gif","QQ59":"QQ/quantou.gif","QQ60":"QQ/saorao.gif","QQ61":"QQ/se.gif","QQ62":"QQ/shengli.gif","QQ63":"QQ/shouqiang.gif","QQ64":"QQ/shuai.gif","QQ65":"QQ/shui.gif","QQ66":"QQ/tiaopi.gif","QQ67":"QQ/touxiao.gif","QQ68":"QQ/tu.gif","QQ69":"QQ/tuosai.gif","QQ70":"QQ/weiqu.gif","QQ71":"QQ/weixiao.gif","QQ72":"QQ/woshou.gif","QQ73":"QQ/wozuimei.gif","QQ74":"QQ/wunai.gif","QQ75":"QQ/xia.gif","QQ76":"QQ/xiaojiujie.gif","QQ77":"QQ/xiaoku.gif","QQ78":"QQ/xiaoyanger.gif","QQ79":"QQ/xieyanxiao.gif","QQ80":"QQ/xigua.gif","QQ81":"QQ/xu.gif","QQ82":"QQ/yangtuo.gif","QQ83":"QQ/yinxian.gif","QQ84":"QQ/yiwen.gif","QQ85":"QQ/youhengheng.gif","QQ86":"QQ/youling.gif","QQ87":"QQ/yun.gif","QQ88":"QQ/zaijian.gif","QQ89":"QQ/zhayanjian.gif","QQ90":"QQ/zhemo.gif","QQ91":"QQ/zhouma.gif","QQ92":"QQ/zhuakuang.gif","QQ93":"QQ/zuohengheng.gif","bilibiliHotKey1":"bilibiliHotKey/1.jpg","bilibiliHotKey2":"bilibiliHotKey/10.jpg","bilibiliHotKey3":"bilibiliHotKey/11.jpg","bilibiliHotKey4":"bilibiliHotKey/12.jpg","bilibiliHotKey5":"bilibiliHotKey/13.jpg","bilibiliHotKey6":"bilibiliHotKey/14.jpg","bilibiliHotKey7":"bilibiliHotKey/15.jpg","bilibiliHotKey8":"bilibiliHotKey/16.jpg","bilibiliHotKey9":"bilibiliHotKey/17.jpg","bilibiliHotKey10":"bilibiliHotKey/18.jpg","bilibiliHotKey11":"bilibiliHotKey/19.jpg","bilibiliHotKey12":"bilibiliHotKey/2.jpg","bilibiliHotKey13":"bilibiliHotKey/20.jpg","bilibiliHotKey14":"bilibiliHotKey/21.jpg","bilibiliHotKey15":"bilibiliHotKey/22.jpg","bilibiliHotKey16":"bilibiliHotKey/23.jpg","bilibiliHotKey17":"bilibiliHotKey/24.jpg","bilibiliHotKey18":"bilibiliHotKey/25.jpg","bilibiliHotKey19":"bilibiliHotKey/26.jpg","bilibiliHotKey20":"bilibiliHotKey/27.jpg","bilibiliHotKey21":"bilibiliHotKey/28.jpg","bilibiliHotKey22":"bilibiliHotKey/29.jpg","bilibiliHotKey23":"bilibiliHotKey/3.jpg","bilibiliHotKey24":"bilibiliHotKey/30.jpg","bilibiliHotKey25":"bilibiliHotKey/31.jpg","bilibiliHotKey26":"bilibiliHotKey/32.jpg","bilibiliHotKey27":"bilibiliHotKey/4.jpg","bilibiliHotKey28":"bilibiliHotKey/5.jpg","bilibiliHotKey29":"bilibiliHotKey/6.jpg","bilibiliHotKey30":"bilibiliHotKey/7.jpg","bilibiliHotKey31":"bilibiliHotKey/8.jpg","bilibiliHotKey32":"bilibiliHotKey/9.jpg","Menhera-chan1":"Menhera-chan/1.jpg","Menhera-chan2":"Menhera-chan/10.jpg","Menhera-chan3":"Menhera-chan/100.jpg","Menhera-chan4":"Menhera-chan/101.jpg","Menhera-chan5":"Menhera-chan/102.jpg","Menhera-chan6":"Menhera-chan/103.jpg","Menhera-chan7":"Menhera-chan/104.jpg","Menhera-chan8":"Menhera-chan/105.jpg","Menhera-chan9":"Menhera-chan/106.jpg","Menhera-chan10":"Menhera-chan/107.jpg","Menhera-chan11":"Menhera-chan/108.jpg","Menhera-chan12":"Menhera-chan/109.jpg","Menhera-chan13":"Menhera-chan/11.jpg","Menhera-chan14":"Menhera-chan/110.jpg","Menhera-chan15":"Menhera-chan/111.jpg","Menhera-chan16":"Menhera-chan/112.jpg","Menhera-chan17":"Menhera-chan/113.jpg","Menhera-chan18":"Menhera-chan/114.jpg","Menhera-chan19":"Menhera-chan/115.jpg","Menhera-chan20":"Menhera-chan/116.jpg","Menhera-chan21":"Menhera-chan/117.jpg","Menhera-chan22":"Menhera-chan/118.jpg","Menhera-chan23":"Menhera-chan/119.jpg","Menhera-chan24":"Menhera-chan/12.jpg","Menhera-chan25":"Menhera-chan/120.jpg","Menhera-chan26":"Menhera-chan/13.jpg","Menhera-chan27":"Menhera-chan/14.jpg","Menhera-chan28":"Menhera-chan/15.jpg","Menhera-chan29":"Menhera-chan/16.jpg","Menhera-chan30":"Menhera-chan/17.jpg","Menhera-chan31":"Menhera-chan/18.jpg","Menhera-chan32":"Menhera-chan/19.jpg","Menhera-chan33":"Menhera-chan/2.jpg","Menhera-chan34":"Menhera-chan/20.jpg","Menhera-chan35":"Menhera-chan/21.jpg","Menhera-chan36":"Menhera-chan/22.jpg","Menhera-chan37":"Menhera-chan/23.jpg","Menhera-chan38":"Menhera-chan/24.jpg","Menhera-chan39":"Menhera-chan/25.jpg","Menhera-chan40":"Menhera-chan/26.jpg","Menhera-chan41":"Menhera-chan/27.jpg","Menhera-chan42":"Menhera-chan/28.jpg","Menhera-chan43":"Menhera-chan/29.jpg","Menhera-chan44":"Menhera-chan/3.jpg","Menhera-chan45":"Menhera-chan/30.jpg","Menhera-chan46":"Menhera-chan/31.jpg","Menhera-chan47":"Menhera-chan/32.jpg","Menhera-chan48":"Menhera-chan/33.jpg","Menhera-chan49":"Menhera-chan/34.jpg","Menhera-chan50":"Menhera-chan/35.jpg","Menhera-chan51":"Menhera-chan/36.jpg","Menhera-chan52":"Menhera-chan/37.jpg","Menhera-chan53":"Menhera-chan/38.jpg","Menhera-chan54":"Menhera-chan/39.jpg","Menhera-chan55":"Menhera-chan/4.jpg","Menhera-chan56":"Menhera-chan/40.jpg","Menhera-chan57":"Menhera-chan/41.jpg","Menhera-chan58":"Menhera-chan/42.jpg","Menhera-chan59":"Menhera-chan/43.jpg","Menhera-chan60":"Menhera-chan/44.jpg","Menhera-chan61":"Menhera-chan/45.jpg","Menhera-chan62":"Menhera-chan/46.jpg","Menhera-chan63":"Menhera-chan/47.jpg","Menhera-chan64":"Menhera-chan/48.jpg","Menhera-chan65":"Menhera-chan/49.jpg","Menhera-chan66":"Menhera-chan/5.jpg","Menhera-chan67":"Menhera-chan/50.jpg","Menhera-chan68":"Menhera-chan/51.jpg","Menhera-chan69":"Menhera-chan/52.jpg","Menhera-chan70":"Menhera-chan/53(1).jpg","Menhera-chan71":"Menhera-chan/53.jpg","Menhera-chan72":"Menhera-chan/54.jpg","Menhera-chan73":"Menhera-chan/55.jpg","Menhera-chan74":"Menhera-chan/56.jpg","Menhera-chan75":"Menhera-chan/57.jpg","Menhera-chan76":"Menhera-chan/58.jpg","Menhera-chan77":"Menhera-chan/59.jpg","Menhera-chan78":"Menhera-chan/6.jpg","Menhera-chan79":"Menhera-chan/60.jpg","Menhera-chan80":"Menhera-chan/61.jpg","Menhera-chan81":"Menhera-chan/62.jpg","Menhera-chan82":"Menhera-chan/63.jpg","Menhera-chan83":"Menhera-chan/64.jpg","Menhera-chan84":"Menhera-chan/65.jpg","Menhera-chan85":"Menhera-chan/66.jpg","Menhera-chan86":"Menhera-chan/67.jpg","Menhera-chan87":"Menhera-chan/68.jpg","Menhera-chan88":"Menhera-chan/69.jpg","Menhera-chan89":"Menhera-chan/7.jpg","Menhera-chan90":"Menhera-chan/70.jpg","Menhera-chan91":"Menhera-chan/71.jpg","Menhera-chan92":"Menhera-chan/72.jpg","Menhera-chan93":"Menhera-chan/73.jpg","Menhera-chan94":"Menhera-chan/74.jpg","Menhera-chan95":"Menhera-chan/75.jpg","Menhera-chan96":"Menhera-chan/76.jpg","Menhera-chan97":"Menhera-chan/77.jpg","Menhera-chan98":"Menhera-chan/78.jpg","Menhera-chan99":"Menhera-chan/79.jpg","Menhera-chan100":"Menhera-chan/8.jpg","Menhera-chan101":"Menhera-chan/80.jpg","Menhera-chan102":"Menhera-chan/81.jpg","Menhera-chan103":"Menhera-chan/82.jpg","Menhera-chan104":"Menhera-chan/83.jpg","Menhera-chan105":"Menhera-chan/84.jpg","Menhera-chan106":"Menhera-chan/85.jpg","Menhera-chan107":"Menhera-chan/86.jpg","Menhera-chan108":"Menhera-chan/87.jpg","Menhera-chan109":"Menhera-chan/88.jpg","Menhera-chan110":"Menhera-chan/89.jpg","Menhera-chan111":"Menhera-chan/9.jpg","Menhera-chan112":"Menhera-chan/90.jpg","Menhera-chan113":"Menhera-chan/91.jpg","Menhera-chan114":"Menhera-chan/92.jpg","Menhera-chan115":"Menhera-chan/93.jpg","Menhera-chan116":"Menhera-chan/94.jpg","Menhera-chan117":"Menhera-chan/95.jpg","Menhera-chan118":"Menhera-chan/96.jpg","Menhera-chan119":"Menhera-chan/97.jpg","Menhera-chan120":"Menhera-chan/98.jpg","Menhera-chan121":"Menhera-chan/99.jpg","Sweetie-Bunny1":"Sweetie-Bunny/12311678.png","Sweetie-Bunny2":"Sweetie-Bunny/12311679.png","Sweetie-Bunny3":"Sweetie-Bunny/12311680.png","Sweetie-Bunny4":"Sweetie-Bunny/12311681.png","Sweetie-Bunny5":"Sweetie-Bunny/12311682.png","Sweetie-Bunny6":"Sweetie-Bunny/12311683.png","Sweetie-Bunny7":"Sweetie-Bunny/12311684.png","Sweetie-Bunny8":"Sweetie-Bunny/12311685.png","Sweetie-Bunny9":"Sweetie-Bunny/12311686.png","Sweetie-Bunny10":"Sweetie-Bunny/12311687.png","Sweetie-Bunny11":"Sweetie-Bunny/12311688.png","Sweetie-Bunny12":"Sweetie-Bunny/12311689.png","Sweetie-Bunny13":"Sweetie-Bunny/12311690.png","Sweetie-Bunny14":"Sweetie-Bunny/12311691.png","Sweetie-Bunny15":"Sweetie-Bunny/12311692.png","Sweetie-Bunny16":"Sweetie-Bunny/12311693.png","Sweetie-Bunny17":"Sweetie-Bunny/12311694.png","Sweetie-Bunny18":"Sweetie-Bunny/12311695.png","Sweetie-Bunny19":"Sweetie-Bunny/12311696.png","Sweetie-Bunny20":"Sweetie-Bunny/12311697.png","Sweetie-Bunny21":"Sweetie-Bunny/12311698.png","Sweetie-Bunny22":"Sweetie-Bunny/12311699.png","Sweetie-Bunny23":"Sweetie-Bunny/12311700.png","Sweetie-Bunny24":"Sweetie-Bunny/12311701.png","Sweetie-Bunny25":"Sweetie-Bunny/12311702.png","Sweetie-Bunny26":"Sweetie-Bunny/12311703.png","Sweetie-Bunny27":"Sweetie-Bunny/12311704.png","Sweetie-Bunny28":"Sweetie-Bunny/12311705.png","Sweetie-Bunny29":"Sweetie-Bunny/12311706.png","Sweetie-Bunny30":"Sweetie-Bunny/12311707.png","Sweetie-Bunny31":"Sweetie-Bunny/12311708.png","Sweetie-Bunny32":"Sweetie-Bunny/12311709.png","Sweetie-Bunny33":"Sweetie-Bunny/12311710.png","Sweetie-Bunny34":"Sweetie-Bunny/12311711.png","Sweetie-Bunny35":"Sweetie-Bunny/12311712.png","Sweetie-Bunny36":"Sweetie-Bunny/12311713.png","Sweetie-Bunny37":"Sweetie-Bunny/12311714.png","Sweetie-Bunny38":"Sweetie-Bunny/12311715.png","Sweetie-Bunny39":"Sweetie-Bunny/12311716.png","Sweetie-Bunny40":"Sweetie-Bunny/12311717.png","Majotabi1":"Majotabi/367516718.png","Majotabi2":"Majotabi/367516719.png","Majotabi3":"Majotabi/367516720.png","Majotabi4":"Majotabi/367516721.png","Majotabi5":"Majotabi/367516722.png","Majotabi6":"Majotabi/367516723.png","Majotabi7":"Majotabi/367516724.png","Majotabi8":"Majotabi/367516725.png","Majotabi9":"Majotabi/367516726.png","Majotabi10":"Majotabi/367516727.png","Majotabi11":"Majotabi/367516728.png","Majotabi12":"Majotabi/367516729.png","Majotabi13":"Majotabi/367516730.png","Majotabi14":"Majotabi/367516731.png","Majotabi15":"Majotabi/367516732.png","Majotabi16":"Majotabi/367516733.png","Majotabi17":"Majotabi/367516734.png","Majotabi18":"Majotabi/367516735.png","Majotabi19":"Majotabi/367516736.png","Majotabi20":"Majotabi/367516737.png","Majotabi21":"Majotabi/367516738.png","Majotabi22":"Majotabi/367516739.png","Majotabi23":"Majotabi/367516740.png","Majotabi24":"Majotabi/367516741.png","Majotabi25":"Majotabi/367516742.png","Majotabi26":"Majotabi/367516743.png","Majotabi27":"Majotabi/367516744.png","Majotabi28":"Majotabi/367516745.png","Majotabi29":"Majotabi/367516746.png","Majotabi30":"Majotabi/367516747.png","Majotabi31":"Majotabi/367516748.png","Majotabi32":"Majotabi/367516749.png","Majotabi33":"Majotabi/367516750.png","Majotabi34":"Majotabi/367516751.png","Majotabi35":"Majotabi/367516752.png","Majotabi36":"Majotabi/367516753.png","Majotabi37":"Majotabi/367516754.png","Majotabi38":"Majotabi/367516755.png","Majotabi39":"Majotabi/367516756.png","Majotabi40":"Majotabi/367516757.png","Snow-Miku1":"Snow-Miku/3583066@2x.png","Snow-Miku2":"Snow-Miku/3583067@2x.png","Snow-Miku3":"Snow-Miku/3583068@2x.png","Snow-Miku4":"Snow-Miku/3583069@2x.png","Snow-Miku5":"Snow-Miku/3583070@2x.png","Snow-Miku6":"Snow-Miku/3583071@2x.png","Snow-Miku7":"Snow-Miku/3583072@2x.png","Snow-Miku8":"Snow-Miku/3583073@2x.png","Snow-Miku9":"Snow-Miku/3583074@2x.png","Snow-Miku10":"Snow-Miku/3583075@2x.png","Snow-Miku11":"Snow-Miku/3583076@2x.png","Snow-Miku12":"Snow-Miku/3583077@2x.png","Snow-Miku13":"Snow-Miku/3583078@2x.png","Snow-Miku14":"Snow-Miku/3583079@2x.png","Snow-Miku15":"Snow-Miku/3583080@2x.png","Snow-Miku16":"Snow-Miku/3583081@2x.png","Snow-Miku17":"Snow-Miku/3583082@2x.png","Snow-Miku18":"Snow-Miku/3583083@2x.png","Snow-Miku19":"Snow-Miku/3583084@2x.png","Snow-Miku20":"Snow-Miku/3583085@2x.png","Snow-Miku21":"Snow-Miku/3583086@2x.png","Snow-Miku22":"Snow-Miku/3583087@2x.png","Snow-Miku23":"Snow-Miku/3583088@2x.png","Snow-Miku24":"Snow-Miku/3583089@2x.png","Snow-Miku25":"Snow-Miku/3583090@2x.png","Snow-Miku26":"Snow-Miku/3583091@2x.png","Snow-Miku27":"Snow-Miku/3583092@2x.png","Snow-Miku28":"Snow-Miku/3583093@2x.png","Snow-Miku29":"Snow-Miku/3583094@2x.png","Snow-Miku30":"Snow-Miku/3583095@2x.png","Snow-Miku31":"Snow-Miku/3583096@2x.png","Snow-Miku32":"Snow-Miku/3583097@2x.png","Snow-Miku33":"Snow-Miku/3583098@2x.png","Snow-Miku34":"Snow-Miku/3583099@2x.png","Snow-Miku35":"Snow-Miku/3583100@2x.png","Snow-Miku36":"Snow-Miku/3583101@2x.png","Snow-Miku37":"Snow-Miku/3583102@2x.png","Snow-Miku38":"Snow-Miku/3583103@2x.png","Snow-Miku39":"Snow-Miku/3583104@2x.png","Snow-Miku40":"Snow-Miku/3583105@2x.png"},
      enableQQ: true,
      path: window.location.pathname,
    }

    if (true) { 
      initData.requiredFields= ('nick,mail'.split(','))
    }
    
    if (false) {
      const otherData = false
      initData = Object.assign({}, initData, otherData)
    }
    
    const valine = new Valine(initData)
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.querySelector('#vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script>(function(){
  const bp = document.createElement('script');
  const curProtocol = window.location.protocol.split(':')[0];
  if (curProtocol === 'https') {
    bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
  }
  else{
    bp.src = 'http://push.zhanzhang.baidu.com/push.js';
  }
  bp.dataset.pjax = ''
  const s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(bp, s);
})()</script></div></body></html>