<!DOCTYPE html><html lang="en" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Navigating the Complexity of Mixture of Experts (MoE) in Multi-Modal Systems | Ⅹ. Harbor</title><meta name="keywords" content="Mixture of Experts,Multi-Modal AI,LangChain,AI Architecture"><meta name="author" content="✨白拾ShiroX✨,hobart.yang@qq.com"><meta name="copyright" content="✨白拾ShiroX✨"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="English Version中文版本IntroductionIn the rapidly evolving field of artificial intelligence, integrating diverse data modalities—such as text, images, audio, and sensor data—poses significant challenges.">
<meta property="og:type" content="article">
<meta property="og:title" content="Navigating the Complexity of Mixture of Experts (MoE) in Multi-Modal Systems">
<meta property="og:url" content="https://discover304.top/2024/09/21/2024q3/195-moe/index.html">
<meta property="og:site_name" content="Ⅹ. Harbor">
<meta property="og:description" content="English Version中文版本IntroductionIn the rapidly evolving field of artificial intelligence, integrating diverse data modalities—such as text, images, audio, and sensor data—poses significant challenges.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://image.discover304.top/1726926461860.png?imageView2/2/h/300">
<meta property="article:published_time" content="2024-09-21T08:26:16.000Z">
<meta property="article:modified_time" content="2024-09-21T13:47:51.709Z">
<meta property="article:author" content="✨白拾ShiroX✨">
<meta property="article:tag" content="Mixture of Experts">
<meta property="article:tag" content="Multi-Modal AI">
<meta property="article:tag" content="LangChain">
<meta property="article:tag" content="AI Architecture">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://image.discover304.top/1726926461860.png?imageView2/2/h/300"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://discover304.top/2024/09/21/2024q3/195-moe/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="preconnect" href="//zz.bdstatic.com"/><meta name="google-site-verification" content="ilqpfk3vkgzDNNikz_V37-DOvRyi5wv4Hoi_eyBqvTg"/><meta name="msvalidate.01" content="49D9A50CCF9744E17274791468EDB517"/><meta name="baidu-site-verification" content="code-V24KosyVh1"/><meta name="360-site-verification" content="bd8859c3d74dfa3e8aeee9db30c94bd2"/><meta name="yandex-verification" content="f28ec9bbd50c56f5"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script async="async" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script>(adsbygoogle = window.adsbygoogle || []).push({
  google_ad_client: 'ca-pub-1849044985266192',
  enable_page_level_ads: 'true'
});</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8030f6052f2fed6a4704d96619f090d6";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><link rel="stylesheet" href="/css/font.css" media="print" onload="this.media='all'"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: {"limitDay":365,"position":"bottom","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'days',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: {"limitCount":200,"languages":{"author":"Author: ✨白拾ShiroX✨","link":"Link: ","source":"Source: Ⅹ. Harbor","info":"Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source."}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"Traditional Chinese Activated Manually","cht_to_chs":"Simplified Chinese Activated Manually","day_to_night":"Dark Mode Activated Manually","night_to_day":"Light Mode Activated Manually","bgLight":"#ffc910","bgDark":"#02c3f6","position":"bottom-left"},
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isanchor: true
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}

// https://stackoverflow.com/questions/16839698/jquery-getscript-alternative-in-native-javascript
const getScript = url => new Promise((resolve, reject) => {
  const script = document.createElement('script')
  script.src = url
  script.async = true
  script.onerror = reject
  script.onload = script.onreadystatechange = function() {
    const loadState = this.readyState
    if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
    script.onload = script.onreadystatechange = null
    resolve()
  }
  document.head.appendChild(script)
})</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2024-09-21 21:47:51'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
   if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }
  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified
    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }const asideStatus = saveToLocal.get('aside-status')
if (asideStatus !== undefined) {
   if (asideStatus === 'hide') {
     document.documentElement.classList.add('hide-aside')
   } else {
     document.documentElement.classList.remove('hide-aside')
   }
}const fontSizeVal = saveToLocal.get('global-font-size')
if (fontSizeVal !== undefined) {
  document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
}})()</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Ⅹ. Harbor" type="application/atom+xml">
</head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/head.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">282</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">148</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">29</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-link"></i><span> Connection</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/link/"><i class="fa-fw fas fa-address-book"></i><span> Friends</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://aierlab.tech"><i class="fa-fw fas fa-sitemap"></i><span> GroupSite</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-wrench"></i><span> Tools</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://wandb.ai/"><i class="fa-fw fas fa-newspaper"></i><span> WandB</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> Article</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archive</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Category</span></a></li><li><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></li></ul></div></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://image.discover304.top/1726926461860.png?imageView2/2/h/300)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Ⅹ. Harbor</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-link"></i><span> Connection</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/link/"><i class="fa-fw fas fa-address-book"></i><span> Friends</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://aierlab.tech"><i class="fa-fw fas fa-sitemap"></i><span> GroupSite</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-wrench"></i><span> Tools</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://wandb.ai/"><i class="fa-fw fas fa-newspaper"></i><span> WandB</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> Article</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archive</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Category</span></a></li><li><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Navigating the Complexity of Mixture of Experts (MoE) in Multi-Modal Systems</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2024-09-21T08:26:16.000Z" title="Created 2024-09-21 16:26:16">2024-09-21</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2024-09-21T13:47:51.709Z" title="Updated 2024-09-21 21:47:51">2024-09-21</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/NoteBook/">NoteBook</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/NoteBook/TechNote/">TechNote</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">3.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>16min</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><div class="tabs" id=""><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#-1">English Version</button></li><li class="tab"><button type="button" data-href="#-2">中文版本</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="-1"><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>In the rapidly evolving field of artificial intelligence, integrating diverse data modalities—such as text, images, audio, and sensor data—poses significant challenges. Traditional monolithic AI models often struggle to handle the exponential complexity that arises when processing multiple modalities simultaneously. This is where the <strong>Mixture of Experts (MoE)</strong> framework demonstrates its true value. While MoE in isolation may seem less impactful compared to powerful single-model AI solutions, its application in <strong>multi-modal systems</strong> is transformative. By delegating each modality to specialized expert models, multi-modal MoE systems efficiently manage complexity, enabling more effective data processing and integration.</p>
<h2 id="Understanding-Mixture-of-Experts"><a href="#Understanding-Mixture-of-Experts" class="headerlink" title="Understanding Mixture of Experts"></a>Understanding Mixture of Experts</h2><h3 id="The-Role-of-Modality-in-MoE"><a href="#The-Role-of-Modality-in-MoE" class="headerlink" title="The Role of Modality in MoE"></a>The Role of Modality in MoE</h3><p>At its core, the Mixture of Experts architecture excels by leveraging the specialization of expert models, each finely tuned to handle a specific data modality. In multi-modal contexts, the differences between data types are substantial—textual data requires natural language processing techniques, images necessitate computer vision algorithms, and audio data demands signal processing methods. Attempting to build a single model capable of effectively processing all these modalities is often impractical due to the lack of sufficient aligned data and the vast differences in processing requirements. <strong>MoE addresses this by assigning each modality to an expert</strong>, thus simplifying the overall system design and improving performance.</p>
<h3 id="Current-Landscape"><a href="#Current-Landscape" class="headerlink" title="Current Landscape"></a>Current Landscape</h3><p>Currently, multi-modal MoE systems are at the forefront of applications that require the integration of diverse input types. Fields such as autonomous driving, multimedia content analysis, and virtual assistants rely heavily on processing multiple modalities simultaneously. For instance, an autonomous vehicle must interpret visual data from cameras, spatial data from LIDAR, and contextual data from GPS and maps. By utilizing specialized experts for each modality within an MoE framework, these systems can process complex inputs more effectively than traditional models.</p>
<h3 id="Challenges-and-Future-Directions"><a href="#Challenges-and-Future-Directions" class="headerlink" title="Challenges and Future Directions"></a>Challenges and Future Directions</h3><p>The primary challenge in multi-modal MoE systems lies in integrating an ever-increasing number of modalities. As the number of modalities grows, the <strong>complexity of the system increases exponentially</strong>. Aligning data from disparate sources to produce coherent outputs becomes more difficult, especially when modalities are not naturally aligned or synchronized. Moreover, there is often insufficient data that encompasses all modalities in a fully integrated manner, making it challenging to train a single model to handle everything.</p>
<p>Looking ahead, advancements in multi-modal MoE systems are expected to focus on improving the <strong>integration and alignment of modalities</strong>. Researchers are exploring methods to facilitate the incorporation of new modalities without requiring extensive reconfiguration of the system. This includes developing universal feature representations that can bridge different modalities and enable more seamless data integration.</p>
<h2 id="The-Significance-of-Multi-Modal-MoE-Systems"><a href="#The-Significance-of-Multi-Modal-MoE-Systems" class="headerlink" title="The Significance of Multi-Modal MoE Systems"></a>The Significance of Multi-Modal MoE Systems</h2><h3 id="Introduction-1"><a href="#Introduction-1" class="headerlink" title="Introduction"></a>Introduction</h3><p>Multi-modal MoE systems represent a critical innovation in AI, offering structured approaches to handling the complexities of diverse data types. As modalities increase, the complexity of processing and integrating them grows exponentially. Building a single model to tackle all modalities becomes unfeasible due to the lack of sufficient aligned data and the intrinsic differences between modalities. <strong>Multi-modal MoE systems address this by integrating as many data-specific experts as necessary, each handling their modality effectively</strong>.</p>
<h3 id="Current-State"><a href="#Current-State" class="headerlink" title="Current State"></a>Current State</h3><p>These systems are especially prevalent in fields that demand the simultaneous processing of varied data types. For example, in multimedia content analysis, combining textual, visual, and audio data allows for richer and more accurate content interpretation and recommendation. The precision with which multi-modal MoE systems handle each modality significantly outpaces traditional models that might struggle with the depth and nuance of such varied data.</p>
<h3 id="Challenges-and-Future-Projections"><a href="#Challenges-and-Future-Projections" class="headerlink" title="Challenges and Future Projections"></a>Challenges and Future Projections</h3><p>Despite their advantages, multi-modal MoE systems face significant challenges. One major issue is the integration of new modalities, which often requires extensive recalibration of the system and integration of new expert models. Aligning data from these varied sources to produce coherent outputs remains a complex task, particularly as the diversity and volume of data continue to grow.</p>
<p>Future projections for multi-modal MoE systems include enhancements in their adaptability and flexibility. Researchers are exploring methods to simplify the incorporation of new modalities, possibly through automated expert creation and integration processes. Additionally, the need for more sophisticated alignment techniques that can dynamically synchronize data from different modalities to maintain context and meaning is becoming increasingly clear.</p>
<h2 id="Implementing-Multi-Modal-MoE-with-LangChain"><a href="#Implementing-Multi-Modal-MoE-with-LangChain" class="headerlink" title="Implementing Multi-Modal MoE with LangChain"></a>Implementing Multi-Modal MoE with LangChain</h2><h3 id="Introduction-to-LangChain"><a href="#Introduction-to-LangChain" class="headerlink" title="Introduction to LangChain"></a>Introduction to LangChain</h3><p><a target="_blank" rel="noopener" href="https://github.com/hwchase17/langchain">LangChain</a> provides a robust framework for implementing multi-modal MoE systems. Its modular architecture allows developers to create and manage specialized tools or agents—each acting as an expert for a specific modality. By simplifying the integration of these experts, LangChain enables efficient handling of diverse data types within a unified system.</p>
<h3 id="Practical-Implementation"><a href="#Practical-Implementation" class="headerlink" title="Practical Implementation"></a>Practical Implementation</h3><p>Below is a comprehensive example of how to set up a basic multi-modal MoE system using LangChain that can handle both text and image data:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.tools <span class="keyword">import</span> BaseTool</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define an expert tool for processing text</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TextExpertTool</span>(<span class="title class_ inherited__">BaseTool</span>):</span><br><span class="line">    name = <span class="string">&quot;text_expert&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self, input_text</span>):</span><br><span class="line">        <span class="comment"># Implement text processing logic here, e.g., sentiment analysis</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;Processed text: <span class="subst">&#123;input_text&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define an expert tool for processing images</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ImageExpertTool</span>(<span class="title class_ inherited__">BaseTool</span>):</span><br><span class="line">    name = <span class="string">&quot;image_expert&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self, input_image</span>):</span><br><span class="line">        <span class="comment"># Implement image processing logic here, e.g., object recognition</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;Processed image data: <span class="subst">&#123;input_image&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define a gating function to decide which expert to use based on modality</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gating_function</span>(<span class="params">input_data</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(input_data, <span class="built_in">str</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;text_expert&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(input_data, <span class="built_in">bytes</span>):  <span class="comment"># Assuming image data is in byte format</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;image_expert&quot;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;Unsupported input type&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Implement the MoE Agent</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MoEAgent</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, tools</span>):</span><br><span class="line">        <span class="variable language_">self</span>.tools = &#123;tool.name: tool <span class="keyword">for</span> tool <span class="keyword">in</span> tools&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self, input_data</span>):</span><br><span class="line">        expert_name = gating_function(input_data)</span><br><span class="line">        expert_tool = <span class="variable language_">self</span>.tools.get(expert_name)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> expert_tool:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">f&quot;No expert found for the given input: <span class="subst">&#123;expert_name&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> expert_tool.run(input_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Example usage of the MoE system</span></span><br><span class="line">tools = [TextExpertTool(), ImageExpertTool()]</span><br><span class="line">moe_agent = MoEAgent(tools)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Test with a text input</span></span><br><span class="line">text_result = moe_agent.run(<span class="string">&quot;Hello, this is a text example.&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(text_result)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Test with an image input (assuming image data is a byte string)</span></span><br><span class="line">image_result = moe_agent.run(<span class="string">b&#x27;\x89PNG\r\n\x1a\n...&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(image_result)</span><br></pre></td></tr></table></figure>

<p>In this code:</p>
<ul>
<li><strong>TextExpertTool</strong> and <strong>ImageExpertTool</strong> are specialized experts for handling text and image data, respectively.</li>
<li>The <strong>gating_function</strong> routes input data to the appropriate expert based on the data modality.</li>
<li>The <strong>MoEAgent</strong> manages the experts and processes the input data using the correct expert.</li>
</ul>
<p>This modular approach allows the system to be easily extended with additional modalities by adding new expert tools and updating the gating function accordingly.</p>
<h3 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h3><p>The key to the success of multi-modal MoE systems is the effective handling of different modalities through specialized experts. By focusing on modality-specific processing, each expert can employ the most appropriate algorithms and techniques for its data type. This not only enhances performance but also simplifies the integration of new modalities, as each expert operates independently within the MoE framework.</p>
<p>While gating mechanisms are necessary for routing inputs, the primary challenge lies in <strong>managing the complexity introduced by multiple modalities</strong>. As more modalities are added, developers must ensure that the system remains coherent and that the integration of experts does not lead to conflicts or inefficiencies.</p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Multi-modal Mixture of Experts systems represent a significant advancement in artificial intelligence, addressing the exponential complexity that arises from processing diverse data types. By delegating each modality to specialized expert models, these systems overcome the limitations of traditional monolithic models, which are often incapable of effectively handling all modalities due to the lack of sufficient aligned data and the inherent differences between data types.</p>
<p>Implementing multi-modal MoE systems with frameworks like LangChain empowers developers to build scalable and adaptable AI applications. By focusing on <strong>modality as the key aspect of MoE</strong>, these systems can efficiently integrate as many data types as necessary, each processed with expert-level precision. This approach not only enhances performance but also allows for the continuous expansion of the system as new modalities emerge.</p>
<p>As we continue to advance in the field of AI, the importance of modality-specific processing within MoE frameworks will only grow. The challenges associated with integrating multiple modalities will drive innovation, leading to more sophisticated methods for data alignment and expert coordination. Ultimately, embracing multi-modal MoE systems will enable the development of AI applications that more accurately reflect the complex, multi-faceted nature of real-world data.</p>
<hr>
<blockquote>
<p><strong>🍀Afterword🍀</strong><br>The blog focuses on programming, algorithms, robotics, artificial intelligence, mathematics, etc., with a continuous output of high quality.<br><strong>🌸Chat QQ Group</strong>: <a target="_blank" rel="noopener" href="https://jq.qq.com/?_wv=1027&k=EaGddTQg">Rabbit’s Magic Workshop</a> (942848525)<br><strong>⭐Bilibili Account</strong>: <a target="_blank" rel="noopener" href="https://space.bilibili.com/98639326">白拾ShiroX</a> (Active in the knowledge and animation zones)<br><strong>✨GitHub Page</strong>: <a target="_blank" rel="noopener" href="https://github.com/yhbcode000">yhbcode000</a> (Engineering files)<br><strong>⛳Discord Community</strong>: <a target="_blank" rel="noopener" href="https://discord.g/nn5NDXMgae">AierLab</a> (Artificial Intelligence community)</p>
</blockquote><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="-2"><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>在迅速发展的人工智能领域，整合多种数据模态（如文本、图像、音频和传感器数据）是一个极具挑战性的任务。传统的单一模型AI系统通常难以应对同时处理多模态时产生的指数级复杂性。而这正是<strong>混合专家（Mixture of Experts，MoE）</strong>框架展现其真正价值的地方。虽然MoE本身相较于强大的单一模型AI解决方案可能显得影响较小，但其在<strong>多模态系统</strong>中的应用是革命性的。通过将每种模态交给特定的专家模型，MoE多模态系统能够有效管理复杂性，从而提高数据处理和整合的效率。</p>
<h2 id="理解混合专家（MoE）"><a href="#理解混合专家（MoE）" class="headerlink" title="理解混合专家（MoE）"></a>理解混合专家（MoE）</h2><h3 id="模态在MoE中的作用"><a href="#模态在MoE中的作用" class="headerlink" title="模态在MoE中的作用"></a>模态在MoE中的作用</h3><p>混合专家架构的核心在于，通过专家模型的专门化优势，每个专家都能被精心调优以处理特定的数据模态。在多模态情境下，各数据类型的差异性十分显著——文本数据需要自然语言处理技术，图像需要计算机视觉算法，而音频数据则要求信号处理方法。试图构建一个能有效处理所有这些模态的单一模型通常是不现实的，原因在于缺乏足够的对齐数据以及各模态处理要求的巨大差异。<strong>MoE通过为每个模态分配一个专家</strong>，从而简化了整体系统设计并提高了性能。</p>
<h3 id="当前形势"><a href="#当前形势" class="headerlink" title="当前形势"></a>当前形势</h3><p>目前，多模态MoE系统在需要整合多种输入类型的应用中处于前沿。自动驾驶、多媒体内容分析、虚拟助手等领域依赖于同时处理多个模态。例如，自动驾驶车辆需要解读来自摄像头的视觉数据、来自LIDAR的空间数据，以及来自GPS和地图的上下文数据。通过在MoE框架中为每种模态分配专门的专家，这些系统能够比传统模型更有效地处理复杂输入。</p>
<h3 id="挑战与未来方向"><a href="#挑战与未来方向" class="headerlink" title="挑战与未来方向"></a>挑战与未来方向</h3><p>多模态MoE系统的主要挑战在于整合不断增加的模态。随着模态数量的增加，<strong>系统的复杂性成倍增长</strong>。对齐来自不同源的数据以生成一致的输出变得更加困难，尤其是在模态并不自然对齐或同步的情况下。此外，往往缺乏涵盖所有模态的完整集成数据，使得训练一个能够处理所有内容的模型变得困难。</p>
<p>展望未来，多模态MoE系统的进步将集中在改进<strong>模态的整合与对齐</strong>上。研究人员正在探索如何在不需要对系统进行大规模重构的情况下引入新模态的方法，包括开发可以跨越不同模态的通用特征表示，从而实现更顺畅的数据整合。</p>
<h2 id="多模态MoE系统的重要性"><a href="#多模态MoE系统的重要性" class="headerlink" title="多模态MoE系统的重要性"></a>多模态MoE系统的重要性</h2><h3 id="引言-1"><a href="#引言-1" class="headerlink" title="引言"></a>引言</h3><p>多模态MoE系统代表了AI领域中的重要创新，提供了应对多样化数据类型复杂性结构化的方法。随着模态的增加，处理和整合它们的复杂性成倍增加。由于缺乏足够对齐的数据以及各模态之间的本质差异，构建一个处理所有模态的单一模型变得不切实际。<strong>多模态MoE系统通过整合所需数量的特定数据专家，每个专家都有效地处理其负责的模态</strong>，从而应对了这一挑战。</p>
<h3 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h3><p>这些系统在需要同时处理多种数据类型的领域尤其常见。例如，在多媒体内容分析中，结合文本、视觉和音频数据能够实现更丰富、更准确的内容解读和推荐。多模态MoE系统对每个模态的精确处理能力远远超过可能会在处理如此多样化数据时显得力不从心的传统模型。</p>
<h3 id="挑战与未来预测"><a href="#挑战与未来预测" class="headerlink" title="挑战与未来预测"></a>挑战与未来预测</h3><p>尽管多模态MoE系统具有显著优势，但它们面临着巨大的挑战。一个主要问题是新模态的整合，通常需要对系统进行广泛的重新校准并引入新的专家模型。对齐来自这些不同源的数据以生成一致的输出仍然是一个复杂的任务，尤其是在数据的多样性和数量不断增加的情况下。</p>
<p>对于多模态MoE系统的未来预测，重点是提升其适应性和灵活性。研究人员正在探索简化新模态整合的方法，可能通过自动化的专家创建和整合过程。此外，随着保持上下文和意义的需要日益明确，研究者们还需要开发更复杂的对齐技术，以便动态同步来自不同模态的数据。</p>
<h2 id="使用LangChain实现多模态MoE"><a href="#使用LangChain实现多模态MoE" class="headerlink" title="使用LangChain实现多模态MoE"></a>使用LangChain实现多模态MoE</h2><h3 id="LangChain简介"><a href="#LangChain简介" class="headerlink" title="LangChain简介"></a>LangChain简介</h3><p><a target="_blank" rel="noopener" href="https://github.com/hwchase17/langchain">LangChain</a> 提供了一个强大的框架，用于实现多模态MoE系统。其模块化架构允许开发人员创建和管理专门的工具或代理——每个工具或代理作为特定模态的专家。通过简化这些专家的整合，LangChain使在统一系统内高效处理多样化数据类型成为可能。</p>
<h3 id="实际实现"><a href="#实际实现" class="headerlink" title="实际实现"></a>实际实现</h3><p>下面是一个使用LangChain设置能够处理文本和图像数据的基本多模态MoE系统的全面示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.tools <span class="keyword">import</span> BaseTool</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义处理文本的专家工具</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TextExpertTool</span>(<span class="title class_ inherited__">BaseTool</span>):</span><br><span class="line">    name = <span class="string">&quot;text_expert&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self, input_text</span>):</span><br><span class="line">        <span class="comment"># 实现文本处理逻辑，例如情感分析</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;处理过的文本: <span class="subst">&#123;input_text&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义处理图像的专家工具</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ImageExpertTool</span>(<span class="title class_ inherited__">BaseTool</span>):</span><br><span class="line">    name = <span class="string">&quot;image_expert&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self, input_image</span>):</span><br><span class="line">        <span class="comment"># 实现图像处理逻辑，例如目标识别</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;处理过的图像数据: <span class="subst">&#123;input_image&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个选择使用哪个专家的函数，基于输入数据的模态</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gating_function</span>(<span class="params">input_data</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(input_data, <span class="built_in">str</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;text_expert&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(input_data, <span class="built_in">bytes</span>):  <span class="comment"># 假设图像数据是字节格式</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;image_expert&quot;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;不支持的输入类型&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实现MoE代理</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MoEAgent</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, tools</span>):</span><br><span class="line">        <span class="variable language_">self</span>.tools = &#123;tool.name: tool <span class="keyword">for</span> tool <span class="keyword">in</span> tools&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self, input_data</span>):</span><br><span class="line">        expert_name = gating_function(input_data)</span><br><span class="line">        expert_tool = <span class="variable language_">self</span>.tools.get(expert_name)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> expert_tool:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">f&quot;未找到适合给定输入的专家: <span class="subst">&#123;expert_name&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> expert_tool.run(input_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用MoE系统示例</span></span><br><span class="line">tools = [TextExpertTool(), ImageExpertTool()]</span><br><span class="line">moe_agent = MoEAgent(tools)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试文本输入</span></span><br><span class="line">text_result = moe_agent.run(<span class="string">&quot;你好，这是一个文本示例。&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(text_result)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试图像输入（假设图像数据是字节字符串）</span></span><br><span class="line">image_result = moe_agent.run(<span class="string">b&#x27;\x89PNG\r\n\x1a\n...&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(image_result)</span><br></pre></td></tr></table></figure>

<p>在这个代码中：</p>
<ul>
<li><strong>TextExpertTool</strong> 和 <strong>ImageExpertTool</strong> 是处理文本和图像数据的专门专家。</li>
<li><strong>gating_function</strong> 根据数据模态将输入数据路由到合适的专家。</li>
<li><strong>MoEAgent</strong> 管理专家并使用正确的专家处理输入数据。</li>
</ul>
<p>这种模块化方法使得通过添加新的专家工具和更新gating_function能够轻松扩展系统以支持更多模态。</p>
<h3 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h3><p>多模态MoE系统成功的关键在于通过专门的专家有效处理不同的模态。通过专注于模态特定的处理，每个专家都可以为其数据类型采用最合适的算法和技术。这不仅提高了性能，还简化了新模态的整合，因为每个专家在MoE框架中是独立操作的。</p>
<p>虽然路由机制是必要的以正确处理输入数据，但主要挑战在于<strong>管理多个模态带来的复杂性</strong>。随着模态数量的增加，开发人员必须确保系统保持一致性，并且专家的整合不会导致冲突或低效。</p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>多模态混合专家系统代表了人工智能领域的一大进步，解决了处理多种数据类型时产生的指数级复杂性。通过将每种模态交给特定的专家模型处理，这些系统克服了传统单一模型的局限性，后者往往由于缺乏对齐数据以及数据类型本质上的差异而难以有效处理所有模态。</p>
<p>使用LangChain等框架实现多模态MoE系统，使开发人员能够构建可扩展和适应性强的AI应用程序。通过将<strong>模态作为MoE的关键要素</strong>，这些系统能够高效整合尽可能多的数据类型，并由专家级精度处理每种类型。这种方法不仅提高了性能，还允许随着新模态的出现，系统可以持续扩展。</p>
<p>随着AI领域的不断发展，模态特定处理在MoE框架中的重要性只会增加。整合多个模态的挑战将推动创新，促使更复杂的数据对齐和专家协调方法的</p>
<p>出现。最终，拥抱多模态MoE系统将使得AI应用程序更准确地反映现实世界中复杂、多方面的数据。</p>
<hr>
<h3 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h3><ul>
<li><strong>模态（Modality）</strong>：指数据的不同类型，例如文本、图像、音频等。</li>
<li><strong>混合专家（Mixture of Experts, MoE）</strong>：一种AI架构，通过多个专门的专家模型来处理不同的数据模态。</li>
<li><strong>LangChain</strong>：一个用于实现多模态系统的框架，提供了模块化架构以简化专家工具的管理和整合。</li>
</ul>
<hr>
<blockquote>
<p><strong>🍀后记🍀</strong><br>博客的关键词集中在编程、算法、机器人、人工智能、数学等等，持续高质量输出中。<br><strong>🌸唠嗑QQ群</strong>：<a target="_blank" rel="noopener" href="https://jq.qq.com/?_wv=1027&k=EaGddTQg">兔叽の魔术工房</a> (942848525)<br><strong>⭐B站账号</strong>：<a target="_blank" rel="noopener" href="https://space.bilibili.com/98639326">白拾ShiroX</a>（活跃于知识区和动画区）<br><strong>✨GitHub主页</strong>：<a target="_blank" rel="noopener" href="https://github.com/yhbcode000">yhbcode000</a>（工程文件）<br><strong>⛳Discord社区</strong>：<a target="_blank" rel="noopener" href="https://discord.g/nn5NDXMgae">AierLab</a>（人工智能社区）</p>
</blockquote><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:hobart.yang@qq.com">✨白拾ShiroX✨</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://discover304.top/2024/09/21/2024q3/195-moe/">https://discover304.top/2024/09/21/2024q3/195-moe/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0anime</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Mixture-of-Experts/">Mixture of Experts</a><a class="post-meta__tags" href="/tags/Multi-Modal-AI/">Multi-Modal AI</a><a class="post-meta__tags" href="/tags/LangChain/">LangChain</a><a class="post-meta__tags" href="/tags/AI-Architecture/">AI Architecture</a></div><div class="post_share"><div class="social-share" data-image="https://image.discover304.top/1726926461860.png?imageView2/2/h/300" data-sites="facebook,twitter,wechat,weibo,qzone,qq,linkedin"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> Donate<div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/img/wechat.jpg" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/alipay.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/10/03/2024q4/196-generative-agent/"><img class="prev-cover" src="https://image.discover304.top/1727972986837.png?imageView2/2/h/300" onerror="onerror=null;src='/img/404.png'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">UIST2023 Generative Agents: Interactive Simulacra of Human Behavior</div></div></a></div><div class="next-post pull-right"><a href="/2024/09/19/2024q3/194-sustainablility/"><img class="next-cover" src="https://image.discover304.top/1726775487424.png?imageView2/2/h/300" onerror="onerror=null;src='/img/404.png'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Expanding Sustainability: Space Migration, Long-Lasting Products, and Humanity's Future</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside_content" id="aside_content"><div class="card-widget card-info"><div class="card-content"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/head.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">✨白拾ShiroX✨</div><div class="author-info__description">Love Everything You Like.</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">282</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">148</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">29</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://space.bilibili.com/98639326"><i class="fab fa-bilibili"></i><span>Bilibili Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/YangSierCode000" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://x.com/ShiroHiro2024" target="_blank" title="X"><i class="fab fa-x"></i></a><a class="social-icon" href="https://www.youtube.com/channel/UCuQQr55i3VCQuCPMTQnpzDA" target="_blank" title="YouTube"><i class="fab fa-youtube"></i></a><a class="social-icon" href="https://blog.csdn.net/Discover304" target="_blank" title="CSDN"><i class="fa-solid fa-c"></i></a><a class="social-icon" href="https://www.zhihu.com/people/discover-56-86-75" target="_blank" title="知乎"><i class="fa-brands fa-zhihu"></i></a><a class="social-icon" href="mailto:hobart.yang@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://jq.qq.com/?_wv=1027&amp;k=EaGddTQg" target="_blank" title="QQ"><i class="fa-brands fa-qq"></i></a></div></div></div><div class="card-widget card-announcement"><div class="card-content"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">✨动态更新：<p style="text-align:center">享受精彩大学生活中。</p>✨聊天划水QQ群：<p style="text-align:center"><a target="_blank" rel="noopener" href="https://jq.qq.com/?_wv=1027&k=EaGddTQg"><strong>兔叽の魔术工房</strong></a><br>942-848-525</p>✨我们的口号是：<p style="text-align:center; color:#39C5BB">人工降神，机械飞升！</p><a target="_blank" rel="noopener" href='https://space.bilibili.com/98639326'><img src='/img/mikulittletrans.png'></a></div></div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="card-content"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/10/03/2024q4/196-generative-agent/" title="UIST2023 Generative Agents: Interactive Simulacra of Human Behavior"><img src="https://image.discover304.top/1727972986837.png?imageView2/2/h/300" onerror="this.onerror=null;this.src='/img/404.png'" alt="UIST2023 Generative Agents: Interactive Simulacra of Human Behavior"/></a><div class="content"><a class="title" href="/2024/10/03/2024q4/196-generative-agent/" title="UIST2023 Generative Agents: Interactive Simulacra of Human Behavior">UIST2023 Generative Agents: Interactive Simulacra of Human Behavior</a><time datetime="2024-10-03T16:35:09.850Z" title="Updated 2024-10-04 00:35:09">2024-10-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/09/08/2024q3/draft/193-AI701/" title="196-Ai701"><img src="https://api.btstu.cn/sjbz/api.php?lx=dongman&amp;format=images" onerror="this.onerror=null;this.src='/img/404.png'" alt="196-Ai701"/></a><div class="content"><a class="title" href="/2024/09/08/2024q3/draft/193-AI701/" title="196-Ai701">196-Ai701</a><time datetime="2024-10-03T16:34:15.082Z" title="Updated 2024-10-04 00:34:15">2024-10-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/02/21/000/" title="【整理】有趣的资料和网站"><img src="https://image.discover304.top/info-girl-see-cropped.jpg?imageView2/2/h/300" onerror="this.onerror=null;this.src='/img/404.png'" alt="【整理】有趣的资料和网站"/></a><div class="content"><a class="title" href="/2022/02/21/000/" title="【整理】有趣的资料和网站">【整理】有趣的资料和网站</a><time datetime="2024-09-21T16:30:45.995Z" title="Updated 2024-09-22 00:30:45">2024-09-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/08/19/2024q3/draft/188-1-mbzuai-help-link/" title="MBZUAI Quick Access Links"><img src="https://image.discover304.top/1726926639202.png?imageView2/2/h/300" onerror="this.onerror=null;this.src='/img/404.png'" alt="MBZUAI Quick Access Links"/></a><div class="content"><a class="title" href="/2024/08/19/2024q3/draft/188-1-mbzuai-help-link/" title="MBZUAI Quick Access Links">MBZUAI Quick Access Links</a><time datetime="2024-09-21T13:50:51.419Z" title="Updated 2024-09-21 21:50:51">2024-09-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/09/21/2024q3/195-moe/" title="Navigating the Complexity of Mixture of Experts (MoE) in Multi-Modal Systems"><img src="https://image.discover304.top/1726926461860.png?imageView2/2/h/300" onerror="this.onerror=null;this.src='/img/404.png'" alt="Navigating the Complexity of Mixture of Experts (MoE) in Multi-Modal Systems"/></a><div class="content"><a class="title" href="/2024/09/21/2024q3/195-moe/" title="Navigating the Complexity of Mixture of Experts (MoE) in Multi-Modal Systems">Navigating the Complexity of Mixture of Experts (MoE) in Multi-Modal Systems</a><time datetime="2024-09-21T13:47:51.709Z" title="Updated 2024-09-21 21:47:51">2024-09-21</time></div></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(https://image.discover304.top/1726926461860.png?imageView2/2/h/300)"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By ✨白拾ShiroX✨</div><div><a target="_blank" href="https://beian.miit.gov.cn/" style="display:inline-block;text-decoration:none;height:20px;line-height:20px;"><p style="float:left;height:20px;line-height:20px;margin: 0px 0px 0px 5px; color:#939393;"> 冀ICP备2021025381号-1</p></a></div><div><a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=13060602001430" style="display:inline-block;text-decoration:none;height:20px;line-height:20px;"><img src="/img/beian.png" style="float:left;"/><p style="float:left;height:20px;line-height:20px;margin: 0px 0px 0px 5px; color:#939393;">冀公网安备 13060602001430号</p></a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="Increase font size"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="Decrease font size"><i class="fas fa-minus"></i></button><button id="translateLink" type="button" title="Switch Between Traditional Chinese And Simplified Chinese">繁</button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.spacingElementById('content-inner')
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.spacingElementById('content-inner')
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> {preloader.endLoading()})</script><div class="js-pjax"><script>if (document.getElementsByClassName('mermaid').length) {
  if (window.mermaidJsLoad) mermaid.init()
  else {
    getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(() => {
      window.mermaidJsLoad = true
      mermaid.initialize({
        theme: 'neutral',
      })
      false && mermaid.init()
    })
  }
}</script><script>function loadValine () {
  function initValine () {
    let initData = {
      el: '#vcomment',
      appId: 'A9RWVELPcIotgfbpp9KLGXQM-gzGzoHsz',
      appKey: 'MLgPQW5h0DPgE8jNkeREKubU',
      placeholder: '欢迎留言呀。（网址是选填，可以留空）',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'zh-CN',
      recordIP: true,
      serverURLs: 'https://a9rwvelp.lc-cn-n1-shared.com',
      emojiCDN: 'https://cdn.jsdelivr.net/gh/GamerNoTitle/ValineCDN@master/',
      emojiMaps: {"QQ1":"QQ/aini.gif","QQ2":"QQ/aixin.gif","QQ3":"QQ/aoman.gif","QQ4":"QQ/baiyan.gif","QQ5":"QQ/bangbangtang.gif","QQ6":"QQ/baojin.gif","QQ7":"QQ/baoquan.gif","QQ8":"QQ/bishi.gif","QQ9":"QQ/bizui.gif","QQ11":"QQ/cahan.gif","QQ12":"QQ/caidao.gif","QQ13":"QQ/chi.gif","QQ14":"QQ/ciya.gif","QQ15":"QQ/dabing.gif","QQ16":"QQ/daku.gif","QQ17":"QQ/dan.gif","QQ18":"QQ/deyi.gif","QQ19":"QQ/doge.gif","QQ20":"QQ/fadai.gif","QQ21":"QQ/fanu.gif","QQ22":"QQ/fendou.gif","QQ23":"QQ/ganga.gif","QQ24":"QQ/gouyin.gif","QQ25":"QQ/guzhang.gif","QQ26":"QQ/haixiu.gif","QQ27":"QQ/hanxiao.gif","QQ28":"QQ/haobang.gif","QQ29":"QQ/haqian.gif","QQ30":"QQ/hecai.gif","QQ31":"QQ/hexie.gif","QQ32":"QQ/huaixiao.gif","QQ33":"QQ/jie.gif","QQ34":"QQ/jingkong.gif","QQ35":"QQ/jingxi.gif","QQ36":"QQ/jingya.gif","QQ37":"QQ/juhua.gif","QQ38":"QQ/keai.gif","QQ39":"QQ/kelian.gif","QQ40":"QQ/koubi.gif","QQ41":"QQ/ku.gif","QQ42":"QQ/kuaikule.gif","QQ43":"QQ/kulou.gif","QQ44":"QQ/kun.gif","QQ45":"QQ/lanqiu.gif","QQ46":"QQ/leiben.gif","QQ47":"QQ/lenghan.gif","QQ48":"QQ/liuhan.gif","QQ49":"QQ/liulei.gif","QQ50":"QQ/nanguo.gif","QQ51":"QQ/OK.gif","QQ52":"QQ/penxue.gif","QQ53":"QQ/piezui.gif","QQ54":"QQ/pijiu.gif","QQ55":"QQ/qiang.gif","QQ56":"QQ/qiaoda.gif","QQ57":"QQ/qinqin.gif","QQ58":"QQ/qiudale.gif","QQ59":"QQ/quantou.gif","QQ60":"QQ/saorao.gif","QQ61":"QQ/se.gif","QQ62":"QQ/shengli.gif","QQ63":"QQ/shouqiang.gif","QQ64":"QQ/shuai.gif","QQ65":"QQ/shui.gif","QQ66":"QQ/tiaopi.gif","QQ67":"QQ/touxiao.gif","QQ68":"QQ/tu.gif","QQ69":"QQ/tuosai.gif","QQ70":"QQ/weiqu.gif","QQ71":"QQ/weixiao.gif","QQ72":"QQ/woshou.gif","QQ73":"QQ/wozuimei.gif","QQ74":"QQ/wunai.gif","QQ75":"QQ/xia.gif","QQ76":"QQ/xiaojiujie.gif","QQ77":"QQ/xiaoku.gif","QQ78":"QQ/xiaoyanger.gif","QQ79":"QQ/xieyanxiao.gif","QQ80":"QQ/xigua.gif","QQ81":"QQ/xu.gif","QQ82":"QQ/yangtuo.gif","QQ83":"QQ/yinxian.gif","QQ84":"QQ/yiwen.gif","QQ85":"QQ/youhengheng.gif","QQ86":"QQ/youling.gif","QQ87":"QQ/yun.gif","QQ88":"QQ/zaijian.gif","QQ89":"QQ/zhayanjian.gif","QQ90":"QQ/zhemo.gif","QQ91":"QQ/zhouma.gif","QQ92":"QQ/zhuakuang.gif","QQ93":"QQ/zuohengheng.gif","bilibiliHotKey1":"bilibiliHotKey/1.jpg","bilibiliHotKey2":"bilibiliHotKey/10.jpg","bilibiliHotKey3":"bilibiliHotKey/11.jpg","bilibiliHotKey4":"bilibiliHotKey/12.jpg","bilibiliHotKey5":"bilibiliHotKey/13.jpg","bilibiliHotKey6":"bilibiliHotKey/14.jpg","bilibiliHotKey7":"bilibiliHotKey/15.jpg","bilibiliHotKey8":"bilibiliHotKey/16.jpg","bilibiliHotKey9":"bilibiliHotKey/17.jpg","bilibiliHotKey10":"bilibiliHotKey/18.jpg","bilibiliHotKey11":"bilibiliHotKey/19.jpg","bilibiliHotKey12":"bilibiliHotKey/2.jpg","bilibiliHotKey13":"bilibiliHotKey/20.jpg","bilibiliHotKey14":"bilibiliHotKey/21.jpg","bilibiliHotKey15":"bilibiliHotKey/22.jpg","bilibiliHotKey16":"bilibiliHotKey/23.jpg","bilibiliHotKey17":"bilibiliHotKey/24.jpg","bilibiliHotKey18":"bilibiliHotKey/25.jpg","bilibiliHotKey19":"bilibiliHotKey/26.jpg","bilibiliHotKey20":"bilibiliHotKey/27.jpg","bilibiliHotKey21":"bilibiliHotKey/28.jpg","bilibiliHotKey22":"bilibiliHotKey/29.jpg","bilibiliHotKey23":"bilibiliHotKey/3.jpg","bilibiliHotKey24":"bilibiliHotKey/30.jpg","bilibiliHotKey25":"bilibiliHotKey/31.jpg","bilibiliHotKey26":"bilibiliHotKey/32.jpg","bilibiliHotKey27":"bilibiliHotKey/4.jpg","bilibiliHotKey28":"bilibiliHotKey/5.jpg","bilibiliHotKey29":"bilibiliHotKey/6.jpg","bilibiliHotKey30":"bilibiliHotKey/7.jpg","bilibiliHotKey31":"bilibiliHotKey/8.jpg","bilibiliHotKey32":"bilibiliHotKey/9.jpg","Menhera-chan1":"Menhera-chan/1.jpg","Menhera-chan2":"Menhera-chan/10.jpg","Menhera-chan3":"Menhera-chan/100.jpg","Menhera-chan4":"Menhera-chan/101.jpg","Menhera-chan5":"Menhera-chan/102.jpg","Menhera-chan6":"Menhera-chan/103.jpg","Menhera-chan7":"Menhera-chan/104.jpg","Menhera-chan8":"Menhera-chan/105.jpg","Menhera-chan9":"Menhera-chan/106.jpg","Menhera-chan10":"Menhera-chan/107.jpg","Menhera-chan11":"Menhera-chan/108.jpg","Menhera-chan12":"Menhera-chan/109.jpg","Menhera-chan13":"Menhera-chan/11.jpg","Menhera-chan14":"Menhera-chan/110.jpg","Menhera-chan15":"Menhera-chan/111.jpg","Menhera-chan16":"Menhera-chan/112.jpg","Menhera-chan17":"Menhera-chan/113.jpg","Menhera-chan18":"Menhera-chan/114.jpg","Menhera-chan19":"Menhera-chan/115.jpg","Menhera-chan20":"Menhera-chan/116.jpg","Menhera-chan21":"Menhera-chan/117.jpg","Menhera-chan22":"Menhera-chan/118.jpg","Menhera-chan23":"Menhera-chan/119.jpg","Menhera-chan24":"Menhera-chan/12.jpg","Menhera-chan25":"Menhera-chan/120.jpg","Menhera-chan26":"Menhera-chan/13.jpg","Menhera-chan27":"Menhera-chan/14.jpg","Menhera-chan28":"Menhera-chan/15.jpg","Menhera-chan29":"Menhera-chan/16.jpg","Menhera-chan30":"Menhera-chan/17.jpg","Menhera-chan31":"Menhera-chan/18.jpg","Menhera-chan32":"Menhera-chan/19.jpg","Menhera-chan33":"Menhera-chan/2.jpg","Menhera-chan34":"Menhera-chan/20.jpg","Menhera-chan35":"Menhera-chan/21.jpg","Menhera-chan36":"Menhera-chan/22.jpg","Menhera-chan37":"Menhera-chan/23.jpg","Menhera-chan38":"Menhera-chan/24.jpg","Menhera-chan39":"Menhera-chan/25.jpg","Menhera-chan40":"Menhera-chan/26.jpg","Menhera-chan41":"Menhera-chan/27.jpg","Menhera-chan42":"Menhera-chan/28.jpg","Menhera-chan43":"Menhera-chan/29.jpg","Menhera-chan44":"Menhera-chan/3.jpg","Menhera-chan45":"Menhera-chan/30.jpg","Menhera-chan46":"Menhera-chan/31.jpg","Menhera-chan47":"Menhera-chan/32.jpg","Menhera-chan48":"Menhera-chan/33.jpg","Menhera-chan49":"Menhera-chan/34.jpg","Menhera-chan50":"Menhera-chan/35.jpg","Menhera-chan51":"Menhera-chan/36.jpg","Menhera-chan52":"Menhera-chan/37.jpg","Menhera-chan53":"Menhera-chan/38.jpg","Menhera-chan54":"Menhera-chan/39.jpg","Menhera-chan55":"Menhera-chan/4.jpg","Menhera-chan56":"Menhera-chan/40.jpg","Menhera-chan57":"Menhera-chan/41.jpg","Menhera-chan58":"Menhera-chan/42.jpg","Menhera-chan59":"Menhera-chan/43.jpg","Menhera-chan60":"Menhera-chan/44.jpg","Menhera-chan61":"Menhera-chan/45.jpg","Menhera-chan62":"Menhera-chan/46.jpg","Menhera-chan63":"Menhera-chan/47.jpg","Menhera-chan64":"Menhera-chan/48.jpg","Menhera-chan65":"Menhera-chan/49.jpg","Menhera-chan66":"Menhera-chan/5.jpg","Menhera-chan67":"Menhera-chan/50.jpg","Menhera-chan68":"Menhera-chan/51.jpg","Menhera-chan69":"Menhera-chan/52.jpg","Menhera-chan70":"Menhera-chan/53(1).jpg","Menhera-chan71":"Menhera-chan/53.jpg","Menhera-chan72":"Menhera-chan/54.jpg","Menhera-chan73":"Menhera-chan/55.jpg","Menhera-chan74":"Menhera-chan/56.jpg","Menhera-chan75":"Menhera-chan/57.jpg","Menhera-chan76":"Menhera-chan/58.jpg","Menhera-chan77":"Menhera-chan/59.jpg","Menhera-chan78":"Menhera-chan/6.jpg","Menhera-chan79":"Menhera-chan/60.jpg","Menhera-chan80":"Menhera-chan/61.jpg","Menhera-chan81":"Menhera-chan/62.jpg","Menhera-chan82":"Menhera-chan/63.jpg","Menhera-chan83":"Menhera-chan/64.jpg","Menhera-chan84":"Menhera-chan/65.jpg","Menhera-chan85":"Menhera-chan/66.jpg","Menhera-chan86":"Menhera-chan/67.jpg","Menhera-chan87":"Menhera-chan/68.jpg","Menhera-chan88":"Menhera-chan/69.jpg","Menhera-chan89":"Menhera-chan/7.jpg","Menhera-chan90":"Menhera-chan/70.jpg","Menhera-chan91":"Menhera-chan/71.jpg","Menhera-chan92":"Menhera-chan/72.jpg","Menhera-chan93":"Menhera-chan/73.jpg","Menhera-chan94":"Menhera-chan/74.jpg","Menhera-chan95":"Menhera-chan/75.jpg","Menhera-chan96":"Menhera-chan/76.jpg","Menhera-chan97":"Menhera-chan/77.jpg","Menhera-chan98":"Menhera-chan/78.jpg","Menhera-chan99":"Menhera-chan/79.jpg","Menhera-chan100":"Menhera-chan/8.jpg","Menhera-chan101":"Menhera-chan/80.jpg","Menhera-chan102":"Menhera-chan/81.jpg","Menhera-chan103":"Menhera-chan/82.jpg","Menhera-chan104":"Menhera-chan/83.jpg","Menhera-chan105":"Menhera-chan/84.jpg","Menhera-chan106":"Menhera-chan/85.jpg","Menhera-chan107":"Menhera-chan/86.jpg","Menhera-chan108":"Menhera-chan/87.jpg","Menhera-chan109":"Menhera-chan/88.jpg","Menhera-chan110":"Menhera-chan/89.jpg","Menhera-chan111":"Menhera-chan/9.jpg","Menhera-chan112":"Menhera-chan/90.jpg","Menhera-chan113":"Menhera-chan/91.jpg","Menhera-chan114":"Menhera-chan/92.jpg","Menhera-chan115":"Menhera-chan/93.jpg","Menhera-chan116":"Menhera-chan/94.jpg","Menhera-chan117":"Menhera-chan/95.jpg","Menhera-chan118":"Menhera-chan/96.jpg","Menhera-chan119":"Menhera-chan/97.jpg","Menhera-chan120":"Menhera-chan/98.jpg","Menhera-chan121":"Menhera-chan/99.jpg","Sweetie-Bunny1":"Sweetie-Bunny/12311678.png","Sweetie-Bunny2":"Sweetie-Bunny/12311679.png","Sweetie-Bunny3":"Sweetie-Bunny/12311680.png","Sweetie-Bunny4":"Sweetie-Bunny/12311681.png","Sweetie-Bunny5":"Sweetie-Bunny/12311682.png","Sweetie-Bunny6":"Sweetie-Bunny/12311683.png","Sweetie-Bunny7":"Sweetie-Bunny/12311684.png","Sweetie-Bunny8":"Sweetie-Bunny/12311685.png","Sweetie-Bunny9":"Sweetie-Bunny/12311686.png","Sweetie-Bunny10":"Sweetie-Bunny/12311687.png","Sweetie-Bunny11":"Sweetie-Bunny/12311688.png","Sweetie-Bunny12":"Sweetie-Bunny/12311689.png","Sweetie-Bunny13":"Sweetie-Bunny/12311690.png","Sweetie-Bunny14":"Sweetie-Bunny/12311691.png","Sweetie-Bunny15":"Sweetie-Bunny/12311692.png","Sweetie-Bunny16":"Sweetie-Bunny/12311693.png","Sweetie-Bunny17":"Sweetie-Bunny/12311694.png","Sweetie-Bunny18":"Sweetie-Bunny/12311695.png","Sweetie-Bunny19":"Sweetie-Bunny/12311696.png","Sweetie-Bunny20":"Sweetie-Bunny/12311697.png","Sweetie-Bunny21":"Sweetie-Bunny/12311698.png","Sweetie-Bunny22":"Sweetie-Bunny/12311699.png","Sweetie-Bunny23":"Sweetie-Bunny/12311700.png","Sweetie-Bunny24":"Sweetie-Bunny/12311701.png","Sweetie-Bunny25":"Sweetie-Bunny/12311702.png","Sweetie-Bunny26":"Sweetie-Bunny/12311703.png","Sweetie-Bunny27":"Sweetie-Bunny/12311704.png","Sweetie-Bunny28":"Sweetie-Bunny/12311705.png","Sweetie-Bunny29":"Sweetie-Bunny/12311706.png","Sweetie-Bunny30":"Sweetie-Bunny/12311707.png","Sweetie-Bunny31":"Sweetie-Bunny/12311708.png","Sweetie-Bunny32":"Sweetie-Bunny/12311709.png","Sweetie-Bunny33":"Sweetie-Bunny/12311710.png","Sweetie-Bunny34":"Sweetie-Bunny/12311711.png","Sweetie-Bunny35":"Sweetie-Bunny/12311712.png","Sweetie-Bunny36":"Sweetie-Bunny/12311713.png","Sweetie-Bunny37":"Sweetie-Bunny/12311714.png","Sweetie-Bunny38":"Sweetie-Bunny/12311715.png","Sweetie-Bunny39":"Sweetie-Bunny/12311716.png","Sweetie-Bunny40":"Sweetie-Bunny/12311717.png","Majotabi1":"Majotabi/367516718.png","Majotabi2":"Majotabi/367516719.png","Majotabi3":"Majotabi/367516720.png","Majotabi4":"Majotabi/367516721.png","Majotabi5":"Majotabi/367516722.png","Majotabi6":"Majotabi/367516723.png","Majotabi7":"Majotabi/367516724.png","Majotabi8":"Majotabi/367516725.png","Majotabi9":"Majotabi/367516726.png","Majotabi10":"Majotabi/367516727.png","Majotabi11":"Majotabi/367516728.png","Majotabi12":"Majotabi/367516729.png","Majotabi13":"Majotabi/367516730.png","Majotabi14":"Majotabi/367516731.png","Majotabi15":"Majotabi/367516732.png","Majotabi16":"Majotabi/367516733.png","Majotabi17":"Majotabi/367516734.png","Majotabi18":"Majotabi/367516735.png","Majotabi19":"Majotabi/367516736.png","Majotabi20":"Majotabi/367516737.png","Majotabi21":"Majotabi/367516738.png","Majotabi22":"Majotabi/367516739.png","Majotabi23":"Majotabi/367516740.png","Majotabi24":"Majotabi/367516741.png","Majotabi25":"Majotabi/367516742.png","Majotabi26":"Majotabi/367516743.png","Majotabi27":"Majotabi/367516744.png","Majotabi28":"Majotabi/367516745.png","Majotabi29":"Majotabi/367516746.png","Majotabi30":"Majotabi/367516747.png","Majotabi31":"Majotabi/367516748.png","Majotabi32":"Majotabi/367516749.png","Majotabi33":"Majotabi/367516750.png","Majotabi34":"Majotabi/367516751.png","Majotabi35":"Majotabi/367516752.png","Majotabi36":"Majotabi/367516753.png","Majotabi37":"Majotabi/367516754.png","Majotabi38":"Majotabi/367516755.png","Majotabi39":"Majotabi/367516756.png","Majotabi40":"Majotabi/367516757.png","Snow-Miku1":"Snow-Miku/3583066@2x.png","Snow-Miku2":"Snow-Miku/3583067@2x.png","Snow-Miku3":"Snow-Miku/3583068@2x.png","Snow-Miku4":"Snow-Miku/3583069@2x.png","Snow-Miku5":"Snow-Miku/3583070@2x.png","Snow-Miku6":"Snow-Miku/3583071@2x.png","Snow-Miku7":"Snow-Miku/3583072@2x.png","Snow-Miku8":"Snow-Miku/3583073@2x.png","Snow-Miku9":"Snow-Miku/3583074@2x.png","Snow-Miku10":"Snow-Miku/3583075@2x.png","Snow-Miku11":"Snow-Miku/3583076@2x.png","Snow-Miku12":"Snow-Miku/3583077@2x.png","Snow-Miku13":"Snow-Miku/3583078@2x.png","Snow-Miku14":"Snow-Miku/3583079@2x.png","Snow-Miku15":"Snow-Miku/3583080@2x.png","Snow-Miku16":"Snow-Miku/3583081@2x.png","Snow-Miku17":"Snow-Miku/3583082@2x.png","Snow-Miku18":"Snow-Miku/3583083@2x.png","Snow-Miku19":"Snow-Miku/3583084@2x.png","Snow-Miku20":"Snow-Miku/3583085@2x.png","Snow-Miku21":"Snow-Miku/3583086@2x.png","Snow-Miku22":"Snow-Miku/3583087@2x.png","Snow-Miku23":"Snow-Miku/3583088@2x.png","Snow-Miku24":"Snow-Miku/3583089@2x.png","Snow-Miku25":"Snow-Miku/3583090@2x.png","Snow-Miku26":"Snow-Miku/3583091@2x.png","Snow-Miku27":"Snow-Miku/3583092@2x.png","Snow-Miku28":"Snow-Miku/3583093@2x.png","Snow-Miku29":"Snow-Miku/3583094@2x.png","Snow-Miku30":"Snow-Miku/3583095@2x.png","Snow-Miku31":"Snow-Miku/3583096@2x.png","Snow-Miku32":"Snow-Miku/3583097@2x.png","Snow-Miku33":"Snow-Miku/3583098@2x.png","Snow-Miku34":"Snow-Miku/3583099@2x.png","Snow-Miku35":"Snow-Miku/3583100@2x.png","Snow-Miku36":"Snow-Miku/3583101@2x.png","Snow-Miku37":"Snow-Miku/3583102@2x.png","Snow-Miku38":"Snow-Miku/3583103@2x.png","Snow-Miku39":"Snow-Miku/3583104@2x.png","Snow-Miku40":"Snow-Miku/3583105@2x.png"},
      enableQQ: true,
      path: window.location.pathname,
    }

    if (true) { 
      initData.requiredFields= ('nick,mail'.split(','))
    }
    
    if (false) {
      const otherData = false
      initData = Object.assign({}, initData, otherData)
    }
    
    const valine = new Valine(initData)
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.querySelector('#vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script>(function(){
  const bp = document.createElement('script');
  const curProtocol = window.location.protocol.split(':')[0];
  if (curProtocol === 'https') {
    bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
  }
  else{
    bp.src = 'http://push.zhanzhang.baidu.com/push.js';
  }
  bp.dataset.pjax = ''
  const s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(bp, s);
})()</script></div></body></html>